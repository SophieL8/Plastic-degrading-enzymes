{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UANKGuIKvGYK"
      },
      "source": [
        "# My Analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import csv\n",
        "import itertools\n",
        "from scipy.stats import pearsonr, t\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.stats import binom"
      ],
      "metadata": {
        "id": "kBvhH401_SyJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6_Pbk7qqxIpe"
      },
      "outputs": [],
      "source": [
        "data_dict = {}\n",
        "\n",
        "with open('pollutionData.txt', 'r') as input_file:\n",
        "    next(input_file)\n",
        "    for line in input_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        key = (values[0], values[1])\n",
        "        distance = float(values[5])\n",
        "\n",
        "        if key in data_dict:\n",
        "            existing_value = data_dict[key]\n",
        "            if distance < existing_value[1] and distance < 400:\n",
        "                data_dict[key] = (values[3], distance)\n",
        "        elif distance < 400:\n",
        "            data_dict[key] = (values[3], distance)\n",
        "\n",
        "with open('smallest_dist.txt', 'w') as output_file:\n",
        "    for key, value in data_dict.items():\n",
        "        output_file.write(f\"{key[0]}\\t{key[1]}\\t{value[0]}\\t{value[1]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "chouaQ15NgnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2692209b-ace3-47d5-a5d2-9ae67097e1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Map the pollution in smallest_dist.txt to the sample location in Sunagawa file using the enzyme id in both files\n",
        "sunagawa_data = pd.read_excel('Sunagawa_TableS1.xlsx')\n",
        "new_data = pd.read_csv('smallest_dist.txt', sep='\\t', header=None)\n",
        "\n",
        "mapping_dict = dict(zip(sunagawa_data.iloc[1:, 2], sunagawa_data.iloc[1:, 0]))\n",
        "new_data[1] = new_data[1].map(mapping_dict)\n",
        "\n",
        "new_data.to_csv('mapped.txt', sep='\\t', header=False, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vxOJx1Ak4_TF"
      },
      "outputs": [],
      "source": [
        "file3_path = 'TARA243.KO.profile.release'\n",
        "df3 = pd.read_csv(file3_path, delimiter='\\t')\n",
        "\n",
        "file2_path = 'mapped.txt'\n",
        "df2 = pd.read_csv(file2_path, delimiter='\\t', header=None, names=['ID', 'Sample', 'Value1', 'Value2'])\n",
        "\n",
        "df_ko_filtered = df3.iloc[:, 0:1]\n",
        "\n",
        "sample_names_to_keep = df2['Sample'].unique()\n",
        "columns_to_keep_ko = [col for col in df3.columns if any(sample_name in col for sample_name in sample_names_to_keep)]\n",
        "df_ko_filtered = pd.concat([df_ko_filtered, df3[columns_to_keep_ko]], axis=1)\n",
        "\n",
        "output_ko_file_path = 'TARA243_KO_filtered.KO.profile.release'\n",
        "df_ko_filtered.to_csv(output_ko_file_path, sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4R-UnI9vjpU"
      },
      "source": [
        "# Calculating Pearson's Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wRF9IqWXfpnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38592160-d6ec-4ca8-ffc0-8daddca2586e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-5-4102174772.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
            "/tmp/ipython-input-5-4102174772.py:2: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  correlation_coefficient, _ = pearsonr(x_values, y_values)\n"
          ]
        }
      ],
      "source": [
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values # sampleIDs\n",
        "y_values = mapped_data[2].values # pollutionValues\n",
        "\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "# For each row of the enzyme abundance data, get corresponding x_values, calculate correlation coefficient, store\n",
        "for row_index in range(len(release_df)):\n",
        "    x_values = [release_df.iloc[row_index][str(second_value)] for second_value in second_values]\n",
        "\n",
        "    correlation_coefficient = calculate_correlation(x_values, y_values)\n",
        "    correlation_coefficients[row_index] = correlation_coefficient\n",
        "\n",
        "    enzyme_name = release_df.iloc[row_index, 0]\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + x_values)\n",
        "\n",
        "# descending order sort\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "first_column_values = release_df.iloc[:, 0].values\n",
        "\n",
        "# Save the sorted coefficients\n",
        "with open(\"all_pearson_correlations.txt\", \"w\") as file:\n",
        "    for row_index, correlation_coefficient in sorted_coefficients:\n",
        "        first_value = first_column_values[row_index]  # Get the corresponding enzyme name\n",
        "        file.write(f\"Row {row_index}: Enzyme = {first_value}, Correlation = {correlation_coefficient}\\n\")\n",
        "\n",
        "# Save x_values\n",
        "column_names = ['Enzyme'] + [f'Pollution_{y_val}' for y_val in y_values]  # Using y_values as sample identifiers\n",
        "x_values_df = pd.DataFrame(x_values_for_all_enzymes, columns=column_names)\n",
        "x_values_df.to_csv('pearson_x_y_values.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQMmt2lCTTcb"
      },
      "source": [
        "##### T-Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sStSuPq4TW2M"
      },
      "outputs": [],
      "source": [
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    x = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - stats.t.cdf(x, degrees_of_freedom)\n",
        "    return x, probability\n",
        "\n",
        "degrees_of_freedom = 39\n",
        "\n",
        "# Calculate and add the t-value distribution to file\n",
        "with open(\"all_pearson_correlations.txt\", \"w\") as file:\n",
        "    for row_index, correlation_coefficient in sorted_coefficients:\n",
        "        first_value = first_column_values[row_index]\n",
        "\n",
        "        x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        file.write(f\"Row {row_index}: First Value = {first_value}, Correlation Coefficient = {correlation_coefficient}, x = {x}, Probability = {probability}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pH0ggC48XA8V"
      },
      "outputs": [],
      "source": [
        "significant_rows = []\n",
        "total_probability = 0\n",
        "\n",
        "for row_index, correlation_coefficient in sorted_coefficients:\n",
        "    first_value = first_column_values[row_index]\n",
        "    x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append((row_index, first_value, correlation_coefficient, x, probability))\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break\n",
        "\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "if significant_rows:\n",
        "    significant_rows = significant_rows[:-1]\n",
        "\n",
        "with open(\"sig_pearson_enzymes.txt\", \"w\") as file:\n",
        "    for row_index, first_value, correlation_coefficient, x, probability in significant_rows:\n",
        "        file.write(f\"Enzyme = {first_value}, Correlation = {correlation_coefficient}\\n\")\n",
        "        #, x = {y_values}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Correlation calculation & t-dist"
      ],
      "metadata": {
        "id": "8sTjx_pVcUHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    x = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - stats.t.cdf(x, degrees_of_freedom)\n",
        "    return x, probability\n",
        "\n",
        "degrees_of_freedom = 39\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "for row_index in range(len(release_df)):\n",
        "    x_values = [release_df.iloc[row_index][str(second_value)] for second_value in second_values]\n",
        "\n",
        "    desired_length = len(x_values)\n",
        "    y_values_resized = np.resize(y_values, desired_length)\n",
        "\n",
        "    correlation_coefficient = calculate_correlation(x_values, y_values_resized)\n",
        "    correlation_coefficients[row_index] = correlation_coefficient\n",
        "\n",
        "    enzyme_name = release_df.iloc[row_index, 0]\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + x_values)\n",
        "\n",
        "# Sort in descending order\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "first_column_values = release_df.iloc[:, 0].values\n",
        "\n",
        "# Calculate the t and p-value for the sorted coefficients\n",
        "significant_rows = []\n",
        "total_probability = 0\n",
        "\n",
        "for row_index, correlation_coefficient in sorted_coefficients:\n",
        "    first_value = first_column_values[row_index]  # Get the corresponding enzyme name\n",
        "    x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append((row_index, first_value, correlation_coefficient, x, probability))\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break\n",
        "\n",
        "with open(\"sig_pearson_enzymes.txt\", \"w\") as file:\n",
        "    for row_index, first_value, correlation_coefficient, x, probability in significant_rows:\n",
        "        file.write(f\"Enzyme = {first_value}, Correlation = {correlation_coefficient}, t-dist = {x}, p-value = {probability}\\n\")"
      ],
      "metadata": {
        "id": "uxBfshXLbaXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006ec281-f2e3-439f-d21f-b05a9b1d4e03"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-56550722.py:12: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
            "/tmp/ipython-input-8-56550722.py:2: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  correlation_coefficient, _ = pearsonr(x_values, y_values)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OYR3wLlx31QS"
      },
      "outputs": [],
      "source": [
        "with open('all_pearson_correlations.txt', 'r') as input_file:\n",
        "    with open('all_pearson_correlations.tab', 'w', newline='') as tab_output_file:\n",
        "        tab_writer = csv.writer(tab_output_file, delimiter='\\t')\n",
        "        tab_writer.writerow(['Enzyme', 'Correlation'])\n",
        "\n",
        "        with open('all_pearson_correlations.csv', 'w', newline='') as csv_output_file:\n",
        "            csv_writer = csv.writer(csv_output_file)\n",
        "            csv_writer.writerow(['Enzyme', 'Correlation'])\n",
        "\n",
        "            for line in input_file:\n",
        "                line = line.strip()\n",
        "                parts = line.split(',')\n",
        "\n",
        "                if len(parts) == 2:\n",
        "                    enzyme = parts[0].split('=')[1].strip()\n",
        "                    correlation = float(parts[1].split('=')[1].strip())\n",
        "                    tab_writer.writerow([enzyme, correlation])\n",
        "                    csv_writer.writerow([enzyme, correlation])\n",
        "\n",
        "with open('sig_pearson_enzymes.txt', 'r') as infile:\n",
        "    lines = infile.readlines()\n",
        "\n",
        "    with open('sig_pearson_enzymes.tab', 'w', newline='') as tab_output_file:\n",
        "        tab_writer = csv.writer(tab_output_file, delimiter='\\t')\n",
        "        tab_writer.writerow(['Enzyme', 'Correlation'])\n",
        "\n",
        "        with open('sig_pearson_enzymes.csv', 'w', newline='') as csv_output_file:\n",
        "            csv_writer = csv.writer(csv_output_file)\n",
        "            csv_writer.writerow(['Enzyme', 'Correlation'])\n",
        "\n",
        "            for line in lines:\n",
        "                parts = line.strip().split(', ')\n",
        "                enzyme = parts[0].split(' = ')[1]\n",
        "                correlation = parts[1].split(' = ')[1]\n",
        "                tab_writer.writerow([enzyme, correlation])\n",
        "                csv_writer.writerow([enzyme, correlation])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qprIgQA1V-Km"
      },
      "source": [
        "## Spearman Correlation Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wSqk2UAX2cIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7218e6b-006d-466b-d6ef-a3016fea2602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-4169890881.py:7: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
            "/tmp/ipython-input-10-4169890881.py:4: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  correlation_coefficient, _ = spearmanr(x_values, y_values)\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import spearmanr  # Import spearmanr instead of pearsonr\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = spearmanr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "for row_index in range(len(release_df)):\n",
        "    x_values = [release_df.iloc[row_index][str(second_value)] for second_value in second_values]\n",
        "\n",
        "    desired_length = len(x_values)\n",
        "    y_values_resized = np.resize(y_values, desired_length)\n",
        "\n",
        "    correlation_coefficient = calculate_correlation(x_values, y_values_resized)\n",
        "    correlation_coefficients[row_index] = correlation_coefficient\n",
        "\n",
        "    enzyme_name = release_df.iloc[row_index, 0]\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + x_values)\n",
        "\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "first_column_values = release_df.iloc[:, 0].values\n",
        "\n",
        "with open(\"all_spearman_correlations.txt\", \"w\") as file:\n",
        "    for row_index, correlation_coefficient in sorted_coefficients:\n",
        "        first_value = first_column_values[row_index]\n",
        "        file.write(f\"Row {row_index}: Enzyme = {first_value}, Spearman Correlation = {correlation_coefficient}\\n\")\n",
        "\n",
        "column_names = ['Enzyme'] + [f'Pollution_{y_val}' for y_val in y_values]\n",
        "x_values_df = pd.DataFrame(x_values_for_all_enzymes, columns=column_names)\n",
        "x_values_df.to_csv('spearman_x_y_values.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Fr0Wvw0W2m44"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    x = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - stats.t.cdf(x, degrees_of_freedom)\n",
        "    return x, probability\n",
        "\n",
        "degrees_of_freedom = 39\n",
        "\n",
        "with open(\"all_spearman_correlations.txt\", \"w\") as file:\n",
        "    for row_index, correlation_coefficient in sorted_coefficients:\n",
        "        first_value = first_column_values[row_index]  # Get the corresponding first value\n",
        "\n",
        "        x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        file.write(f\"Row {row_index}: First Value = {first_value}, Correlation Coefficient = {correlation_coefficient}, x = {x}, Probability = {probability}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L0Co5meA20x8"
      },
      "outputs": [],
      "source": [
        "significant_rows = []\n",
        "total_probability = 0\n",
        "\n",
        "for row_index, correlation_coefficient in sorted_coefficients:\n",
        "    first_value = first_column_values[row_index]\n",
        "\n",
        "    x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append((row_index, first_value, correlation_coefficient, x, probability))\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break\n",
        "\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "if significant_rows:\n",
        "    significant_rows = significant_rows[:-1]\n",
        "\n",
        "with open(\"sig_spearman_enzymes.txt\", \"w\") as file:\n",
        "    for row_index, first_value, correlation_coefficient, x, probability in significant_rows:\n",
        "        file.write(f\"Enzyme = {first_value}, Correlation = {correlation_coefficient}\\n\")\n",
        "        #, x = {y_values}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = spearmanr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    x = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - stats.t.cdf(x, degrees_of_freedom)\n",
        "    return x, probability\n",
        "\n",
        "degrees_of_freedom = 39\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "for row_index in range(len(release_df)):\n",
        "    x_values = [release_df.iloc[row_index][str(second_value)] for second_value in second_values]\n",
        "\n",
        "    desired_length = len(x_values)\n",
        "    y_values_resized = np.resize(y_values, desired_length)\n",
        "\n",
        "    correlation_coefficient = calculate_correlation(x_values, y_values_resized)\n",
        "    correlation_coefficients[row_index] = correlation_coefficient\n",
        "\n",
        "    enzyme_name = release_df.iloc[row_index, 0]\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + x_values)\n",
        "\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "first_column_values = release_df.iloc[:, 0].values\n",
        "\n",
        "significant_rows = []\n",
        "total_probability = 0\n",
        "\n",
        "for row_index, correlation_coefficient in sorted_coefficients:\n",
        "    first_value = first_column_values[row_index]\n",
        "    x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append((row_index, first_value, correlation_coefficient, x, probability))\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break\n",
        "\n",
        "with open(\"sig_spearman_enzymes.txt\", \"w\") as file:\n",
        "    for row_index, first_value, correlation_coefficient, x, probability in significant_rows:\n",
        "        file.write(f\"Enzyme = {first_value}, Correlation = {correlation_coefficient}, t-dist = {x}, p-value = {probability}\\n\")\n"
      ],
      "metadata": {
        "id": "1LVfN1nlcgQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20a0081-1e76-41d1-adbf-994be90aa9c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-13-388148310.py:17: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
            "/tmp/ipython-input-13-388148310.py:7: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  correlation_coefficient, _ = spearmanr(x_values, y_values)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I_RWlEao3u20"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open('all_spearman_correlations.txt', 'r') as input_file:\n",
        "    with open('all_spearman_correlations.tab', 'w', newline='') as tab_output_file:\n",
        "        tab_writer = csv.writer(tab_output_file, delimiter='\\t')\n",
        "        tab_writer.writerow(['Enzyme', 'Correlation'])\n",
        "\n",
        "        with open('all_spearman_correlations.csv', 'w', newline='') as csv_output_file:\n",
        "            csv_writer = csv.writer(csv_output_file)\n",
        "            csv_writer.writerow(['Enzyme', 'Correlation'])\n",
        "\n",
        "            for line in input_file:\n",
        "                line = line.strip()\n",
        "                parts = line.split(',')\n",
        "\n",
        "                if len(parts) == 2:\n",
        "                    enzyme = parts[0].split('=')[1].strip()\n",
        "                    correlation = float(parts[1].split('=')[1].strip())\n",
        "                    tab_writer.writerow([enzyme, correlation])\n",
        "                    csv_writer.writerow([enzyme, correlation])\n",
        "\n",
        "with open('sig_spearman_enzymes.txt', 'r') as infile:\n",
        "    lines = infile.readlines()\n",
        "\n",
        "    with open('sig_spearman_enzymes.tab', 'w', newline='') as tab_output_file:\n",
        "        tab_writer = csv.writer(tab_output_file, delimiter='\\t')\n",
        "        tab_writer.writerow(['Enzyme', 'Correlation'])\n",
        "\n",
        "        with open('sig_spearman_enzymes.csv', 'w', newline='') as csv_output_file:\n",
        "            csv_writer = csv.writer(csv_output_file)\n",
        "            csv_writer.writerow(['Enzyme', 'Correlation'])\n",
        "\n",
        "            for line in lines:\n",
        "                parts = line.strip().split(', ')\n",
        "                enzyme = parts[0].split(' = ')[1]\n",
        "                correlation = parts[1].split(' = ')[1]\n",
        "                tab_writer.writerow([enzyme, correlation])\n",
        "                csv_writer.writerow([enzyme, correlation])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX8fBmyP3W59"
      },
      "source": [
        "### Check for overlap in Pearson and Spearman correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8Y7ZLdXp3WIR"
      },
      "outputs": [],
      "source": [
        "pearson_data = {}\n",
        "with open('sig_pearson_enzymes.csv', 'r') as pearson_file:\n",
        "    reader = csv.reader(pearson_file)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        enzyme = row[0]\n",
        "        correlation = float(row[1])\n",
        "        pearson_data[enzyme] = correlation\n",
        "\n",
        "# Find overlapping enzymes\n",
        "overlap_data = []\n",
        "with open('sig_spearman_enzymes.csv', 'r') as spearman_file:\n",
        "    reader = csv.reader(spearman_file)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        enzyme = row[0]\n",
        "        spearman_correlation = float(row[1])\n",
        "\n",
        "        if enzyme in pearson_data:\n",
        "            pearson_correlation = pearson_data[enzyme]\n",
        "            overlap_data.append([enzyme, pearson_correlation, spearman_correlation])\n",
        "\n",
        "with open('enzyme_overlap.csv', 'w', newline='') as overlap_file:\n",
        "    writer = csv.writer(overlap_file)\n",
        "    writer.writerow(['Enzyme', 'Pearson_Correlation', 'Spearman_Correlation'])\n",
        "    for row in overlap_data:\n",
        "        writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfy-wtenV0fL"
      },
      "source": [
        "# Combination Analysis using Pearson Correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7iyQocwmsHN"
      },
      "source": [
        "### Mean and Standard Deviation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TVb0gJ26Mcot"
      },
      "outputs": [],
      "source": [
        "enzyme_names = []\n",
        "with open('sig_pearson_enzymes.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        enzyme = line.split('=')[1].split(',')[0].strip()\n",
        "        enzyme_names.append(enzyme)\n",
        "\n",
        "with open('TARA243.KO.profile.release', 'r') as release_file, open('updated_releasefile.txt', 'w') as updated_file:\n",
        "    first_row = release_file.readline()\n",
        "    updated_file.write(first_row)\n",
        "\n",
        "    for line in release_file:\n",
        "        data = line.split()\n",
        "        if data[0] in enzyme_names:\n",
        "            updated_file.write(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0aL1a2n-JXQC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38bbc58-b95d-4f11-ae51-3b8be61be285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-17-2330570743.py:12: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True)\n"
          ]
        }
      ],
      "source": [
        "# Calculate the mean and standard deviation\n",
        "import pandas as pd\n",
        "\n",
        "# get enzyme names from significant enzymes file\n",
        "enzyme_names = []\n",
        "with open(\"sig_pearson_enzymes.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        enzyme = line.split(' ')[2].replace(\",\", \"\")\n",
        "        enzyme_names.append(enzyme)\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True)\n",
        "\n",
        "enzyme_rows = {enzyme: [] for enzyme in enzyme_names}\n",
        "\n",
        "for enzyme in enzyme_names:\n",
        "    enzyme_rows[enzyme] = release_df[release_df['ko'].str.contains(enzyme)]\n",
        "\n",
        "with open(\"p_mean&sd.txt\", \"w\") as file:\n",
        "    for enzyme, rows in enzyme_rows.items():\n",
        "        means = rows.iloc[:, 1:].mean(axis=1)\n",
        "        std_devs = rows.iloc[:, 1:].std(axis=1)\n",
        "        for index, (mean, std_dev) in enumerate(zip(means, std_devs)):\n",
        "            file.write(f\"Enzyme: {enzyme} Mean: {mean} Standard Deviation: {std_dev}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LjWqsBQlXnhb"
      },
      "outputs": [],
      "source": [
        "# Normalize abundance data using significant enzyme's mean and sd\n",
        "import pandas as pd\n",
        "\n",
        "mean_sd_values = {}\n",
        "with open(\"p_mean&sd.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        data = line.split()\n",
        "        enzyme = data[1]\n",
        "        mean = float(data[3])\n",
        "        std_dev = float(data[6])\n",
        "        mean_sd_values[enzyme] = {'mean': mean, 'std_dev': std_dev}\n",
        "\n",
        "normalized_values = []\n",
        "with open(\"updated_releasefile.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        data = line.split()\n",
        "        enzyme = data[0]  # enzyme name should be the first column value\n",
        "\n",
        "        if enzyme in mean_sd_values:\n",
        "            mean = mean_sd_values[enzyme]['mean']\n",
        "            std_dev = mean_sd_values[enzyme]['std_dev']\n",
        "\n",
        "            # Normalize each value in the row using its corresponding mean and std dev\n",
        "            normalized_row = [f\"{(float(value) - mean) / std_dev}\" for value in data[1:]]\n",
        "            normalized_values.append([enzyme] + normalized_row)\n",
        "\n",
        "with open('TARA243.KO.profile.release', 'r') as release_file:\n",
        "    first_row = release_file.readline()\n",
        "\n",
        "with open('p_normalized_releasefile.txt', 'w') as normalized_file:\n",
        "    normalized_file.write(first_row)\n",
        "    for row in normalized_values:\n",
        "        normalized_file.write('\\t'.join(row) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Q9Y0Esjk7JHS"
      },
      "outputs": [],
      "source": [
        "#Remove non-related samples\n",
        "\n",
        "sample_names = []\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    lines = mapped_file.readlines()\n",
        "    for line in lines:\n",
        "        sample_name = line.split('\\t')[1].strip()\n",
        "        sample_names.append(sample_name)\n",
        "\n",
        "with open('p_normalized_releasefile.txt', 'r') as release_file, open('p_related_samples_normalized.txt', 'w') as sorted_file:\n",
        "    first_row = release_file.readline()\n",
        "\n",
        "    first_column_index = 0\n",
        "    indices = [i for i, name in enumerate(first_row.split('\\t')) if name.strip() in sample_names]\n",
        "\n",
        "    sorted_file.write('\\t'.join(first_row.split('\\t')[i] for i in indices))\n",
        "\n",
        "    for line in release_file:\n",
        "        data = line.split('\\t')\n",
        "        sorted_file.write(data[first_column_index] + '\\t' + '\\t'.join(data[i] for i in indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uONLgUYjCKK4"
      },
      "outputs": [],
      "source": [
        "# sort based on the number of positive numbers in each row from highest to lowest\n",
        "def count_positive(row):\n",
        "    return sum(1 for value in row.split('\\t')[1:] if float(value) > 0)\n",
        "\n",
        "data_rows = []\n",
        "with open('p_related_samples_normalized.txt', 'r') as sorted_file:\n",
        "    header = sorted_file.readline()\n",
        "\n",
        "    for line in sorted_file:\n",
        "        data_rows.append(line)\n",
        "\n",
        "sorted_rows = sorted(data_rows, key=count_positive, reverse=True)\n",
        "\n",
        "with open('p_sorted_normalized.txt', 'w') as output_file:\n",
        "    output_file.write(header)\n",
        "    for row in sorted_rows:\n",
        "        output_file.write(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7B19PWTlSM7e"
      },
      "outputs": [],
      "source": [
        "# find enzymes that have at least n positive values in their row\n",
        "n = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('p_sorted_normalized.txt', 'r') as input_file, open('p_single.txt', 'w') as output_file:\n",
        "    first_row = input_file.readline()\n",
        "    output_file.write(first_row)\n",
        "\n",
        "    for line in input_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        count_positives = sum(float(value) > 0 for value in values[1:])\n",
        "\n",
        "        if count_positives >= n:\n",
        "            output_file.write(line)"
      ],
      "metadata": {
        "id": "KDWbty_zhFTZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsJkoO-wibRY"
      },
      "source": [
        "### Combination of 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2A4awV1B9uR9"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "# Finding combos enzymes that have at least n matching positive values\n",
        "n = 10\n",
        "\n",
        "with open('p_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('p_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('p_combo2.txt', 'w') as output_file, open('p_Wilcoxon_y-values2.txt', 'w') as y_file, open('p_Wilcoxon_y-samples2.txt', 'w') as samples_file:\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Pair', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for i in range(num_rows - 1):\n",
        "            for j in range(i + 1, num_rows):\n",
        "                count_matches = 0\n",
        "                positive_values = []\n",
        "\n",
        "                for k in range(1, len(sample_names) + 1):\n",
        "                    value_i = float(lines[i].strip().split('\\t')[k])\n",
        "                    value_j = float(lines[j].strip().split('\\t')[k])\n",
        "\n",
        "                    if value_i > 0 and value_j > 0:\n",
        "                        count_matches += 1\n",
        "                        positive_values.append(f'{value_i}, {value_j}')\n",
        "\n",
        "                if count_matches >= n:\n",
        "                    sample1 = lines[i].strip().split('\\t')[0]\n",
        "                    sample2 = lines[j].strip().split('\\t')[0]\n",
        "\n",
        "                    # Get the percentage for each enzyme from the dictionary\n",
        "                    percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                    percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "\n",
        "                    # Calculate the fraction based on the percentage of positive values\n",
        "                    fraction = percentage_sample1 * percentage_sample2\n",
        "\n",
        "                    # Calculate the distribution\n",
        "                    distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "\n",
        "                    # Calculate the p-value (sum of binomial probabilities from k to 41)\n",
        "                    p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                    if p_value < 0.01:\n",
        "                        output_file.write(f'{sample1}\\t{sample2}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                        pair_name = f'{sample1}-{sample2}'\n",
        "                        values_str = ', '.join(positive_values)\n",
        "                        y_file.write(f'{pair_name}\\t{values_str}\\n')\n",
        "\n",
        "                        # Replace each positive value with its corresponding sample name\n",
        "                        for idx, value in enumerate(positive_values):\n",
        "                            sample_name = sample_names[idx]\n",
        "                            values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                        samples_file.write(f'{pair_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0carxy3vw6YX"
      },
      "outputs": [],
      "source": [
        "# Take out positive values that are not in Wilcoxon_y-values2.txt and only in single.txt\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values2.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[pair_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values2.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for pair_name, y_positive_values in y_values.items():\n",
        "        sample_names = pair_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{pair_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_mG5y9ycvHzO"
      },
      "outputs": [],
      "source": [
        "# Replace positive x values with sample names\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values2.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[pair_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values2.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Pair', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for pair_name, y_positive_values in y_values.items():\n",
        "        sample_names = pair_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) - 1]\n",
        "                    x_output_file.write(f'{pair_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8kOe9qEsr9zm"
      },
      "outputs": [],
      "source": [
        "# Replace sample names with pollution data from mapped.txt and perform Mann U Whitney Test\n",
        "\n",
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples2.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[pair_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values2.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{pair_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "with open('p_MannU2.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        pair_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(pair_name, [])\n",
        "\n",
        "        # Mann-Whitney U test\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{pair_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0lDrOjLW4i0p"
      },
      "outputs": [],
      "source": [
        "# Open MannU2.txt and copy the enzyme pairs with p-values less than 0.1 for both enzymes to sig_combo2.txt\n",
        "with open('p_MannU2.txt', 'r') as mann_u_file, open('p_sig_combo2.txt', 'w') as output_file:\n",
        "\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "\n",
        "        if mann_u_value < 0.1:\n",
        "            next_values = next(mann_u_file, None)\n",
        "            if next_values is not None:\n",
        "                next_values = next_values.strip().split('\\t')\n",
        "                next_enzyme_name = next_values[1]\n",
        "                next_mann_u_value = float(next_values[2])\n",
        "\n",
        "                if next_mann_u_value < 0.1:\n",
        "                    output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                    output_file.write('\\t'.join([enzyme_pair, next_enzyme_name, str(next_mann_u_value)]) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKnraHYfqtex"
      },
      "source": [
        "### Combo3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MVO7H-53x46P"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "from itertools import combinations\n",
        "\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "with open('p_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('p_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('p_combo3.txt', 'w') as output_file, open('p_Wilcoxon_y-values3.txt', 'w') as y_file, open('p_Wilcoxon_y-samples3.txt', 'w') as samples_file:\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Trio', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for combo in combinations(range(num_rows), 3):\n",
        "            i, j, k = combo\n",
        "\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "\n",
        "            for m in range(1, len(sample_names) + 1):\n",
        "                value_i = float(lines[i].strip().split('\\t')[m])\n",
        "                value_j = float(lines[j].strip().split('\\t')[m])\n",
        "                value_k = float(lines[k].strip().split('\\t')[m])\n",
        "\n",
        "                if all(value > 0 for value in [value_i, value_j, value_k]):\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(f'{value_i}, {value_j}, {value_k}')\n",
        "\n",
        "            if count_matches >= n:\n",
        "                sample1 = lines[i].strip().split('\\t')[0]\n",
        "                sample2 = lines[j].strip().split('\\t')[0]\n",
        "                sample3 = lines[k].strip().split('\\t')[0]\n",
        "\n",
        "                percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "                percentage_sample3 = enzyme_percentages.get(sample3, 0)\n",
        "\n",
        "                fraction = percentage_sample1 * percentage_sample2 * percentage_sample3\n",
        "\n",
        "                distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "\n",
        "                p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                if p_value < 0.01:\n",
        "                    output_file.write(f'{sample1}\\t{sample2}\\t{sample3}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                    trio_name = f'{sample1}-{sample2}-{sample3}'\n",
        "                    values_str = ', '.join(positive_values)\n",
        "                    y_file.write(f'{trio_name}\\t{values_str}\\n')\n",
        "\n",
        "                    for idx, value in enumerate(positive_values):\n",
        "                        sample_name = sample_names[idx]\n",
        "                        values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                    samples_file.write(f'{trio_name}\\t{values_str}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0DZYOFRnuPVN"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values3.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = set(values_str.split(', '))\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values3.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - y_positive_values\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{set_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PMdsQOiu4k0U"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values3.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values3.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) -1]\n",
        "                    x_output_file.write(f'{set_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MjTKb40z61ig"
      },
      "outputs": [],
      "source": [
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples3.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[set_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values3.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{set_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "with open('p_MannU3.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Set', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        set_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(set_name, [])\n",
        "\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{set_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lfb-72mj4b66"
      },
      "outputs": [],
      "source": [
        "with open('p_MannU3.txt', 'r') as mann_u_file, open('p_sig_combo3.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3yYZ0UcwHZo"
      },
      "source": [
        "### Combo4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9m1Z6JuEemqX"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "from itertools import combinations\n",
        "\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "with open('p_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243  # Assuming 243 as the total number of values\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('p_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('p_combo4.txt', 'w') as output_file, open('p_Wilcoxon_y-values4.txt', 'w') as y_file, open('p_Wilcoxon_y-samples4.txt', 'w') as samples_file:\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Quadruplet', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for combo in combinations(range(num_rows), 4):\n",
        "            i, j, k, l = combo\n",
        "\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "\n",
        "            for m in range(1, len(sample_names) + 1):\n",
        "                value_i = float(lines[i].strip().split('\\t')[m])\n",
        "                value_j = float(lines[j].strip().split('\\t')[m])\n",
        "                value_k = float(lines[k].strip().split('\\t')[m])\n",
        "                value_l = float(lines[l].strip().split('\\t')[m])\n",
        "\n",
        "                if all(value > 0 for value in [value_i, value_j, value_k, value_l]):\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(f'{value_i}, {value_j}, {value_k}, {value_l}')\n",
        "\n",
        "            if count_matches >= n:\n",
        "                sample1 = lines[i].strip().split('\\t')[0]\n",
        "                sample2 = lines[j].strip().split('\\t')[0]\n",
        "                sample3 = lines[k].strip().split('\\t')[0]\n",
        "                sample4 = lines[l].strip().split('\\t')[0]\n",
        "\n",
        "                percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "                percentage_sample3 = enzyme_percentages.get(sample3, 0)\n",
        "                percentage_sample4 = enzyme_percentages.get(sample4, 0)\n",
        "\n",
        "                # Calculate the fraction based on the percentage of positive values\n",
        "                fraction = percentage_sample1 * percentage_sample2 * percentage_sample3 * percentage_sample4\n",
        "\n",
        "                # Calculate the distribution\n",
        "                distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "\n",
        "                p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                if p_value < 0.01:\n",
        "                    output_file.write(f'{sample1}\\t{sample2}\\t{sample3}\\t{sample4}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                    quadruplet_name = f'{sample1}-{sample2}-{sample3}-{sample4}'\n",
        "                    values_str = ', '.join(positive_values)\n",
        "                    y_file.write(f'{quadruplet_name}\\t{values_str}\\n')\n",
        "\n",
        "                    for idx, value in enumerate(positive_values):\n",
        "                        sample_name = sample_names[idx]\n",
        "                        values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                    samples_file.write(f'{quadruplet_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NuF2Zk1jMDAg"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values4.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = set(values_str.split(', '))\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values4.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - y_positive_values\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{set_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6Vj90Jz8N1Go"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values4.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values4.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) - 1]\n",
        "                    x_output_file.write(f'{set_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zzFdHyn5O62i"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples4.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[set_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values4.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{set_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "with open('p_MannU4.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Set', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        set_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(set_name, [])\n",
        "\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{set_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "1tW4SGKX4ST_"
      },
      "outputs": [],
      "source": [
        "with open('p_MannU4.txt', 'r') as mann_u_file, open('p_sig_combo4.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "        next_values_4 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None and next_values_4 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "            next_values_4 = next_values_4.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            next_enzyme_name_4 = next_values_4[1]\n",
        "            next_mann_u_value_4 = float(next_values_4[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1 and next_mann_u_value_4 < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_4, str(next_mann_u_value_4)]) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucyyIfieKjoh"
      },
      "source": [
        "### Combo5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8dlk-ur_ZJ-f"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "from itertools import combinations\n",
        "\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "with open('p_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('p_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('p_combo5.txt', 'w') as output_file, open('p_Wilcoxon_y-values5.txt', 'w') as y_file, open('p_Wilcoxon_y-samples5.txt', 'w') as samples_file:\n",
        "\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Enzyme5', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Quintuplet', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for combo in combinations(range(num_rows), 5):\n",
        "            i, j, k, l, m = combo\n",
        "\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "\n",
        "            for a in range(1, len(sample_names) + 1):\n",
        "                value_i = float(lines[i].strip().split('\\t')[a])\n",
        "                value_j = float(lines[j].strip().split('\\t')[a])\n",
        "                value_k = float(lines[k].strip().split('\\t')[a])\n",
        "                value_l = float(lines[l].strip().split('\\t')[a])\n",
        "                value_m = float(lines[m].strip().split('\\t')[a])\n",
        "\n",
        "                if all(value > 0 for value in [value_i, value_j, value_k, value_l, value_m]):\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(f'{value_i}, {value_j}, {value_k}, {value_l}, {value_m}')\n",
        "\n",
        "            if count_matches >= n:\n",
        "                sample1 = lines[i].strip().split('\\t')[0]\n",
        "                sample2 = lines[j].strip().split('\\t')[0]\n",
        "                sample3 = lines[k].strip().split('\\t')[0]\n",
        "                sample4 = lines[l].strip().split('\\t')[0]\n",
        "                sample5 = lines[m].strip().split('\\t')[0]\n",
        "\n",
        "                percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "                percentage_sample3 = enzyme_percentages.get(sample3, 0)\n",
        "                percentage_sample4 = enzyme_percentages.get(sample4, 0)\n",
        "                percentage_sample5 = enzyme_percentages.get(sample5, 0)\n",
        "\n",
        "                fraction = percentage_sample1 * percentage_sample2 * percentage_sample3 * percentage_sample4 * percentage_sample5\n",
        "                distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "                p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                if p_value < 0.01:\n",
        "                    output_file.write(f'{sample1}\\t{sample2}\\t{sample3}\\t{sample4}\\t{sample5}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                    quintuplet_name = f'{sample1}-{sample2}-{sample3}-{sample4}-{sample5}'\n",
        "                    values_str = ', '.join(positive_values)\n",
        "                    y_file.write(f'{quintuplet_name}\\t{values_str}\\n')\n",
        "\n",
        "                    for idx, value in enumerate(positive_values):\n",
        "                        sample_name = sample_names[idx]\n",
        "                        values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                    samples_file.write(f'{quintuplet_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EaakrzaKbLIH"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values5.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = set(values_str.split(', '))\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values5.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - y_positive_values\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{set_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "psL7OMaObfda"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values5.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values5.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) - 1]\n",
        "                    x_output_file.write(f'{set_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "V8Vbnb2ZcBrB"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples5.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[set_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values5.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{set_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "with open('p_MannU5.txt', 'w') as mann_u_file:\n",
        "\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Set', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        set_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(set_name, [])\n",
        "\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{set_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "pmBSS-6y4OZ5"
      },
      "outputs": [],
      "source": [
        "with open('p_MannU5.txt', 'r') as mann_u_file, open('p_sig_combo5.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "        next_values_4 = next(mann_u_file, None)\n",
        "        next_values_5 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None and next_values_4 is not None and next_values_5 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "            next_values_4 = next_values_4.strip().split('\\t')\n",
        "            next_values_5 = next_values_5.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            next_enzyme_name_4 = next_values_4[1]\n",
        "            next_mann_u_value_4 = float(next_values_4[2])\n",
        "\n",
        "            next_enzyme_name_5 = next_values_5[1]\n",
        "            next_mann_u_value_5 = float(next_values_5[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1 and next_mann_u_value_4 < 0.1 and next_mann_u_value_5 < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_4, str(next_mann_u_value_4)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_5, str(next_mann_u_value_5)]) + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbsaL8mLKom0"
      },
      "source": [
        "### Combo6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmFq3ZbIfPYr"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "from itertools import combinations\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "with open('p_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('p_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('p_combo6.txt', 'w') as output_file, open('p_Wilcoxon_y-values6.txt', 'w') as y_file, open('p_Wilcoxon_y-samples6.txt', 'w') as samples_file:\n",
        "\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Enzyme5', 'Enzyme6', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Set', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for combo in combinations(range(num_rows), 6):\n",
        "            i, j, k, l, m, o = combo\n",
        "\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "\n",
        "            for a in range(1, len(sample_names) + 1):\n",
        "                value_i = float(lines[i].strip().split('\\t')[a])\n",
        "                value_j = float(lines[j].strip().split('\\t')[a])\n",
        "                value_k = float(lines[k].strip().split('\\t')[a])\n",
        "                value_l = float(lines[l].strip().split('\\t')[a])\n",
        "                value_m = float(lines[m].strip().split('\\t')[a])\n",
        "                value_o = float(lines[o].strip().split('\\t')[a])\n",
        "\n",
        "                if all(value > 0 for value in [value_i, value_j, value_k, value_l, value_m, value_o]):\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(f'{value_i}, {value_j}, {value_k}, {value_l}, {value_m}, {value_o}')\n",
        "\n",
        "            if count_matches >= n:\n",
        "                sample1 = lines[i].strip().split('\\t')[0]\n",
        "                sample2 = lines[j].strip().split('\\t')[0]\n",
        "                sample3 = lines[k].strip().split('\\t')[0]\n",
        "                sample4 = lines[l].strip().split('\\t')[0]\n",
        "                sample5 = lines[m].strip().split('\\t')[0]\n",
        "                sample6 = lines[o].strip().split('\\t')[0]\n",
        "\n",
        "                percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "                percentage_sample3 = enzyme_percentages.get(sample3, 0)\n",
        "                percentage_sample4 = enzyme_percentages.get(sample4, 0)\n",
        "                percentage_sample5 = enzyme_percentages.get(sample5, 0)\n",
        "                percentage_sample6 = enzyme_percentages.get(sample6, 0)\n",
        "\n",
        "                fraction = percentage_sample1 * percentage_sample2 * percentage_sample3 * percentage_sample4 * percentage_sample5 * percentage_sample6\n",
        "\n",
        "                distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "\n",
        "                p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                if p_value < 0.01:\n",
        "                    output_file.write(f'{sample1}\\t{sample2}\\t{sample3}\\t{sample4}\\t{sample5}\\t{sample6}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                    set_name = f'{sample1}-{sample2}-{sample3}-{sample4}-{sample5}-{sample6}'\n",
        "                    values_str = ', '.join(positive_values)\n",
        "                    y_file.write(f'{set_name}\\t{values_str}\\n')\n",
        "\n",
        "                    for idx, value in enumerate(positive_values):\n",
        "                        sample_name = sample_names[idx]\n",
        "                        values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                    samples_file.write(f'{set_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_vLLpKkK9pE"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values6.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = set(values_str.split(', '))\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values6.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - y_positive_values\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{set_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOriDEMsu4Z6"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values6.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('p_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('p_Wilcoxon_x-values6.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) - 1]\n",
        "                    x_output_file.write(f'{set_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkXJQHO9Q3is"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples6.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[set_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values6.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{set_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "with open('p_MannU6.txt', 'w') as mann_u_file:\n",
        "\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Set', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "\n",
        "        set_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(set_name, [])\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{set_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1LYFrti2aUe"
      },
      "outputs": [],
      "source": [
        "with open('p_MannU6.txt', 'r') as mann_u_file, open('p_sig_combo6.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "        next_values_4 = next(mann_u_file, None)\n",
        "        next_values_5 = next(mann_u_file, None)\n",
        "        next_values_6 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None and next_values_4 is not None and next_values_5 is not None and next_values_6 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "            next_values_4 = next_values_4.strip().split('\\t')\n",
        "            next_values_5 = next_values_5.strip().split('\\t')\n",
        "            next_values_6 = next_values_6.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            next_enzyme_name_4 = next_values_4[1]\n",
        "            next_mann_u_value_4 = float(next_values_4[2])\n",
        "\n",
        "            next_enzyme_name_5 = next_values_5[1]\n",
        "            next_mann_u_value_5 = float(next_values_5[2])\n",
        "\n",
        "            next_enzyme_name_6 = next_values_6[1]\n",
        "            next_mann_u_value_6 = float(next_values_6[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1 and next_mann_u_value_4 < 0.1 and next_mann_u_value_5 < 0.1 and next_mann_u_value_6 < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_4, str(next_mann_u_value_4)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_5, str(next_mann_u_value_5)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_6, str(next_mann_u_value_6)]) + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMGJzyJBWD-V"
      },
      "source": [
        "# Combination Analysis using Spearman Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1HyqUvpXL3Z"
      },
      "source": [
        "### Mean and Standard Deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_pHrc7SWAc1"
      },
      "outputs": [],
      "source": [
        "enzyme_names = []\n",
        "with open('sig_spearman_enzymes.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        enzyme = line.split('=')[1].split(',')[0].strip()\n",
        "        enzyme_names.append(enzyme)\n",
        "\n",
        "with open('TARA243.KO.profile.release', 'r') as release_file, open('updated_releasefile.txt', 'w') as updated_file:\n",
        "    first_row = release_file.readline()\n",
        "    updated_file.write(first_row)\n",
        "\n",
        "    for line in release_file:\n",
        "        data = line.split()\n",
        "        if data[0] in enzyme_names:\n",
        "            updated_file.write(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltXNfPqXWXTM"
      },
      "outputs": [],
      "source": [
        "enzyme_names = []\n",
        "with open(\"sig_spearman_enzymes.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        enzyme = line.split(' ')[2].replace(\",\", \"\")\n",
        "        enzyme_names.append(enzyme)\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True)\n",
        "\n",
        "enzyme_rows = {enzyme: [] for enzyme in enzyme_names}\n",
        "\n",
        "for enzyme in enzyme_names:\n",
        "    enzyme_rows[enzyme] = release_df[release_df['ko'].str.contains(enzyme)]\n",
        "\n",
        "with open(\"s_mean&sd.txt\", \"w\") as file:\n",
        "    for enzyme, rows in enzyme_rows.items():\n",
        "        means = rows.iloc[:, 1:].mean(axis=1)\n",
        "        std_devs = rows.iloc[:, 1:].std(axis=1)\n",
        "        for index, (mean, std_dev) in enumerate(zip(means, std_devs)):\n",
        "            file.write(f\"Enzyme: {enzyme} Mean: {mean} Standard Deviation: {std_dev}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRpOKFuuWedc"
      },
      "outputs": [],
      "source": [
        "mean_sd_values = {}\n",
        "with open(\"s_mean&sd.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        data = line.split()\n",
        "        enzyme = data[1]\n",
        "        mean = float(data[3])\n",
        "        std_dev = float(data[6])\n",
        "        mean_sd_values[enzyme] = {'mean': mean, 'std_dev': std_dev}\n",
        "\n",
        "normalized_values = []\n",
        "with open(\"updated_releasefile.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        data = line.split()\n",
        "        enzyme = data[0]\n",
        "\n",
        "        if enzyme in mean_sd_values:\n",
        "            mean = mean_sd_values[enzyme]['mean']\n",
        "            std_dev = mean_sd_values[enzyme]['std_dev']\n",
        "            normalized_row = [f\"{(float(value) - mean) / std_dev}\" for value in data[1:]]\n",
        "            normalized_values.append([enzyme] + normalized_row)\n",
        "\n",
        "with open('TARA243.KO.profile.release', 'r') as release_file:\n",
        "    first_row = release_file.readline()\n",
        "\n",
        "with open('s_normalized_releasefile.txt', 'w') as normalized_file:\n",
        "    normalized_file.write(first_row)\n",
        "\n",
        "    for row in normalized_values:\n",
        "        normalized_file.write('\\t'.join(row) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1phz5eGWsCT"
      },
      "outputs": [],
      "source": [
        "sample_names = []\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    lines = mapped_file.readlines()\n",
        "    for line in lines:\n",
        "        sample_name = line.split('\\t')[1].strip()\n",
        "        sample_names.append(sample_name)\n",
        "\n",
        "with open('s_normalized_releasefile.txt', 'r') as release_file, open('s_related_samples_normalized.txt', 'w') as sorted_file:\n",
        "\n",
        "    first_row = release_file.readline()\n",
        "    first_column_index = 0\n",
        "    indices = [i for i, name in enumerate(first_row.split('\\t')) if name.strip() in sample_names]\n",
        "    sorted_file.write('\\t'.join(first_row.split('\\t')[i] for i in indices))\n",
        "\n",
        "    for line in release_file:\n",
        "        data = line.split('\\t')\n",
        "        sorted_file.write(data[first_column_index] + '\\t' + '\\t'.join(data[i] for i in indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "281Oy6ZcW4QK"
      },
      "outputs": [],
      "source": [
        "def count_positive(row):\n",
        "    return sum(1 for value in row.split('\\t')[1:] if float(value) > 0)\n",
        "\n",
        "data_rows = []\n",
        "with open('s_related_samples_normalized.txt', 'r') as sorted_file:\n",
        "\n",
        "    header = sorted_file.readline()\n",
        "    for line in sorted_file:\n",
        "        data_rows.append(line)\n",
        "\n",
        "sorted_rows = sorted(data_rows, key=count_positive, reverse=True)\n",
        "\n",
        "with open('s_sorted_normalized.txt', 'w') as output_file:\n",
        "\n",
        "    output_file.write(header)\n",
        "\n",
        "    for row in sorted_rows:\n",
        "        output_file.write(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Slr2YhU9XAtv"
      },
      "outputs": [],
      "source": [
        "# Finding enzymes that have at least n positive values in their row\n",
        "n = 10\n",
        "\n",
        "with open('s_sorted_normalized.txt', 'r') as input_file, open('s_single.txt', 'w') as output_file:\n",
        "    first_row = input_file.readline()\n",
        "    output_file.write(first_row)\n",
        "\n",
        "    for line in input_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        count_positives = sum(float(value) > 0 for value in values[1:])\n",
        "\n",
        "        if count_positives >= n:\n",
        "            output_file.write(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCqAffZZXQSe"
      },
      "source": [
        "### Combo2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2prZXjL_XRZh"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "n = 10\n",
        "\n",
        "with open('s_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('s_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('s_combo2.txt', 'w') as output_file, open('s_Wilcoxon_y-values2.txt', 'w') as y_file, open('s_Wilcoxon_y-samples2.txt', 'w') as samples_file:\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Pair', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for i in range(num_rows - 1):\n",
        "            for j in range(i + 1, num_rows):\n",
        "                count_matches = 0\n",
        "                positive_values = []\n",
        "\n",
        "                for k in range(1, len(sample_names) + 1):\n",
        "                    value_i = float(lines[i].strip().split('\\t')[k])\n",
        "                    value_j = float(lines[j].strip().split('\\t')[k])\n",
        "\n",
        "                    if value_i > 0 and value_j > 0:\n",
        "                        count_matches += 1\n",
        "                        positive_values.append(f'{value_i}, {value_j}')\n",
        "\n",
        "                if count_matches >= n:\n",
        "                    sample1 = lines[i].strip().split('\\t')[0]\n",
        "                    sample2 = lines[j].strip().split('\\t')[0]\n",
        "\n",
        "                    percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                    percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "\n",
        "                    fraction = percentage_sample1 * percentage_sample2\n",
        "                    distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "                    p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                    if p_value < 0.01:\n",
        "                        output_file.write(f'{sample1}\\t{sample2}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                        pair_name = f'{sample1}-{sample2}'\n",
        "                        values_str = ', '.join(positive_values)\n",
        "                        y_file.write(f'{pair_name}\\t{values_str}\\n')\n",
        "\n",
        "                        for idx, value in enumerate(positive_values):\n",
        "                            sample_name = sample_names[idx]\n",
        "                            values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                        samples_file.write(f'{pair_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxwJ7YuXXlU6"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values2.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[pair_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values2.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for pair_name, y_positive_values in y_values.items():\n",
        "        sample_names = pair_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{pair_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a_heqbrXurQ"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values2.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[pair_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values2.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Pair', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for pair_name, y_positive_values in y_values.items():\n",
        "        sample_names = pair_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) - 1]  # Shift the index by one\n",
        "                    x_output_file.write(f'{pair_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75aJOStYX1Lp"
      },
      "outputs": [],
      "source": [
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples2.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[pair_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values2.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{pair_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "with open('s_MannU2.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        pair_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(pair_name, [])\n",
        "\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{pair_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8BYJBCAX574"
      },
      "outputs": [],
      "source": [
        "with open('s_MannU2.txt', 'r') as mann_u_file, open('s_sig_combo2.txt', 'w') as output_file:\n",
        "\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "\n",
        "        if mann_u_value < 0.1:\n",
        "            next_values = next(mann_u_file, None)\n",
        "            if next_values is not None:\n",
        "                next_values = next_values.strip().split('\\t')\n",
        "                next_enzyme_name = next_values[1]\n",
        "                next_mann_u_value = float(next_values[2])\n",
        "\n",
        "                if next_mann_u_value < 0.1:\n",
        "                    output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                    output_file.write('\\t'.join([enzyme_pair, next_enzyme_name, str(next_mann_u_value)]) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbfrY09pYB1D"
      },
      "source": [
        "### Combo3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZHu7X73YCju"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "from itertools import combinations\n",
        "\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "with open('s_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('s_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('s_combo3.txt', 'w') as output_file, open('s_Wilcoxon_y-values3.txt', 'w') as y_file, open('s_Wilcoxon_y-samples3.txt', 'w') as samples_file:\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Trio', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for combo in combinations(range(num_rows), 3):\n",
        "            i, j, k = combo\n",
        "\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "\n",
        "            for m in range(1, len(sample_names) + 1):\n",
        "                value_i = float(lines[i].strip().split('\\t')[m])\n",
        "                value_j = float(lines[j].strip().split('\\t')[m])\n",
        "                value_k = float(lines[k].strip().split('\\t')[m])\n",
        "\n",
        "                if all(value > 0 for value in [value_i, value_j, value_k]):\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(f'{value_i}, {value_j}, {value_k}')\n",
        "\n",
        "            if count_matches >= n:\n",
        "                sample1 = lines[i].strip().split('\\t')[0]\n",
        "                sample2 = lines[j].strip().split('\\t')[0]\n",
        "                sample3 = lines[k].strip().split('\\t')[0]\n",
        "\n",
        "                percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "                percentage_sample3 = enzyme_percentages.get(sample3, 0)\n",
        "\n",
        "                fraction = percentage_sample1 * percentage_sample2 * percentage_sample3\n",
        "\n",
        "                distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "\n",
        "                p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                if p_value < 0.01:\n",
        "                    output_file.write(f'{sample1}\\t{sample2}\\t{sample3}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                    trio_name = f'{sample1}-{sample2}-{sample3}'\n",
        "                    values_str = ', '.join(positive_values)\n",
        "                    y_file.write(f'{trio_name}\\t{values_str}\\n')\n",
        "\n",
        "                    for idx, value in enumerate(positive_values):\n",
        "                        sample_name = sample_names[idx]\n",
        "                        values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                    samples_file.write(f'{trio_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyFErknCYKqE"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values3.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = set(values_str.split(', '))\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values3.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - y_positive_values\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{set_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_HxRZQ_YSsI"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values3.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values3.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) -1]\n",
        "                    x_output_file.write(f'{set_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co2FvyqoYXUP"
      },
      "outputs": [],
      "source": [
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples3.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[set_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values3.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{set_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "with open('s_MannU3.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Set', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        set_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(set_name, [])\n",
        "\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{set_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNf1SseTYgHp"
      },
      "outputs": [],
      "source": [
        "with open('s_MannU3.txt', 'r') as mann_u_file, open('s_sig_combo3.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZgQnxIYnIf"
      },
      "source": [
        "### Combo4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcFvzoZZYn-B"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "from itertools import combinations\n",
        "\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "with open('s_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243  # Assuming 243 as the total number of values\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('s_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('s_combo4.txt', 'w') as output_file, open('s_Wilcoxon_y-values4.txt', 'w') as y_file, open('s_Wilcoxon_y-samples4.txt', 'w') as samples_file:\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Quadruplet', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for combo in combinations(range(num_rows), 4):\n",
        "            i, j, k, l = combo\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "\n",
        "            for m in range(1, len(sample_names) + 1):\n",
        "                value_i = float(lines[i].strip().split('\\t')[m])\n",
        "                value_j = float(lines[j].strip().split('\\t')[m])\n",
        "                value_k = float(lines[k].strip().split('\\t')[m])\n",
        "                value_l = float(lines[l].strip().split('\\t')[m])\n",
        "\n",
        "                if all(value > 0 for value in [value_i, value_j, value_k, value_l]):\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(f'{value_i}, {value_j}, {value_k}, {value_l}')\n",
        "\n",
        "            if count_matches >= n:\n",
        "                sample1 = lines[i].strip().split('\\t')[0]\n",
        "                sample2 = lines[j].strip().split('\\t')[0]\n",
        "                sample3 = lines[k].strip().split('\\t')[0]\n",
        "                sample4 = lines[l].strip().split('\\t')[0]\n",
        "\n",
        "                percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "                percentage_sample3 = enzyme_percentages.get(sample3, 0)\n",
        "                percentage_sample4 = enzyme_percentages.get(sample4, 0)\n",
        "\n",
        "                fraction = percentage_sample1 * percentage_sample2 * percentage_sample3 * percentage_sample4\n",
        "                distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "                p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                if p_value < 0.01:\n",
        "                    output_file.write(f'{sample1}\\t{sample2}\\t{sample3}\\t{sample4}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                    quadruplet_name = f'{sample1}-{sample2}-{sample3}-{sample4}'\n",
        "                    values_str = ', '.join(positive_values)\n",
        "                    y_file.write(f'{quadruplet_name}\\t{values_str}\\n')\n",
        "\n",
        "                    for idx, value in enumerate(positive_values):\n",
        "                        sample_name = sample_names[idx]\n",
        "                        values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                    samples_file.write(f'{quadruplet_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8nAT32zY4FD"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values4.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = set(values_str.split(', '))\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values4.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - y_positive_values\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{set_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ67Rf0XY8Fp"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values4.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values4.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) - 1]\n",
        "                    x_output_file.write(f'{set_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esRkS_HQZGzU"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples4.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[set_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values4.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{set_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "with open('s_MannU4.txt', 'w') as mann_u_file:\n",
        "\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Set', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        set_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(set_name, [])\n",
        "\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{set_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMs4qGHNZMWX"
      },
      "outputs": [],
      "source": [
        "with open('s_MannU4.txt', 'r') as mann_u_file, open('s_sig_combo4.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "        next_values_4 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None and next_values_4 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "            next_values_4 = next_values_4.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            next_enzyme_name_4 = next_values_4[1]\n",
        "            next_mann_u_value_4 = float(next_values_4[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1 and next_mann_u_value_4 < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_4, str(next_mann_u_value_4)]) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnwwx_TCZQGD"
      },
      "source": [
        "### Combo5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZCOLe1BZZEr"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "from itertools import combinations\n",
        "\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "with open('s_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('s_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('s_combo5.txt', 'w') as output_file, open('s_Wilcoxon_y-values5.txt', 'w') as y_file, open('s_Wilcoxon_y-samples5.txt', 'w') as samples_file:\n",
        "\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Enzyme5', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Quintuplet', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for combo in combinations(range(num_rows), 5):\n",
        "            i, j, k, l, m = combo\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "\n",
        "            for a in range(1, len(sample_names) + 1):\n",
        "                value_i = float(lines[i].strip().split('\\t')[a])\n",
        "                value_j = float(lines[j].strip().split('\\t')[a])\n",
        "                value_k = float(lines[k].strip().split('\\t')[a])\n",
        "                value_l = float(lines[l].strip().split('\\t')[a])\n",
        "                value_m = float(lines[m].strip().split('\\t')[a])\n",
        "\n",
        "                if all(value > 0 for value in [value_i, value_j, value_k, value_l, value_m]):\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(f'{value_i}, {value_j}, {value_k}, {value_l}, {value_m}')\n",
        "\n",
        "            if count_matches >= n:\n",
        "                sample1 = lines[i].strip().split('\\t')[0]\n",
        "                sample2 = lines[j].strip().split('\\t')[0]\n",
        "                sample3 = lines[k].strip().split('\\t')[0]\n",
        "                sample4 = lines[l].strip().split('\\t')[0]\n",
        "                sample5 = lines[m].strip().split('\\t')[0]\n",
        "\n",
        "                percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "                percentage_sample3 = enzyme_percentages.get(sample3, 0)\n",
        "                percentage_sample4 = enzyme_percentages.get(sample4, 0)\n",
        "                percentage_sample5 = enzyme_percentages.get(sample5, 0)\n",
        "\n",
        "                fraction = percentage_sample1 * percentage_sample2 * percentage_sample3 * percentage_sample4 * percentage_sample5\n",
        "                distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "                p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                if p_value < 0.01:\n",
        "                    output_file.write(f'{sample1}\\t{sample2}\\t{sample3}\\t{sample4}\\t{sample5}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                    quintuplet_name = f'{sample1}-{sample2}-{sample3}-{sample4}-{sample5}'\n",
        "                    values_str = ', '.join(positive_values)\n",
        "                    y_file.write(f'{quintuplet_name}\\t{values_str}\\n')\n",
        "\n",
        "                    for idx, value in enumerate(positive_values):\n",
        "                        sample_name = sample_names[idx]\n",
        "                        values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                    samples_file.write(f'{quintuplet_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKt6ZtajZqqY"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values5.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = set(values_str.split(', '))\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values5.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - y_positive_values\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{set_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy1O5s67Z0J4"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values5.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values5.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) - 1]\n",
        "                    x_output_file.write(f'{set_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_2ygtZKZ2zX"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples5.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[set_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values5.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{set_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "with open('s_MannU5.txt', 'w') as mann_u_file:\n",
        "\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Set', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        set_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(set_name, [])\n",
        "\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{set_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdq0fODFZ878"
      },
      "outputs": [],
      "source": [
        "with open('s_MannU5.txt', 'r') as mann_u_file, open('s_sig_combo5.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "        next_values_4 = next(mann_u_file, None)\n",
        "        next_values_5 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None and next_values_4 is not None and next_values_5 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "            next_values_4 = next_values_4.strip().split('\\t')\n",
        "            next_values_5 = next_values_5.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            next_enzyme_name_4 = next_values_4[1]\n",
        "            next_mann_u_value_4 = float(next_values_4[2])\n",
        "\n",
        "            next_enzyme_name_5 = next_values_5[1]\n",
        "            next_mann_u_value_5 = float(next_values_5[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1 and next_mann_u_value_4 < 0.1 and next_mann_u_value_5 < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_4, str(next_mann_u_value_4)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_5, str(next_mann_u_value_5)]) + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn1u6B29Z-ng"
      },
      "source": [
        "### Combo6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPHK1V1EaOnU"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "from itertools import combinations\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "with open('s_normalized_releasefile.txt', 'r') as enzyme_file:\n",
        "    enzyme_names = enzyme_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    enzyme_percentages = {}\n",
        "    for line in enzyme_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_name = values[0]\n",
        "        positive_values = sum(1 for value in values[1:] if float(value) > 0)\n",
        "        percentage = positive_values / 243\n",
        "        enzyme_percentages[enzyme_name] = percentage\n",
        "\n",
        "with open('s_single.txt', 'r') as input_file:\n",
        "    sample_names = input_file.readline().strip().split('\\t')[1:]\n",
        "\n",
        "    with open('s_combo6.txt', 'w') as output_file, open('s_Wilcoxon_y-values6.txt', 'w') as y_file, open('s_Wilcoxon_y-samples6.txt', 'w') as samples_file:\n",
        "\n",
        "        output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Enzyme5', 'Enzyme6', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "        y_file.write('\\t'.join(['Enzyme Set', 'Values']) + '\\n')\n",
        "\n",
        "        lines = input_file.readlines()\n",
        "        num_rows = len(lines)\n",
        "\n",
        "        for combo in combinations(range(num_rows), 6):\n",
        "            i, j, k, l, m, o = combo\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "\n",
        "            for a in range(1, len(sample_names) + 1):\n",
        "                value_i = float(lines[i].strip().split('\\t')[a])\n",
        "                value_j = float(lines[j].strip().split('\\t')[a])\n",
        "                value_k = float(lines[k].strip().split('\\t')[a])\n",
        "                value_l = float(lines[l].strip().split('\\t')[a])\n",
        "                value_m = float(lines[m].strip().split('\\t')[a])\n",
        "                value_o = float(lines[o].strip().split('\\t')[a])\n",
        "\n",
        "                if all(value > 0 for value in [value_i, value_j, value_k, value_l, value_m, value_o]):\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(f'{value_i}, {value_j}, {value_k}, {value_l}, {value_m}, {value_o}')\n",
        "\n",
        "            if count_matches >= n:\n",
        "                sample1 = lines[i].strip().split('\\t')[0]\n",
        "                sample2 = lines[j].strip().split('\\t')[0]\n",
        "                sample3 = lines[k].strip().split('\\t')[0]\n",
        "                sample4 = lines[l].strip().split('\\t')[0]\n",
        "                sample5 = lines[m].strip().split('\\t')[0]\n",
        "                sample6 = lines[o].strip().split('\\t')[0]\n",
        "\n",
        "                percentage_sample1 = enzyme_percentages.get(sample1, 0)\n",
        "                percentage_sample2 = enzyme_percentages.get(sample2, 0)\n",
        "                percentage_sample3 = enzyme_percentages.get(sample3, 0)\n",
        "                percentage_sample4 = enzyme_percentages.get(sample4, 0)\n",
        "                percentage_sample5 = enzyme_percentages.get(sample5, 0)\n",
        "                percentage_sample6 = enzyme_percentages.get(sample6, 0)\n",
        "\n",
        "                fraction = percentage_sample1 * percentage_sample2 * percentage_sample3 * percentage_sample4 * percentage_sample5 * percentage_sample6\n",
        "                distribution = calculate_binomial_distribution(count_matches, 41, fraction)\n",
        "                p_value = sum(calculate_binomial_distribution(k, 41, fraction) for k in range(count_matches, 42))\n",
        "\n",
        "                if p_value < 0.01:\n",
        "                    output_file.write(f'{sample1}\\t{sample2}\\t{sample3}\\t{sample4}\\t{sample5}\\t{sample6}\\t{fraction}\\t{count_matches}\\t{distribution}\\t{p_value}\\n')\n",
        "\n",
        "                    set_name = f'{sample1}-{sample2}-{sample3}-{sample4}-{sample5}-{sample6}'\n",
        "                    values_str = ', '.join(positive_values)\n",
        "                    y_file.write(f'{set_name}\\t{values_str}\\n')\n",
        "\n",
        "                    for idx, value in enumerate(positive_values):\n",
        "                        sample_name = sample_names[idx]\n",
        "                        values_str = values_str.replace(value, sample_name)\n",
        "\n",
        "                    samples_file.write(f'{set_name}\\t{values_str}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uu-wnytaUPP"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values6.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = set(values_str.split(', '))\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values6.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - y_positive_values\n",
        "\n",
        "            if unique_values:\n",
        "                x_output_file.write(f'{set_name}\\t{sample_name}\\t{\" \".join(map(str, unique_values))}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3b4fqXOaYIA"
      },
      "outputs": [],
      "source": [
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values6.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[set_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('s_single.txt', 'r') as sample_file:\n",
        "    header = sample_file.readline().strip().split('\\t')[1:]\n",
        "    data = [line.strip().split('\\t') for line in sample_file]\n",
        "\n",
        "with open('s_Wilcoxon_x-values6.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Set', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for set_name, y_positive_values in y_values.items():\n",
        "        sample_names = set_name.split('-')\n",
        "\n",
        "        for sample_name in sample_names:\n",
        "            sample_row = next(row for row in data if row[0] == sample_name)\n",
        "            sample_positive_values = [float(value) for value in sample_row[1:] if float(value) > 0]\n",
        "            unique_values = set(sample_positive_values) - set(y_positive_values)\n",
        "\n",
        "            if unique_values:\n",
        "                for value in unique_values:\n",
        "                    enzyme_name = header[sample_row[1:].index(str(value)) - 1]\n",
        "                    x_output_file.write(f'{set_name}\\t{enzyme_name}\\t{sample_name}\\t{value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejNEr4Z0HXFu"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "def extract_values(sample_name, mapped_data):\n",
        "    row = next(row for row in mapped_data if row[1] == sample_name)\n",
        "    return float(row[2])\n",
        "\n",
        "with open('mapped.txt', 'r') as mapped_file:\n",
        "    mapped_data = [line.strip().split('\\t') for line in mapped_file]\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples6.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_values(sample_name, mapped_data)\n",
        "            sample_values.append(value)\n",
        "\n",
        "        y_values[set_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values6.txt', 'r') as x_file:\n",
        "    next(x_file)\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        set_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        value = extract_values(sample_name, mapped_data)\n",
        "\n",
        "        key = f'{set_name} {enzyme_name}'\n",
        "        if key in x_values:\n",
        "            x_values[key].append(value)\n",
        "        else:\n",
        "            x_values[key] = [value]\n",
        "\n",
        "with open('s_MannU6.txt', 'w') as mann_u_file:\n",
        "\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Set', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "\n",
        "        set_name, enzyme_name_x = key.split()\n",
        "        y_sample_values = y_values.get(set_name, [])\n",
        "\n",
        "        stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "\n",
        "        mann_u_file.write(f'{set_name}\\t{enzyme_name_x}\\t{p_value}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w50aUlQBarK1"
      },
      "outputs": [],
      "source": [
        "with open('s_MannU6.txt', 'r') as mann_u_file, open('s_sig_combo6.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "        next_values_4 = next(mann_u_file, None)\n",
        "        next_values_5 = next(mann_u_file, None)\n",
        "        next_values_6 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None and next_values_4 is not None and next_values_5 is not None and next_values_6 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "            next_values_4 = next_values_4.strip().split('\\t')\n",
        "            next_values_5 = next_values_5.strip().split('\\t')\n",
        "            next_values_6 = next_values_6.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            next_enzyme_name_4 = next_values_4[1]\n",
        "            next_mann_u_value_4 = float(next_values_4[2])\n",
        "\n",
        "            next_enzyme_name_5 = next_values_5[1]\n",
        "            next_mann_u_value_5 = float(next_values_5[2])\n",
        "\n",
        "            next_enzyme_name_6 = next_values_6[1]\n",
        "            next_mann_u_value_6 = float(next_values_6[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1 and next_mann_u_value_4 < 0.1 and next_mann_u_value_5 < 0.1 and next_mann_u_value_6 < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_4, str(next_mann_u_value_4)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_5, str(next_mann_u_value_5)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_6, str(next_mann_u_value_6)]) + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7xKUmNSfla7"
      },
      "source": [
        "## Combination Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-XJQEhYwVgv"
      },
      "outputs": [],
      "source": [
        "def count_samples(y_samples):\n",
        "    return len(set(y_samples.split(', ')))\n",
        "\n",
        "def read_significant_enzymes(file_path):\n",
        "    enzymes = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split(', ')\n",
        "            enzyme_name = parts[0].split(' = ')[1]\n",
        "            correlation = float(parts[1].split(' = ')[1])\n",
        "            enzymes.append((enzyme_name, correlation))\n",
        "    return pd.DataFrame(enzymes, columns=['Enzyme', 'Correlation'])\n",
        "\n",
        "significant_enzymes_df = read_significant_enzymes('sig_pearson_enzymes.txt')\n",
        "\n",
        "files = ['p_sig_combo2.txt', 'p_sig_combo3.txt', 'p_sig_combo4.txt', 'p_sig_combo5.txt', 'p_sig_combo6.txt']\n",
        "\n",
        "results_df = pd.DataFrame(columns=['Enzyme Pair', 'Enzyme Name', 'Mann U', 'Binomial Distribution', 'y-samples', '# of samples'])\n",
        "\n",
        "results_df = pd.concat([significant_enzymes_df, results_df], ignore_index=True)\n",
        "\n",
        "for file in files:\n",
        "    with open(file, 'r') as sig_file:\n",
        "        next(sig_file)\n",
        "\n",
        "        for line in sig_file:\n",
        "            values = line.strip().split('\\t')\n",
        "            enzyme_set = values[0]\n",
        "            enzyme_name = values[1]\n",
        "            mann_u_value = float(values[2])\n",
        "\n",
        "            combo_file = f'p_combo{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            binomial_distribution = None\n",
        "\n",
        "            with open(combo_file, 'r') as combo_data:\n",
        "                next(combo_data)\n",
        "                for combo_line in combo_data:\n",
        "                    combo_values = combo_line.strip().split('\\t')\n",
        "\n",
        "                    combo_enzymes = set(combo_values[:len(enzyme_set.split(\"-\"))])\n",
        "                    if set(enzyme_set.split(\"-\")) == combo_enzymes:\n",
        "                        binomial_distribution = float(combo_values[-2])\n",
        "                        break\n",
        "\n",
        "            y_samples_file = f'p_Wilcoxon_y-samples{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            y_samples = []\n",
        "            with open(y_samples_file, 'r') as y_samples_data:\n",
        "                for y_samples_line in y_samples_data:\n",
        "                    y_samples_values = y_samples_line.strip().split('\\t')\n",
        "                    if y_samples_values[0] == enzyme_set:\n",
        "                        y_samples = y_samples_values[1:]\n",
        "                        break\n",
        "\n",
        "            num_samples = count_samples(', '.join(y_samples))\n",
        "\n",
        "            new_row = pd.DataFrame([{\n",
        "                'Enzyme Pair': enzyme_set,\n",
        "                'Enzyme Name': enzyme_name,\n",
        "                'Mann U': mann_u_value,\n",
        "                'Binomial Distribution': binomial_distribution,\n",
        "                'y-samples': ', '.join(y_samples),\n",
        "                '# of samples': num_samples\n",
        "            }])\n",
        "\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "\n",
        "results_df.to_excel('pearson_combinations.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRwgzjDdHcFs"
      },
      "outputs": [],
      "source": [
        "def count_samples(y_samples):\n",
        "    return len(set(y_samples.split(', ')))\n",
        "\n",
        "significant_enzymes_df = pd.read_csv('sig_spearman_enzymes.txt', sep=', ', header=None, engine='python')\n",
        "significant_enzymes_df.columns = ['Enzyme', 'Correlation', 't-dist', 'p-value']\n",
        "\n",
        "files = ['s_sig_combo2.txt', 's_sig_combo3.txt', 's_sig_combo4.txt', 's_sig_combo5.txt', 's_sig_combo6.txt']\n",
        "results_df = pd.DataFrame(columns=['Enzyme Pair', 'Enzyme Name', 'Mann U', 'Binomial Distribution', 'y-samples', '# of samples'])\n",
        "results_df = pd.concat([significant_enzymes_df, results_df], ignore_index=True)\n",
        "\n",
        "for file in files:\n",
        "    with open(file, 'r') as sig_file:\n",
        "        next(sig_file)\n",
        "\n",
        "        for line in sig_file:\n",
        "            values = line.strip().split('\\t')\n",
        "            enzyme_set = values[0]\n",
        "            enzyme_name = values[1]\n",
        "            mann_u_value = float(values[2])\n",
        "\n",
        "            combo_file = f's_combo{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            binomial_distribution = None\n",
        "\n",
        "            with open(combo_file, 'r') as combo_data:\n",
        "                next(combo_data)\n",
        "                for combo_line in combo_data:\n",
        "                    combo_values = combo_line.strip().split('\\t')\n",
        "                    combo_enzymes = set(combo_values[:len(enzyme_set.split(\"-\"))])\n",
        "                    if set(enzyme_set.split(\"-\")) == combo_enzymes:\n",
        "                        binomial_distribution = float(combo_values[-2])\n",
        "                        break\n",
        "\n",
        "            y_samples_file = f's_Wilcoxon_y-samples{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            with open(y_samples_file, 'r') as y_samples_data:\n",
        "                for y_samples_line in y_samples_data:\n",
        "                    y_samples_values = y_samples_line.strip().split('\\t')\n",
        "                    if y_samples_values[0] == enzyme_set:\n",
        "                        y_samples = y_samples_values[1:]\n",
        "                        break\n",
        "\n",
        "            num_samples = count_samples(', '.join(y_samples))\n",
        "\n",
        "            new_row = pd.DataFrame([{\n",
        "                'Enzyme Pair': enzyme_set,\n",
        "                'Enzyme Name': enzyme_name,\n",
        "                'Mann U': mann_u_value,\n",
        "                'Binomial Distribution': binomial_distribution,\n",
        "                'y-samples': ', '.join(y_samples),\n",
        "                '# of samples': num_samples\n",
        "            }])\n",
        "\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "\n",
        "results_df.to_excel('spearman_combinations.xlsx', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEoE3rRYR0fx"
      },
      "source": [
        "#Species Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L--tFBwLR8Hf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file1_path = 'miTAG.taxonomic.profiles.release.tsv'\n",
        "df1 = pd.read_csv(file1_path, delimiter='\\t')\n",
        "\n",
        "file2_path = 'mapped.txt'\n",
        "df2 = pd.read_csv(file2_path, delimiter='\\t', header=None, names=['ID', 'Sample', 'Value1', 'Value2'])\n",
        "\n",
        "df_filtered = df1.iloc[:, :7]\n",
        "\n",
        "sample_names_to_keep = df2['Sample'].unique()\n",
        "columns_to_keep = [col for col in df1.columns if any(sample_name in col for sample_name in sample_names_to_keep)]\n",
        "df_filtered = pd.concat([df_filtered, df1[columns_to_keep]], axis=1)\n",
        "\n",
        "output_file_path = 'miTAG_taxonomic_filtered.tsv'\n",
        "df_filtered.to_csv(output_file_path, sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfL3y_4GIAtF"
      },
      "source": [
        "#### Using pearson correlation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taxonomic_data = pd.read_csv('miTAG_taxonomic_filtered.tsv', delimiter='\\t')\n",
        "x_values = taxonomic_data.iloc[:, 7:].values\n",
        "\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", sep='\\s+', skiprows=[1])\n",
        "\n",
        "# Calculate t-value and probability distribution\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    x = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - stats.t.cdf(x, degrees_of_freedom)\n",
        "    return x, probability\n",
        "\n",
        "# Calculate Spearman correlation\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "degrees_of_freedom = 39\n",
        "\n",
        "correlation_coefficients = {}\n",
        "\n",
        "for row_index in range(len(release_df)):\n",
        "    y_values = mapped_data[2].values\n",
        "    x_row_values = x_values[row_index]\n",
        "    correlation_coefficient = calculate_correlation(x_row_values, y_values)\n",
        "    correlation_coefficients[row_index] = correlation_coefficient\n",
        "\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "domain = taxonomic_data.iloc[:, 0].values\n",
        "phylum = taxonomic_data.iloc[:, 1].values\n",
        "specie_class = taxonomic_data.iloc[:, 2].values\n",
        "order = taxonomic_data.iloc[:, 3].values\n",
        "family = taxonomic_data.iloc[:, 4].values\n",
        "genus = taxonomic_data.iloc[:, 5].values\n",
        "specie = taxonomic_data.iloc[:, 6].values\n",
        "\n",
        "with open(\"p_species_correlation.tab\", \"w\") as file:\n",
        "    file.write(\"Domain\\tPhylum\\tSpecies Class\\tOrder\\tFamily\\tGenus\\tSpecies\\tCorrelation\\tx\\tProbability\\n\")\n",
        "\n",
        "    for row_index, correlation_coefficient in sorted_coefficients:\n",
        "        one = domain[row_index]\n",
        "        two = phylum[row_index]\n",
        "        three = specie_class[row_index]\n",
        "        four = order[row_index]\n",
        "        five = family[row_index]\n",
        "        six = genus[row_index]\n",
        "        seven = specie[row_index]\n",
        "\n",
        "        x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        file.write(f\"{one}\\t{two}\\t{three}\\t{four}\\t{five}\\t{six}\\t{seven}\\t{correlation_coefficient}\\t{x}\\t{probability}\\n\")"
      ],
      "metadata": {
        "id": "GohiVzryDJPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BenjaminiHochberg method\n",
        "significant_rows = []\n",
        "\n",
        "total_probability = 0\n",
        "\n",
        "for row_index, correlation_coefficient in sorted_coefficients:\n",
        "    one = domain[row_index]\n",
        "    two = phylum[row_index]\n",
        "    three = specie_class[row_index]\n",
        "    four = order[row_index]\n",
        "    five = family[row_index]\n",
        "    six = genus[row_index]\n",
        "    seven = specie[row_index]\n",
        "    x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append((row_index, seven, correlation_coefficient, x, probability))\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break\n",
        "\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "if significant_rows:\n",
        "    significant_rows = significant_rows[:-1]\n",
        "\n",
        "with open(\"p_significant_species.tab\", \"w\") as file:\n",
        "    for row_index, seven, correlation_coefficient, x, probability in significant_rows:\n",
        "        one = domain[row_index]\n",
        "        two = phylum[row_index]\n",
        "        three = specie_class[row_index]\n",
        "        four = order[row_index]\n",
        "        five = family[row_index]\n",
        "        six = genus[row_index]\n",
        "        seven = specie[row_index]\n",
        "        file.write(f\"{one}\\t{two}\\t{three}\\t{four}\\t{five}\\t{six}\\t{seven}\\t{correlation_coefficient}\\t{probability}\\n\")"
      ],
      "metadata": {
        "id": "wVfgWZUPDCw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec9IsvJoIavR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def plot_line_of_best_fit(x, y, color, label):\n",
        "    slope, intercept = np.polyfit(x, y, 1)\n",
        "    plt.plot(x, slope * np.array(x) + intercept, color=color, linestyle='--', label=f'Fit for {label}')\n",
        "\n",
        "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
        "\n",
        "markers = ['o', 's', '^', 'v', 'D']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(min(5, len(sorted_coefficients))):\n",
        "    row_index, correlation_coefficient = sorted_coefficients[i]\n",
        "    one = domain[row_index]\n",
        "    two = phylum[row_index]\n",
        "    three = specie_class[row_index]\n",
        "    four = order[row_index]\n",
        "    five = family[row_index]\n",
        "    six = genus[row_index]\n",
        "    seven = specie[row_index]\n",
        "\n",
        "    x_row_values = x_values[row_index]\n",
        "    marker = markers[i]\n",
        "    color = colors[i]\n",
        "\n",
        "    sns.scatterplot(x=x_row_values, y=y_values, label=f'Species: {seven}\\nCorrelation: {correlation_coefficient}',\n",
        "                    color=color, marker=marker, alpha=0.7, s=25)\n",
        "\n",
        "    plot_line_of_best_fit(x_row_values, y_values, color, label=seven)\n",
        "\n",
        "plt.xlabel('Species Abundance')\n",
        "plt.ylabel('Pollution Degree')\n",
        "plt.title('Top 5 Species Pearson Correlations')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjD_BNVHIDtS"
      },
      "source": [
        "#### Using Spearman Correlation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taxonomic_data = pd.read_csv('miTAG_taxonomic_filtered.tsv', delimiter='\\t')\n",
        "x_values = taxonomic_data.iloc[:, 7:].values\n",
        "\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", sep='\\s+', skiprows=[1])\n",
        "\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    x = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - stats.t.cdf(x, degrees_of_freedom)\n",
        "    return x, probability\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = spearmanr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "degrees_of_freedom = 39\n",
        "\n",
        "correlation_coefficients = {}\n",
        "\n",
        "for row_index in range(len(release_df)):\n",
        "    y_values = mapped_data[2].values\n",
        "    x_row_values = x_values[row_index]\n",
        "    correlation_coefficient = calculate_correlation(x_row_values, y_values)\n",
        "    correlation_coefficients[row_index] = correlation_coefficient\n",
        "\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "domain = taxonomic_data.iloc[:, 0].values\n",
        "phylum = taxonomic_data.iloc[:, 1].values\n",
        "specie_class = taxonomic_data.iloc[:, 2].values\n",
        "order = taxonomic_data.iloc[:, 3].values\n",
        "family = taxonomic_data.iloc[:, 4].values\n",
        "genus = taxonomic_data.iloc[:, 5].values\n",
        "specie = taxonomic_data.iloc[:, 6].values\n",
        "\n",
        "with open(\"s_species_correlation.tab\", \"w\") as file:\n",
        "    file.write(\"Domain\\tPhylum\\tSpecies Class\\tOrder\\tFamily\\tGenus\\tSpecies\\tCorrelation\\tx\\tProbability\\n\")\n",
        "\n",
        "    for row_index, correlation_coefficient in sorted_coefficients:\n",
        "        one = domain[row_index]\n",
        "        two = phylum[row_index]\n",
        "        three = specie_class[row_index]\n",
        "        four = order[row_index]\n",
        "        five = family[row_index]\n",
        "        six = genus[row_index]\n",
        "        seven = specie[row_index]\n",
        "\n",
        "        x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        file.write(f\"{one}\\t{two}\\t{three}\\t{four}\\t{five}\\t{six}\\t{seven}\\t{correlation_coefficient}\\t{x}\\t{probability}\\n\")"
      ],
      "metadata": {
        "id": "4o-kKhfQAGbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BenjaminiHochberg method\n",
        "significant_rows = []\n",
        "\n",
        "total_probability = 0\n",
        "\n",
        "for row_index, correlation_coefficient in sorted_coefficients:\n",
        "    one = domain[row_index]\n",
        "    two = phylum[row_index]\n",
        "    three = specie_class[row_index]\n",
        "    four = order[row_index]\n",
        "    five = family[row_index]\n",
        "    six = genus[row_index]\n",
        "    seven = specie[row_index]\n",
        "    x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append((row_index, seven, correlation_coefficient, x, probability))\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break\n",
        "\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "if significant_rows:\n",
        "    significant_rows = significant_rows[:-1]\n",
        "\n",
        "with open(\"s_significant_species.tab\", \"w\") as file:\n",
        "    for row_index, seven, correlation_coefficient, x, probability in significant_rows:\n",
        "        one = domain[row_index]\n",
        "        two = phylum[row_index]\n",
        "        three = specie_class[row_index]\n",
        "        four = order[row_index]\n",
        "        five = family[row_index]\n",
        "        six = genus[row_index]\n",
        "        seven = specie[row_index]\n",
        "        file.write(f\"{one}\\t{two}\\t{three}\\t{four}\\t{five}\\t{six}\\t{seven}\\t{correlation_coefficient}\\t{probability}\\n\")"
      ],
      "metadata": {
        "id": "lh-BO5DM9u_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7RG0cetG8Lk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def plot_line_of_best_fit(x, y, color, label):\n",
        "    slope, intercept = np.polyfit(x, y, 1)\n",
        "    plt.plot(x, slope * np.array(x) + intercept, color=color, linestyle='--', label=f'Fit for {label}')\n",
        "\n",
        "colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
        "\n",
        "markers = ['o', 's', '^', 'v', 'D']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for i in range(min(5, len(sorted_coefficients))):\n",
        "    row_index, correlation_coefficient = sorted_coefficients[i]\n",
        "    one = domain[row_index]\n",
        "    two = phylum[row_index]\n",
        "    three = specie_class[row_index]\n",
        "    four = order[row_index]\n",
        "    five = family[row_index]\n",
        "    six = genus[row_index]\n",
        "    seven = specie[row_index]\n",
        "\n",
        "    x_row_values = x_values[row_index]\n",
        "    marker = markers[i]\n",
        "    color = colors[i]\n",
        "\n",
        "    sns.scatterplot(x=x_row_values, y=y_values, label=f'Species: {seven}\\nCorrelation: {correlation_coefficient}',\n",
        "                    color=color, marker=marker, alpha=0.7, s=25)\n",
        "\n",
        "    plot_line_of_best_fit(x_row_values, y_values, color, label=seven)\n",
        "\n",
        "plt.xlabel('Species Abundance')\n",
        "plt.ylabel('Pollution Degree')\n",
        "plt.title('Top 5 Species Spearman Correlations')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-validation (5)"
      ],
      "metadata": {
        "id": "GBcUKbovu7PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from scipy.stats import pearsonr, t\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    x = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - t.cdf(x, degrees_of_freedom)\n",
        "    return x, probability\n",
        "\n",
        "df = pd.read_csv(\"mapped.txt\", header=None, delim_whitespace=True)\n",
        "\n",
        "# Randomly shuffle the samples (41 rows in total)\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split the 41 rows into 5 groups of 8, 8, 8, 8, and 9\n",
        "rows_per_group = [8, 8, 8, 8, 9]  # Sizes of the groups\n",
        "splits = []\n",
        "start_idx = 0\n",
        "for count in rows_per_group:\n",
        "    splits.append(df_shuffled.iloc[start_idx:start_idx + count])\n",
        "    start_idx += count\n",
        "\n",
        "# Generate all combinations of 4 groups out of the 5 groups\n",
        "group_combinations = list(itertools.combinations(range(5), 4))  # Generate combinations of 4 out of 5 groups\n",
        "\n",
        "for combo_index, combo in enumerate(group_combinations):\n",
        "    # Combine selected groups\n",
        "    combined_rows = pd.concat([splits[i] for i in combo], ignore_index=True)\n",
        "    group_file_name = f\"cross-combo{combo_index + 1}.tab\"\n",
        "    combined_rows.to_csv(group_file_name, sep='\\t', index=False, header=False)\n",
        "\n",
        "    # Enzyme abundance data\n",
        "    release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "\n",
        "    sample_names = combined_rows[1].values\n",
        "    y_values = combined_rows[2].values\n",
        "\n",
        "    tara_dict = release_df.set_index('ko').to_dict('index')\n",
        "    x_values_for_all_enzymes = []\n",
        "\n",
        "    for enzyme, enzyme_data in tara_dict.items():\n",
        "        x_values = []\n",
        "        for sample in sample_names:\n",
        "            if sample in enzyme_data:\n",
        "                x_values.append(enzyme_data[sample])\n",
        "            else:\n",
        "                x_values.append(np.nan)\n",
        "\n",
        "        x_values_for_all_enzymes.append([enzyme] + x_values)\n",
        "\n",
        "    correlation_results = []\n",
        "    for enzyme_data in x_values_for_all_enzymes:\n",
        "        enzyme_name = enzyme_data[0]\n",
        "        x_values = enzyme_data[1:]\n",
        "\n",
        "        correlation_coefficient = calculate_correlation(x_values, y_values)\n",
        "        correlation_results.append((enzyme_name, correlation_coefficient))\n",
        "\n",
        "    correlation_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    with open(f\"cross-combo{combo_index + 1}_all_correlations.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient in correlation_results:\n",
        "            degrees_of_freedom = len(combined_rows) - 2  # Adjust degrees of freedom based on current group size\n",
        "            t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")\n",
        "\n",
        "    degrees_of_freedom = len(combined_rows) - 2  # Adjust degrees of freedom based on current group size\n",
        "    significant_rows = []\n",
        "    total_probability = 0\n",
        "\n",
        "    # Check the significance of each enzyme\n",
        "    for enzyme_name, correlation_coefficient in correlation_results:\n",
        "        t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        # Add the current result if the total probability does not exceed 1\n",
        "        if total_probability + p_value <= 1:\n",
        "            significant_rows.append((enzyme_name, correlation_coefficient, t_value, p_value))\n",
        "            total_probability += p_value\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    with open(f\"cross_sig_combo{combo_index + 1}.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient, t_value, p_value in significant_rows:\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "YRSheLB8I-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding shared enzymes between cross combos and sig_pearson_enzymes\n",
        "import pandas as pd\n",
        "\n",
        "def read_sig_pearson_file(file_name):\n",
        "    enzyme_data = {}\n",
        "    with open(file_name, \"r\") as file:\n",
        "        for line in file:\n",
        "            if line.strip():  # Skip empty lines\n",
        "                parts = line.strip().split(\", \")\n",
        "                enzyme_name = parts[0].split(\" = \")[1]\n",
        "                correlation = float(parts[1].split(\" = \")[1])\n",
        "                enzyme_data[enzyme_name] = correlation\n",
        "    return enzyme_data\n",
        "\n",
        "def read_cross_sig_file(file_name):\n",
        "    enzyme_data = {}\n",
        "    with open(file_name, \"r\") as file:\n",
        "        next(file)\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                parts = line.strip().split(\"\\t\")\n",
        "                enzyme_name = parts[0]\n",
        "                correlation = float(parts[1])\n",
        "                enzyme_data[enzyme_name] = correlation\n",
        "    return enzyme_data\n",
        "\n",
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"cross_sig_combo1.tab\",\n",
        "    \"cross_sig_combo2.tab\",\n",
        "    \"cross_sig_combo3.tab\",\n",
        "    \"cross_sig_combo4.tab\",\n",
        "    \"cross_sig_combo5.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:  # Only consider enzymes that are shared between sig_pearson and the current group\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 6)]\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 6)])\n",
        "\n",
        "total_enzymes_in_sig = len(sig_enzymes)\n",
        "for i in range(1, 6):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "    percentage_common = (common_enzymes_in_group / total_enzymes_in_sig) * 100 if total_enzymes_in_sig else 0\n",
        "    df[f\"Percentage Common in Group{i}\"] = percentage_common\n",
        "\n",
        "# Calculate how many groups share each enzyme\n",
        "df[\"Shared Count\"] = df[[\"Group1 Correlation\", \"Group2 Correlation\", \"Group3 Correlation\", \"Group4 Correlation\", \"Group5 Correlation\"]].apply(lambda x: (x != \"na\").sum(), axis=1)\n",
        "df_sorted = df.sort_values(by=\"Shared Count\", ascending=False)\n",
        "df_sorted = df_sorted.drop(columns=[\"Shared Count\"])\n",
        "\n",
        "for group in [\"Group1 Correlation\", \"Group2 Correlation\", \"Group3 Correlation\", \"Group4 Correlation\", \"Group5 Correlation\"]:\n",
        "    df_sorted[group] = df_sorted[group].apply(lambda x: f\"{x:.2f}\" if x != \"na\" else \"na\")\n",
        "\n",
        "for i in range(1, 6):\n",
        "    df_sorted[f\"Percentage Common in Group{i}\"] = df_sorted[f\"Percentage Common in Group{i}\"].apply(lambda x: f\"{x:.2f}%\")\n",
        "\n",
        "df_sorted.to_csv(\"cross_validation_results.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "6mfZy5vU-Ycq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_sig_pearson_file(file_name):\n",
        "    enzyme_data = {}\n",
        "    with open(file_name, \"r\") as file:\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                parts = line.strip().split(\", \")\n",
        "                enzyme_name = parts[0].split(\" = \")[1]\n",
        "                correlation = float(parts[1].split(\" = \")[1])\n",
        "                enzyme_data[enzyme_name] = correlation\n",
        "    return enzyme_data\n",
        "\n",
        "def read_cross_sig_file(file_name):\n",
        "    enzyme_data = {}\n",
        "    with open(file_name, \"r\") as file:\n",
        "        next(file)\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                parts = line.strip().split(\"\\t\")\n",
        "                enzyme_name = parts[0]\n",
        "                correlation = float(parts[1])\n",
        "                enzyme_data[enzyme_name] = correlation\n",
        "    return enzyme_data\n",
        "\n",
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"cross_sig_combo1.tab\",\n",
        "    \"cross_sig_combo2.tab\",\n",
        "    \"cross_sig_combo3.tab\",\n",
        "    \"cross_sig_combo4.tab\",\n",
        "    \"cross_sig_combo5.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 6)]\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 6)])\n",
        "\n",
        "for i in range(1, 6):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "\n",
        "    total_enzymes_in_sig = len(sig_enzymes)\n",
        "    total_enzymes_in_group = len(df)\n",
        "\n",
        "    denominator = min(total_enzymes_in_sig, total_enzymes_in_group)\n",
        "    percentage_common = (common_enzymes_in_group / denominator) * 100 if denominator else 0\n",
        "\n",
        "    df[f\"Percentage Common in Group{i}\"] = percentage_common\n",
        "\n",
        "df[\"Shared Count\"] = df[[\"Group1 Correlation\", \"Group2 Correlation\", \"Group3 Correlation\", \"Group4 Correlation\", \"Group5 Correlation\"]].apply(lambda x: (x != \"na\").sum(), axis=1)\n",
        "df_sorted = df.sort_values(by=\"Shared Count\", ascending=False)\n",
        "df_sorted = df_sorted.drop(columns=[\"Shared Count\"])\n",
        "\n",
        "for group in [\"Group1 Correlation\", \"Group2 Correlation\", \"Group3 Correlation\", \"Group4 Correlation\", \"Group5 Correlation\"]:\n",
        "    df_sorted[group] = df_sorted[group].apply(lambda x: f\"{x:.2f}\" if x != \"na\" else \"na\")\n",
        "\n",
        "for i in range(1, 6):\n",
        "    df_sorted[f\"Percentage Common in Group{i}\"] = df_sorted[f\"Percentage Common in Group{i}\"].apply(lambda x: f\"{x:.2f}%\")\n",
        "\n",
        "df_sorted.to_csv(\"cross_validation_results.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "vIwQ_mF-eHP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross-validation (10)"
      ],
      "metadata": {
        "id": "1poxtoEIEyBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from scipy.stats import pearsonr, t\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    x = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - t.cdf(x, degrees_of_freedom)\n",
        "    return x, probability\n",
        "\n",
        "df = pd.read_csv(\"mapped.txt\", header=None, delim_whitespace=True)\n",
        "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "rows_per_group = [4, 4, 4, 4, 4, 4, 4, 4, 4, 5]\n",
        "splits = []\n",
        "start_idx = 0\n",
        "for count in rows_per_group:\n",
        "    splits.append(df_shuffled.iloc[start_idx:start_idx + count])\n",
        "    start_idx += count\n",
        "\n",
        "group_combinations = list(itertools.combinations(range(10), 9))  # Generate combinations of 9 out of 10 groups\n",
        "\n",
        "for combo_index, combo in enumerate(group_combinations):\n",
        "    combined_rows = pd.concat([splits[i] for i in combo], ignore_index=True)\n",
        "\n",
        "    group_file_name = f\"cross-combo{combo_index + 1}.tab\"\n",
        "    combined_rows.to_csv(group_file_name, sep='\\t', index=False, header=False)\n",
        "\n",
        "    release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "    sample_names = combined_rows[1].values\n",
        "    y_values = combined_rows[2].values\n",
        "\n",
        "    tara_dict = release_df.set_index('ko').to_dict('index')\n",
        "\n",
        "    x_values_for_all_enzymes = []\n",
        "\n",
        "    for enzyme, enzyme_data in tara_dict.items():\n",
        "        x_values = []\n",
        "\n",
        "        for sample in sample_names:\n",
        "            if sample in enzyme_data:\n",
        "                x_values.append(enzyme_data[sample])\n",
        "            else:\n",
        "                x_values.append(np.nan)\n",
        "\n",
        "        x_values_for_all_enzymes.append([enzyme] + x_values)\n",
        "\n",
        "    correlation_results = []\n",
        "    for enzyme_data in x_values_for_all_enzymes:\n",
        "        enzyme_name = enzyme_data[0]\n",
        "        x_values = enzyme_data[1:]\n",
        "\n",
        "        correlation_coefficient = calculate_correlation(x_values, y_values)\n",
        "        correlation_results.append((enzyme_name, correlation_coefficient))\n",
        "\n",
        "    correlation_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    with open(f\"cross-combo{combo_index + 1}_all_correlations.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient in correlation_results:\n",
        "            degrees_of_freedom = len(combined_rows) - 2\n",
        "            t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")\n",
        "\n",
        "    degrees_of_freedom = len(combined_rows) - 2\n",
        "    significant_rows = []\n",
        "    total_probability = 0\n",
        "\n",
        "    for enzyme_name, correlation_coefficient in correlation_results:\n",
        "        t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        if total_probability + p_value <= 1:\n",
        "            significant_rows.append((enzyme_name, correlation_coefficient, t_value, p_value))\n",
        "            total_probability += p_value\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    with open(f\"cross_sig_combo{combo_index + 1}.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient, t_value, p_value in significant_rows:\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "oBe9_1tafInO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_sig_pearson_file(file_name):\n",
        "    enzyme_data = {}\n",
        "    with open(file_name, \"r\") as file:\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                parts = line.strip().split(\", \")\n",
        "                enzyme_name = parts[0].split(\" = \")[1]\n",
        "                correlation = float(parts[1].split(\" = \")[1])\n",
        "                enzyme_data[enzyme_name] = correlation\n",
        "    return enzyme_data\n",
        "\n",
        "def read_cross_sig_file(file_name):\n",
        "    enzyme_data = {}\n",
        "    with open(file_name, \"r\") as file:\n",
        "        next(file)\n",
        "        for line in file:\n",
        "            if line.strip():\n",
        "                parts = line.strip().split(\"\\t\")\n",
        "                enzyme_name = parts[0]\n",
        "                correlation = float(parts[1])\n",
        "                enzyme_data[enzyme_name] = correlation\n",
        "    return enzyme_data\n",
        "\n",
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"cross_sig_combo1.tab\",\n",
        "    \"cross_sig_combo2.tab\",\n",
        "    \"cross_sig_combo3.tab\",\n",
        "    \"cross_sig_combo4.tab\",\n",
        "    \"cross_sig_combo5.tab\",\n",
        "    \"cross_sig_combo6.tab\",\n",
        "    \"cross_sig_combo7.tab\",\n",
        "    \"cross_sig_combo8.tab\",\n",
        "    \"cross_sig_combo9.tab\",\n",
        "    \"cross_sig_combo10.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 11)]  # Update to 10 groups\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 11)])  # Update to 10 groups\n",
        "\n",
        "total_enzymes_in_sig = len(sig_enzymes)\n",
        "for i in range(1, 11):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "    percentage_common = (common_enzymes_in_group / total_enzymes_in_sig) * 100 if total_enzymes_in_sig else 0\n",
        "    df[f\"Percentage Common in Group{i}\"] = percentage_common\n",
        "\n",
        "df[\"Shared Count\"] = df[[\"Group1 Correlation\", \"Group2 Correlation\", \"Group3 Correlation\", \"Group4 Correlation\", \"Group5 Correlation\",\n",
        "                         \"Group6 Correlation\", \"Group7 Correlation\", \"Group8 Correlation\", \"Group9 Correlation\", \"Group10 Correlation\"]].apply(\n",
        "    lambda x: (x != \"na\").sum(), axis=1)\n",
        "\n",
        "df_sorted = df.sort_values(by=\"Shared Count\", ascending=False)\n",
        "df_sorted = df_sorted.drop(columns=[\"Shared Count\"])\n",
        "\n",
        "for group in [f\"Group{i} Correlation\" for i in range(1, 11)]:  # Update to 10 groups\n",
        "    df_sorted[group] = df_sorted[group].apply(lambda x: f\"{x:.2f}\" if x != \"na\" else \"na\")\n",
        "\n",
        "for i in range(1, 11):\n",
        "    df_sorted[f\"Percentage Common in Group{i}\"] = df_sorted[f\"Percentage Common in Group{i}\"].apply(lambda x: f\"{x:.2f}%\")\n",
        "\n",
        "df_sorted.to_csv(\"10cross_validation_results.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "Tg5J9T70FpyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"cross_sig_combo1.tab\",\n",
        "    \"cross_sig_combo2.tab\",\n",
        "    \"cross_sig_combo3.tab\",\n",
        "    \"cross_sig_combo4.tab\",\n",
        "    \"cross_sig_combo5.tab\",\n",
        "    \"cross_sig_combo6.tab\",\n",
        "    \"cross_sig_combo7.tab\",\n",
        "    \"cross_sig_combo8.tab\",\n",
        "    \"cross_sig_combo9.tab\",\n",
        "    \"cross_sig_combo10.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 11)]  # Update for 10 groups\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 11)])  # Updated for 10 groups\n",
        "\n",
        "percentages = {}\n",
        "for i in range(1, 11):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "\n",
        "    total_enzymes_in_sig = len(sig_enzymes)\n",
        "    total_enzymes_in_group = len(df)\n",
        "\n",
        "    denominator = min(total_enzymes_in_sig, total_enzymes_in_group)\n",
        "\n",
        "    percentage_common = (common_enzymes_in_group / denominator) * 100 if denominator else 0\n",
        "    percentages[f\"Group{i}\"] = percentage_common\n",
        "\n",
        "percentages_df = pd.DataFrame(list(percentages.items()), columns=[\"Group\", \"Percentage\"])\n",
        "percentages_df[\"Percentage\"] = percentages_df[\"Percentage\"].apply(lambda x: f\"{x:.5f}%\")\n",
        "percentages_df.to_csv(\"10_cross_validation_percentages.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "74fdKcYGFt5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "df = pd.read_csv(\"mapped.txt\", header=None, delim_whitespace=True)\n",
        "\n",
        "row_order = [\n",
        "    38, 28, 33, 9, 0, 25, 14, 39, 23, 37, 15, 20, 11, 6, 32, 29, 21, 7, 36, 18,\n",
        "    2, 10, 22, 13, 5, 40, 3, 8, 4, 24, 35, 16, 19, 27, 31, 17, 26, 34, 30, 12, 1\n",
        "]\n",
        "\n",
        "df_ordered = df.iloc[row_order].reset_index(drop=True)\n",
        "\n",
        "rows_per_group = [4, 4, 4, 4, 4, 4, 4, 4, 4, 5]\n",
        "splits = []\n",
        "start_idx = 0\n",
        "for count in rows_per_group:\n",
        "    splits.append(df_ordered.iloc[start_idx:start_idx + count])\n",
        "    start_idx += count\n",
        "\n",
        "group_combinations = list(itertools.combinations(range(10), 9))\n",
        "\n",
        "for combo_index, combo in enumerate(group_combinations):\n",
        "    combined_rows = pd.concat([splits[i] for i in combo], ignore_index=True)\n",
        "\n",
        "    group_file_name = f\"cross-combo{combo_index + 1}.tab\"\n",
        "    combined_rows.to_csv(group_file_name, sep='\\t', index=False, header=False)\n",
        "\n",
        "    release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "\n",
        "    sample_names = combined_rows[1].values\n",
        "    y_values = combined_rows[2].values\n",
        "\n",
        "    tara_dict = release_df.set_index('ko').to_dict('index')\n",
        "\n",
        "    x_values_for_all_enzymes = []\n",
        "\n",
        "    for enzyme, enzyme_data in tara_dict.items():\n",
        "        x_values = []\n",
        "\n",
        "        for sample in sample_names:\n",
        "            if sample in enzyme_data:\n",
        "                x_values.append(enzyme_data[sample])\n",
        "            else:\n",
        "                x_values.append(np.nan)\n",
        "\n",
        "        x_values_for_all_enzymes.append([enzyme] + x_values)\n",
        "\n",
        "    correlation_results = []\n",
        "    for enzyme_data in x_values_for_all_enzymes:\n",
        "        enzyme_name = enzyme_data[0]\n",
        "        x_values = enzyme_data[1:]\n",
        "\n",
        "        correlation_coefficient = calculate_correlation(x_values, y_values)\n",
        "        correlation_results.append((enzyme_name, correlation_coefficient))\n",
        "\n",
        "    correlation_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    with open(f\"cross-combo{combo_index + 1}_all_correlations.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient in correlation_results:\n",
        "            degrees_of_freedom = len(combined_rows) - 2\n",
        "            t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")\n",
        "\n",
        "    degrees_of_freedom = len(combined_rows) - 2\n",
        "    significant_rows = []\n",
        "    total_probability = 0\n",
        "\n",
        "    for enzyme_name, correlation_coefficient in correlation_results:\n",
        "        t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        if total_probability + p_value <= 1:\n",
        "            significant_rows.append((enzyme_name, correlation_coefficient, t_value, p_value))\n",
        "            total_probability += p_value\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    with open(f\"1_10_cross_sig_combo{combo_index + 1}.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient, t_value, p_value in significant_rows:\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "Kit78J2oJYyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"1_10_cross_sig_combo1.tab\",\n",
        "    \"1_10_cross_sig_combo2.tab\",\n",
        "    \"1_10_cross_sig_combo3.tab\",\n",
        "    \"1_10_cross_sig_combo4.tab\",\n",
        "    \"1_10_cross_sig_combo5.tab\",\n",
        "    \"1_10_cross_sig_combo6.tab\",\n",
        "    \"1_10_cross_sig_combo7.tab\",\n",
        "    \"1_10_cross_sig_combo8.tab\",\n",
        "    \"1_10_cross_sig_combo9.tab\",\n",
        "    \"1_10_cross_sig_combo10.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 11)]  # Update for 10 groups\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 11)])  # Updated for 10 groups\n",
        "\n",
        "percentages = {}\n",
        "for i in range(1, 11):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "    total_enzymes_in_sig = len(sig_enzymes)\n",
        "    total_enzymes_in_group = len(df)\n",
        "\n",
        "    denominator = min(total_enzymes_in_sig, total_enzymes_in_group)\n",
        "    percentage_common = (common_enzymes_in_group / denominator) * 100 if denominator else 0\n",
        "    percentages[f\"Group{i}\"] = percentage_common\n",
        "\n",
        "percentages_df = pd.DataFrame(list(percentages.items()), columns=[\"Group\", \"Percentage\"])\n",
        "percentages_df[\"Percentage\"] = percentages_df[\"Percentage\"].apply(lambda x: f\"{x:.5f}%\")\n",
        "percentages_df.to_csv(\"1_10_cross_validation_percentages.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "x1ZBF_z5TA-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"mapped.txt\", header=None, delim_whitespace=True)\n",
        "\n",
        "row_order = [\n",
        "    26, 6, 19, 23, 15, 18, 1, 0, 12, 25, 34, 30, 35, 16, 29, 10, 2, 24, 13, 28,\n",
        "    32, 31, 36, 7, 8, 40, 11, 9, 17, 22, 3, 4, 27, 20, 14, 39, 5, 38, 21, 37, 33\n",
        "]\n",
        "\n",
        "df_ordered = df.iloc[row_order].reset_index(drop=True)\n",
        "\n",
        "rows_per_group = [4, 4, 4, 4, 4, 4, 4, 4, 4, 5]\n",
        "splits = []\n",
        "start_idx = 0\n",
        "for count in rows_per_group:\n",
        "    splits.append(df_ordered.iloc[start_idx:start_idx + count])\n",
        "    start_idx += count\n",
        "\n",
        "group_combinations = list(itertools.combinations(range(10), 9))\n",
        "\n",
        "for combo_index, combo in enumerate(group_combinations):\n",
        "    combined_rows = pd.concat([splits[i] for i in combo], ignore_index=True)\n",
        "\n",
        "    group_file_name = f\"cross-combo{combo_index + 1}.tab\"\n",
        "    combined_rows.to_csv(group_file_name, sep='\\t', index=False, header=False)\n",
        "\n",
        "    release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "\n",
        "    sample_names = combined_rows[1].values\n",
        "    y_values = combined_rows[2].values\n",
        "\n",
        "    tara_dict = release_df.set_index('ko').to_dict('index')\n",
        "\n",
        "    x_values_for_all_enzymes = []\n",
        "\n",
        "    for enzyme, enzyme_data in tara_dict.items():\n",
        "        x_values = []\n",
        "\n",
        "        for sample in sample_names:\n",
        "            if sample in enzyme_data:\n",
        "                x_values.append(enzyme_data[sample])\n",
        "            else:\n",
        "                x_values.append(np.nan)\n",
        "\n",
        "        x_values_for_all_enzymes.append([enzyme] + x_values)\n",
        "\n",
        "    correlation_results = []\n",
        "    for enzyme_data in x_values_for_all_enzymes:\n",
        "        enzyme_name = enzyme_data[0]\n",
        "        x_values = enzyme_data[1:]\n",
        "\n",
        "        correlation_coefficient = calculate_correlation(x_values, y_values)\n",
        "        correlation_results.append((enzyme_name, correlation_coefficient))\n",
        "\n",
        "    correlation_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    with open(f\"cross-combo{combo_index + 1}_all_correlations.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient in correlation_results:\n",
        "            degrees_of_freedom = len(combined_rows) - 2\n",
        "            t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")\n",
        "\n",
        "    degrees_of_freedom = len(combined_rows) - 2\n",
        "    significant_rows = []\n",
        "    total_probability = 0\n",
        "\n",
        "    for enzyme_name, correlation_coefficient in correlation_results:\n",
        "        t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        if total_probability + p_value <= 1:\n",
        "            significant_rows.append((enzyme_name, correlation_coefficient, t_value, p_value))\n",
        "            total_probability += p_value\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    with open(f\"2_10_cross_sig_combo{combo_index + 1}.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient, t_value, p_value in significant_rows:\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "5cAgcoh_PdHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"2_10_cross_sig_combo1.tab\",\n",
        "    \"2_10_cross_sig_combo2.tab\",\n",
        "    \"2_10_cross_sig_combo3.tab\",\n",
        "    \"2_10_cross_sig_combo4.tab\",\n",
        "    \"2_10_cross_sig_combo5.tab\",\n",
        "    \"2_10_cross_sig_combo6.tab\",\n",
        "    \"2_10_cross_sig_combo7.tab\",\n",
        "    \"2_10_cross_sig_combo8.tab\",\n",
        "    \"2_10_cross_sig_combo9.tab\",\n",
        "    \"2_10_cross_sig_combo10.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 11)]  # Update for 10 groups\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 11)])  # Updated for 10 groups\n",
        "\n",
        "percentages = {}\n",
        "for i in range(1, 11):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "\n",
        "    total_enzymes_in_sig = len(sig_enzymes)\n",
        "    total_enzymes_in_group = len(df)\n",
        "\n",
        "    denominator = min(total_enzymes_in_sig, total_enzymes_in_group)\n",
        "\n",
        "    percentage_common = (common_enzymes_in_group / denominator) * 100 if denominator else 0\n",
        "    percentages[f\"Group{i}\"] = percentage_common\n",
        "\n",
        "percentages_df = pd.DataFrame(list(percentages.items()), columns=[\"Group\", \"Percentage\"])\n",
        "percentages_df[\"Percentage\"] = percentages_df[\"Percentage\"].apply(lambda x: f\"{x:.5f}%\")\n",
        "percentages_df.to_csv(\"2_10_cross_validation_percentages.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "kLSWlKntNYnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"mapped.txt\", header=None, delim_whitespace=True)\n",
        "\n",
        "row_order = [\n",
        "    37, 15, 14, 1, 0, 2, 8, 16, 19, 30, 4, 34, 26, 11, 20, 7, 3, 33, 29, 28,\n",
        "    36, 32, 9, 13, 18, 22, 25, 31, 17, 5, 27, 40, 23, 38, 10, 6, 24, 39, 21, 35, 12\n",
        "]\n",
        "\n",
        "df_ordered = df.iloc[row_order].reset_index(drop=True)\n",
        "\n",
        "rows_per_group = [4, 4, 4, 4, 4, 4, 4, 4, 4, 5]\n",
        "splits = []\n",
        "start_idx = 0\n",
        "for count in rows_per_group:\n",
        "    splits.append(df_ordered.iloc[start_idx:start_idx + count])\n",
        "    start_idx += count\n",
        "\n",
        "group_combinations = list(itertools.combinations(range(10), 9))\n",
        "\n",
        "for combo_index, combo in enumerate(group_combinations):\n",
        "    combined_rows = pd.concat([splits[i] for i in combo], ignore_index=True)\n",
        "    group_file_name = f\"cross-combo{combo_index + 1}.tab\"\n",
        "    combined_rows.to_csv(group_file_name, sep='\\t', index=False, header=False)\n",
        "    release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "\n",
        "    sample_names = combined_rows[1].values\n",
        "    y_values = combined_rows[2].values\n",
        "\n",
        "    tara_dict = release_df.set_index('ko').to_dict('index')\n",
        "\n",
        "    x_values_for_all_enzymes = []\n",
        "\n",
        "    for enzyme, enzyme_data in tara_dict.items():\n",
        "        x_values = []\n",
        "\n",
        "        for sample in sample_names:\n",
        "            if sample in enzyme_data:\n",
        "                x_values.append(enzyme_data[sample])\n",
        "            else:\n",
        "                x_values.append(np.nan)\n",
        "\n",
        "        x_values_for_all_enzymes.append([enzyme] + x_values)\n",
        "\n",
        "    correlation_results = []\n",
        "    for enzyme_data in x_values_for_all_enzymes:\n",
        "        enzyme_name = enzyme_data[0]\n",
        "        x_values = enzyme_data[1:]\n",
        "        correlation_coefficient = calculate_correlation(x_values, y_values)\n",
        "        correlation_results.append((enzyme_name, correlation_coefficient))\n",
        "\n",
        "    correlation_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    with open(f\"cross-combo{combo_index + 1}_all_correlations.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient in correlation_results:\n",
        "            degrees_of_freedom = len(combined_rows) - 2\n",
        "            t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")\n",
        "\n",
        "    degrees_of_freedom = len(combined_rows) - 2\n",
        "    significant_rows = []\n",
        "    total_probability = 0\n",
        "\n",
        "    for enzyme_name, correlation_coefficient in correlation_results:\n",
        "        t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        if total_probability + p_value <= 1:\n",
        "            significant_rows.append((enzyme_name, correlation_coefficient, t_value, p_value))\n",
        "            total_probability += p_value\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    with open(f\"3_10_cross_sig_combo{combo_index + 1}.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient, t_value, p_value in significant_rows:\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "Lh0fieQQSB-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"3_10_cross_sig_combo1.tab\",\n",
        "    \"3_10_cross_sig_combo2.tab\",\n",
        "    \"3_10_cross_sig_combo3.tab\",\n",
        "    \"3_10_cross_sig_combo4.tab\",\n",
        "    \"3_10_cross_sig_combo5.tab\",\n",
        "    \"3_10_cross_sig_combo6.tab\",\n",
        "    \"3_10_cross_sig_combo7.tab\",\n",
        "    \"3_10_cross_sig_combo8.tab\",\n",
        "    \"3_10_cross_sig_combo9.tab\",\n",
        "    \"3_10_cross_sig_combo10.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 11)]  # Update for 10 groups\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 11)])  # Updated for 10 groups\n",
        "\n",
        "percentages = {}\n",
        "for i in range(1, 11):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "\n",
        "    total_enzymes_in_sig = len(sig_enzymes)\n",
        "    total_enzymes_in_group = len(df)\n",
        "\n",
        "    denominator = min(total_enzymes_in_sig, total_enzymes_in_group)\n",
        "\n",
        "    percentage_common = (common_enzymes_in_group / denominator) * 100 if denominator else 0\n",
        "    percentages[f\"Group{i}\"] = percentage_common\n",
        "\n",
        "percentages_df = pd.DataFrame(list(percentages.items()), columns=[\"Group\", \"Percentage\"])\n",
        "percentages_df[\"Percentage\"] = percentages_df[\"Percentage\"].apply(lambda x: f\"{x:.5f}%\")\n",
        "percentages_df.to_csv(\"3_10_cross_validation_percentages.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "IvNn6MrxSZ56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "df = pd.read_csv(\"mapped.txt\", header=None, delim_whitespace=True)\n",
        "\n",
        "row_order = [\n",
        "    6, 35, 39, 8, 26, 14, 5, 3, 12, 37, 24, 40, 30,\n",
        "    13, 4, 29, 19, 28, 9, 7, 0, 27, 11, 15, 18, 22, 1, 17, 20,\n",
        "    32, 33, 36, 23, 34, 16, 31, 10, 2, 38, 25, 21\n",
        " ]\n",
        "\n",
        "df_ordered = df.iloc[row_order].reset_index(drop=True)\n",
        "\n",
        "rows_per_group = [4, 4, 4, 4, 4, 4, 4, 4, 4, 5]\n",
        "splits = []\n",
        "start_idx = 0\n",
        "for count in rows_per_group:\n",
        "    splits.append(df_ordered.iloc[start_idx:start_idx + count])\n",
        "    start_idx += count\n",
        "\n",
        "group_combinations = list(itertools.combinations(range(10), 9))\n",
        "\n",
        "for combo_index, combo in enumerate(group_combinations):\n",
        "    combined_rows = pd.concat([splits[i] for i in combo], ignore_index=True)\n",
        "\n",
        "    group_file_name = f\"cross-combo{combo_index + 1}.tab\"\n",
        "    combined_rows.to_csv(group_file_name, sep='\\t', index=False, header=False)\n",
        "\n",
        "    release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "\n",
        "    sample_names = combined_rows[1].values\n",
        "    y_values = combined_rows[2].values\n",
        "\n",
        "    tara_dict = release_df.set_index('ko').to_dict('index')\n",
        "\n",
        "    x_values_for_all_enzymes = []\n",
        "\n",
        "    for enzyme, enzyme_data in tara_dict.items():\n",
        "        x_values = []\n",
        "\n",
        "        for sample in sample_names:\n",
        "            if sample in enzyme_data:\n",
        "                x_values.append(enzyme_data[sample])\n",
        "            else:\n",
        "                x_values.append(np.nan)\n",
        "\n",
        "        x_values_for_all_enzymes.append([enzyme] + x_values)\n",
        "\n",
        "    correlation_results = []\n",
        "    for enzyme_data in x_values_for_all_enzymes:\n",
        "        enzyme_name = enzyme_data[0]\n",
        "        x_values = enzyme_data[1:]\n",
        "\n",
        "        correlation_coefficient = calculate_correlation(x_values, y_values)\n",
        "        correlation_results.append((enzyme_name, correlation_coefficient))\n",
        "\n",
        "    correlation_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    with open(f\"cross-combo{combo_index + 1}_all_correlations.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient in correlation_results:\n",
        "            degrees_of_freedom = len(combined_rows) - 2\n",
        "            t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")\n",
        "\n",
        "    degrees_of_freedom = len(combined_rows) - 2\n",
        "    significant_rows = []\n",
        "    total_probability = 0\n",
        "\n",
        "    for enzyme_name, correlation_coefficient in correlation_results:\n",
        "        t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "        if total_probability + p_value <= 1:\n",
        "            significant_rows.append((enzyme_name, correlation_coefficient, t_value, p_value))\n",
        "            total_probability += p_value\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    with open(f\"4_10_cross_sig_combo{combo_index + 1}.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient, t_value, p_value in significant_rows:\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "uOiskshcSdFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"4_10_cross_sig_combo1.tab\",\n",
        "    \"4_10_cross_sig_combo2.tab\",\n",
        "    \"4_10_cross_sig_combo3.tab\",\n",
        "    \"4_10_cross_sig_combo4.tab\",\n",
        "    \"4_10_cross_sig_combo5.tab\",\n",
        "    \"4_10_cross_sig_combo6.tab\",\n",
        "    \"4_10_cross_sig_combo7.tab\",\n",
        "    \"4_10_cross_sig_combo8.tab\",\n",
        "    \"4_10_cross_sig_combo9.tab\",\n",
        "    \"4_10_cross_sig_combo10.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 11)]\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 11)])\n",
        "\n",
        "percentages = {}\n",
        "for i in range(1, 11):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "\n",
        "    total_enzymes_in_sig = len(sig_enzymes)\n",
        "    total_enzymes_in_group = len(df)\n",
        "\n",
        "    denominator = min(total_enzymes_in_sig, total_enzymes_in_group)\n",
        "\n",
        "    percentage_common = (common_enzymes_in_group / denominator) * 100 if denominator else 0\n",
        "    percentages[f\"Group{i}\"] = percentage_common\n",
        "\n",
        "percentages_df = pd.DataFrame(list(percentages.items()), columns=[\"Group\", \"Percentage\"])\n",
        "percentages_df[\"Percentage\"] = percentages_df[\"Percentage\"].apply(lambda x: f\"{x:.5f}%\")\n",
        "percentages_df.to_csv(\"4_10_cross_validation_percentages.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "Bd3Uy8X0UYJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"mapped.txt\", header=None, delim_whitespace=True)\n",
        "\n",
        "row_order = [\n",
        "    17, 32, 31, 7, 6, 26, 8, 19, 28, 10, 1, 33, 35, 2,\n",
        "    14, 5, 34, 39, 22, 4, 13, 21, 38, 18, 16, 0, 9, 12, 15,\n",
        "    27, 23, 36, 3, 37, 20, 11, 40, 25, 24, 30, 29\n",
        " ]\n",
        "\n",
        "df_ordered = df.iloc[row_order].reset_index(drop=True)\n",
        "\n",
        "rows_per_group = [4, 4, 4, 4, 4, 4, 4, 4, 4, 5]\n",
        "splits = []\n",
        "start_idx = 0\n",
        "for count in rows_per_group:\n",
        "    splits.append(df_ordered.iloc[start_idx:start_idx + count])\n",
        "    start_idx += count\n",
        "\n",
        "group_combinations = list(itertools.combinations(range(10), 9))\n",
        "\n",
        "for combo_index, combo in enumerate(group_combinations):\n",
        "    combined_rows = pd.concat([splits[i] for i in combo], ignore_index=True)\n",
        "\n",
        "    group_file_name = f\"cross-combo{combo_index + 1}.tab\"\n",
        "    combined_rows.to_csv(group_file_name, sep='\\t', index=False, header=False)\n",
        "\n",
        "    release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "\n",
        "    sample_names = combined_rows[1].values\n",
        "    y_values = combined_rows[2].values\n",
        "\n",
        "    tara_dict = release_df.set_index('ko').to_dict('index')\n",
        "\n",
        "    x_values_for_all_enzymes = []\n",
        "\n",
        "    for enzyme, enzyme_data in tara_dict.items():\n",
        "        x_values = []\n",
        "\n",
        "        for sample in sample_names:\n",
        "            if sample in enzyme_data:\n",
        "                x_values.append(enzyme_data[sample])\n",
        "            else:\n",
        "                x_values.append(np.nan)\n",
        "\n",
        "        x_values_for_all_enzymes.append([enzyme] + x_values)\n",
        "\n",
        "    correlation_results = []\n",
        "    for enzyme_data in x_values_for_all_enzymes:\n",
        "        enzyme_name = enzyme_data[0]\n",
        "        x_values = enzyme_data[1:]\n",
        "\n",
        "        correlation_coefficient = calculate_correlation(x_values, y_values)\n",
        "        correlation_results.append((enzyme_name, correlation_coefficient))\n",
        "\n",
        "    correlation_results.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    with open(f\"cross-combo{combo_index + 1}_all_correlations.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient in correlation_results:\n",
        "            degrees_of_freedom = len(combined_rows) - 2\n",
        "            t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")\n",
        "\n",
        "    degrees_of_freedom = len(combined_rows) - 2\n",
        "    significant_rows = []\n",
        "    total_probability = 0\n",
        "\n",
        "    for enzyme_name, correlation_coefficient in correlation_results:\n",
        "        t_value, p_value = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "        if total_probability + p_value <= 1:\n",
        "            significant_rows.append((enzyme_name, correlation_coefficient, t_value, p_value))\n",
        "            total_probability += p_value\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    with open(f\"5_10_cross_sig_combo{combo_index + 1}.tab\", \"w\") as file:\n",
        "        file.write(\"Enzyme\\tCorrelation\\tT-dist\\tP-value\\n\")\n",
        "        for enzyme_name, correlation_coefficient, t_value, p_value in significant_rows:\n",
        "            file.write(f\"{enzyme_name}\\t{correlation_coefficient}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "dvZgbGNdUDwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sig_enzymes = read_sig_pearson_file(\"sig_pearson_enzymes.txt\")\n",
        "\n",
        "group_files = [\n",
        "    \"5_10_cross_sig_combo1.tab\",\n",
        "    \"5_10_cross_sig_combo2.tab\",\n",
        "    \"5_10_cross_sig_combo3.tab\",\n",
        "    \"5_10_cross_sig_combo4.tab\",\n",
        "    \"5_10_cross_sig_combo5.tab\",\n",
        "    \"5_10_cross_sig_combo6.tab\",\n",
        "    \"5_10_cross_sig_combo7.tab\",\n",
        "    \"5_10_cross_sig_combo8.tab\",\n",
        "    \"5_10_cross_sig_combo9.tab\",\n",
        "    \"5_10_cross_sig_combo10.tab\"\n",
        "]\n",
        "\n",
        "shared_enzyme_data = {}\n",
        "\n",
        "for i, group_file in enumerate(group_files, start=1):\n",
        "    group_enzymes = read_cross_sig_file(group_file)\n",
        "    for enzyme_name in group_enzymes:\n",
        "        if enzyme_name in sig_enzymes:\n",
        "            if enzyme_name not in shared_enzyme_data:\n",
        "                shared_enzyme_data[enzyme_name] = {\"Enzyme Name\": enzyme_name}\n",
        "\n",
        "            shared_enzyme_data[enzyme_name][f\"Group{i} Correlation\"] = group_enzymes[enzyme_name]\n",
        "\n",
        "final_data = []\n",
        "for enzyme_name, group_data in shared_enzyme_data.items():\n",
        "    row = [enzyme_name] + [group_data.get(f\"Group{i} Correlation\", \"na\") for i in range(1, 11)]\n",
        "    final_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=[\"Enzyme Name\"] + [f\"Group{i} Correlation\" for i in range(1, 11)])\n",
        "\n",
        "percentages = {}\n",
        "for i in range(1, 11):\n",
        "    group_column = f\"Group{i} Correlation\"\n",
        "\n",
        "    common_enzymes_in_group = df[group_column].apply(lambda x: x != \"na\").sum()\n",
        "\n",
        "    total_enzymes_in_sig = len(sig_enzymes)\n",
        "    total_enzymes_in_group = len(df)\n",
        "\n",
        "    denominator = min(total_enzymes_in_sig, total_enzymes_in_group)\n",
        "\n",
        "    percentage_common = (common_enzymes_in_group / denominator) * 100 if denominator else 0\n",
        "    percentages[f\"Group{i}\"] = percentage_common\n",
        "\n",
        "percentages_df = pd.DataFrame(list(percentages.items()), columns=[\"Group\", \"Percentage\"])\n",
        "percentages_df[\"Percentage\"] = percentages_df[\"Percentage\"].apply(lambda x: f\"{x:.5f}%\")\n",
        "percentages_df.to_csv(\"5_10_cross_validation_percentages.tab\", sep=\"\\t\", index=False)"
      ],
      "metadata": {
        "id": "EliX8PpNUbu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confidence Interval"
      ],
      "metadata": {
        "id": "Pd9MTLFYffBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "for row_index in range(len(release_df)):\n",
        "    x_values = [release_df.iloc[row_index][str(second_value)] for second_value in second_values]\n",
        "\n",
        "    desired_length = len(x_values)\n",
        "    y_values_resized = np.resize(y_values, desired_length)\n",
        "\n",
        "    correlation_coefficient = calculate_correlation(x_values, y_values_resized)\n",
        "    correlation_coefficients[row_index] = correlation_coefficient\n",
        "\n",
        "    enzyme_name = release_df.iloc[row_index, 0]\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + x_values)\n",
        "\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "first_column_values = release_df.iloc[:, 0].values\n",
        "\n",
        "significant_rows = []\n",
        "total_probability = 0\n",
        "\n",
        "for row_index, correlation_coefficient in sorted_coefficients:\n",
        "    first_value = first_column_values[row_index]  # Get the corresponding enzyme name\n",
        "    x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append((row_index, first_value, correlation_coefficient, x, probability))\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break\n",
        "\n",
        "with open(\"sig_pearson_enzymes.txt\", \"w\") as file:\n",
        "    for row_index, first_value, correlation_coefficient, x, probability in significant_rows:\n",
        "        file.write(f\"Enzyme = {first_value}, Correlation = {correlation_coefficient}, t-dist = {x}, p-value = {probability}\\n\")"
      ],
      "metadata": {
        "id": "jBpQysncmci5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fisher_z_transformation(correlation_coefficient):\n",
        "    return 0.5 * np.log((1 + correlation_coefficient) / (1 - correlation_coefficient))\n",
        "\n",
        "def calculate_confidence_interval(correlation_coefficient, degrees_of_freedom, confidence_level=0.95):\n",
        "    z = fisher_z_transformation(correlation_coefficient)\n",
        "\n",
        "    n = degrees_of_freedom + 2\n",
        "    se = 1 / np.sqrt(n - 3)\n",
        "\n",
        "    alpha = 1 - confidence_level\n",
        "    z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
        "\n",
        "    z_lower = z - z_alpha * se\n",
        "    z_upper = z + z_alpha * se\n",
        "\n",
        "    r_lower = (np.exp(2 * z_lower) - 1) / (np.exp(2 * z_lower) + 1)\n",
        "    r_upper = (np.exp(2 * z_upper) - 1) / (np.exp(2 * z_upper) + 1)\n",
        "\n",
        "    return r_lower, r_upper\n",
        "\n",
        "significant_rows = []\n",
        "with open(\"sig_pearson_enzymes.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split(\", \")\n",
        "        enzyme_name = parts[0].split(\" = \")[1]\n",
        "        correlation = float(parts[1].split(\" = \")[1])\n",
        "        t_value = float(parts[2].split(\" = \")[1].split()[0])\n",
        "        p_value = float(parts[3].split(\" = \")[1])\n",
        "\n",
        "        significant_rows.append((enzyme_name, correlation, t_value, p_value))\n",
        "\n",
        "confidence_intervals = []\n",
        "for enzyme_name, correlation, t_value, p_value in significant_rows:\n",
        "    df = 39\n",
        "    r_lower, r_upper = calculate_confidence_interval(correlation, df)\n",
        "    confidence_intervals.append((enzyme_name, correlation, r_lower, r_upper, t_value, p_value))\n",
        "\n",
        "with open(\"confidence_intervals_pearson.tab\", \"w\") as file:\n",
        "    file.write(\"Enzyme\\tCorrelation\\t95% CI Lower\\t95% CI Upper\\tt-dist (x value)\\tp-value\\n\")\n",
        "    for enzyme_name, correlation, r_lower, r_upper, t_value, p_value in confidence_intervals:\n",
        "        file.write(f\"{enzyme_name}\\t{correlation}\\t{r_lower}\\t{r_upper}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "F-DPLeR6sTV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confidence Interval (Spearman)"
      ],
      "metadata": {
        "id": "2G1JiyFyPKSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate correlation\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = spearmanr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "release_df = pd.read_csv(\"TARA243.KO.profile.release\", delim_whitespace=True, skiprows=[1])\n",
        "mapped_data = pd.read_csv('mapped.txt', sep='\\t', header=None)\n",
        "\n",
        "second_values = mapped_data[1].values\n",
        "y_values = mapped_data[2].values\n",
        "\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "for row_index in range(len(release_df)):\n",
        "    x_values = [release_df.iloc[row_index][str(second_value)] for second_value in second_values]\n",
        "\n",
        "    desired_length = len(x_values)\n",
        "    y_values_resized = np.resize(y_values, desired_length)\n",
        "\n",
        "    correlation_coefficient = calculate_correlation(x_values, y_values_resized)\n",
        "    correlation_coefficients[row_index] = correlation_coefficient\n",
        "\n",
        "    enzyme_name = release_df.iloc[row_index, 0]\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + x_values)\n",
        "\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "first_column_values = release_df.iloc[:, 0].values\n",
        "\n",
        "significant_rows = []\n",
        "total_probability = 0\n",
        "\n",
        "for row_index, correlation_coefficient in sorted_coefficients:\n",
        "    first_value = first_column_values[row_index]\n",
        "    x, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append((row_index, first_value, correlation_coefficient, x, probability))\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break\n",
        "\n",
        "with open(\"sig_spearman_enzymes.txt\", \"w\") as file:\n",
        "    for row_index, first_value, correlation_coefficient, x, probability in significant_rows:\n",
        "        file.write(f\"Enzyme = {first_value}, Correlation = {correlation_coefficient}, t-dist = {x}, p-value = {probability}\\n\")"
      ],
      "metadata": {
        "id": "eOdqZEiHPM4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def fisher_z_transformation(correlation_coefficient):\n",
        "    return 0.5 * np.log((1 + correlation_coefficient) / (1 - correlation_coefficient))\n",
        "\n",
        "def calculate_confidence_interval(correlation_coefficient, degrees_of_freedom, confidence_level=0.95):\n",
        "    z = fisher_z_transformation(correlation_coefficient)\n",
        "\n",
        "    n = degrees_of_freedom + 2  # Sample size (degrees of freedom + 2)\n",
        "    se = 1 / np.sqrt(n - 3)\n",
        "\n",
        "    alpha = 1 - confidence_level\n",
        "    z_alpha = stats.norm.ppf(1 - alpha / 2)  # Z value for confidence level (e.g., 1.96 for 95% CI)\n",
        "\n",
        "    z_lower = z - z_alpha * se\n",
        "    z_upper = z + z_alpha * se\n",
        "\n",
        "    r_lower = (np.exp(2 * z_lower) - 1) / (np.exp(2 * z_lower) + 1)\n",
        "    r_upper = (np.exp(2 * z_upper) - 1) / (np.exp(2 * z_upper) + 1)\n",
        "\n",
        "    return r_lower, r_upper\n",
        "\n",
        "significant_rows = []\n",
        "with open(\"sig_spearman_enzymes.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        parts = line.strip().split(\", \")\n",
        "        enzyme_name = parts[0].split(\" = \")[1]\n",
        "        correlation = float(parts[1].split(\" = \")[1])\n",
        "        t_value = float(parts[2].split(\" = \")[1].split()[0])\n",
        "        p_value = float(parts[3].split(\" = \")[1])\n",
        "\n",
        "        significant_rows.append((enzyme_name, correlation, t_value, p_value))\n",
        "\n",
        "confidence_intervals = []\n",
        "for enzyme_name, correlation, t_value, p_value in significant_rows:\n",
        "    df = 39\n",
        "    r_lower, r_upper = calculate_confidence_interval(correlation, df)\n",
        "    confidence_intervals.append((enzyme_name, correlation, r_lower, r_upper, t_value, p_value))\n",
        "\n",
        "with open(\"confidence_intervals_spearman.tab\", \"w\") as file:\n",
        "    file.write(\"Enzyme\\tCorrelation\\t95% CI Lower\\t95% CI Upper\\tt-dist (x value)\\tp-value\\n\")\n",
        "    for enzyme_name, correlation, r_lower, r_upper, t_value, p_value in confidence_intervals:\n",
        "        file.write(f\"{enzyme_name}\\t{correlation}\\t{r_lower}\\t{r_upper}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "EQkK4VBcPVT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "L4R-UnI9vjpU",
        "o7iyQocwmsHN",
        "WsJkoO-wibRY",
        "j3yYZ0UcwHZo",
        "ucyyIfieKjoh",
        "QbsaL8mLKom0",
        "F1HyqUvpXL3Z",
        "hCqAffZZXQSe",
        "xbfrY09pYB1D",
        "BPZgQnxIYnIf",
        "Fnwwx_TCZQGD",
        "bn1u6B29Z-ng",
        "mfL3y_4GIAtF",
        "rjD_BNVHIDtS",
        "GBcUKbovu7PH",
        "1poxtoEIEyBZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}