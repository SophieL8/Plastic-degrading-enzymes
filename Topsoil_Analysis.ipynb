{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v78pubjapgZu",
        "outputId": "2378115d-9191-48d2-854e-2eeb3a2e369f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-bio\n",
            "  Downloading scikit-bio-0.6.3.tar.gz (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (2.32.3)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (4.4.2)\n",
            "Requirement already satisfied: natsort>=4.0.3 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (1.14.1)\n",
            "Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (3.12.1)\n",
            "Collecting biom-format>=2.1.16 (from scikit-bio)\n",
            "  Downloading biom-format-2.1.16.tar.gz (11.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (0.14.4)\n",
            "Requirement already satisfied: patsy>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-bio) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from biom-format>=2.1.16->scikit-bio) (8.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->scikit-bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->scikit-bio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->scikit-bio) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->scikit-bio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->scikit-bio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->scikit-bio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->scikit-bio) (2025.1.31)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->scikit-bio) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->scikit-bio) (1.17.0)\n",
            "Building wheels for collected packages: scikit-bio, biom-format\n",
            "  Building wheel for scikit-bio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-bio: filename=scikit_bio-0.6.3-cp311-cp311-linux_x86_64.whl size=7294506 sha256=8a1e25d31059f32975038d77585f9f1fddc5f37c0480e334e2ea33045e822469\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/11/a2/86492071506a487bcba7015b710a9e89d66ca69845512fb86c\n",
            "  Building wheel for biom-format (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for biom-format: filename=biom_format-2.1.16-cp311-cp311-linux_x86_64.whl size=12182960 sha256=86c662dd205c1d854e46563a47868be6daa778d543bc70d59b5396fc6cc673b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/6b/58/a879e8fbae2479a3d1a68719f3a062fe62701d6494f1b74f5e\n",
            "Successfully built scikit-bio biom-format\n",
            "Installing collected packages: biom-format, scikit-bio\n",
            "Successfully installed biom-format-2.1.16 scikit-bio-0.6.3\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement skbio (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for skbio\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting georasters\n",
            "  Downloading georasters-0.5.29-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from georasters) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from georasters) (2.2.2)\n",
            "Collecting docopt (from georasters)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: GDAL in /usr/local/lib/python3.11/dist-packages (from georasters) (3.6.4)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.11/dist-packages (from georasters) (3.7.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from georasters) (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from georasters) (3.10.0)\n",
            "Collecting coverage (from georasters)\n",
            "  Downloading coverage-7.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting fiona (from georasters)\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: geopandas in /usr/local/lib/python3.11/dist-packages (from georasters) (1.0.1)\n",
            "Collecting pysal (from georasters)\n",
            "  Downloading pysal-25.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting affine (from georasters)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting rasterstats (from georasters)\n",
            "  Downloading rasterstats-0.20.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from fiona->georasters) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from fiona->georasters) (2025.1.31)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.11/dist-packages (from fiona->georasters) (8.1.8)\n",
            "Collecting click-plugins>=1.0 (from fiona->georasters)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting cligj>=0.5 (from fiona->georasters)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas->georasters) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from geopandas->georasters) (24.2)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from geopandas->georasters) (2.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->georasters) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->georasters) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->georasters) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->georasters) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->georasters) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->georasters) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->georasters) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->georasters) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->georasters) (3.2.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10 in /usr/local/lib/python3.11/dist-packages (from pysal->georasters) (4.13.3)\n",
            "Requirement already satisfied: platformdirs>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from pysal->georasters) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.11/dist-packages (from pysal->georasters) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from pysal->georasters) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.11/dist-packages (from pysal->georasters) (1.6.1)\n",
            "Collecting libpysal>=4.12.1 (from pysal->georasters)\n",
            "  Downloading libpysal-4.12.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting access>=1.1.9 (from pysal->georasters)\n",
            "  Downloading access-1.1.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting esda>=2.6.0 (from pysal->georasters)\n",
            "  Downloading esda-2.7.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting giddy>=2.3.6 (from pysal->georasters)\n",
            "  Downloading giddy-2.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inequality>=1.1.1 (from pysal->georasters)\n",
            "  Downloading inequality-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pointpats>=2.5.1 (from pysal->georasters)\n",
            "  Downloading pointpats-2.5.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting segregation>=2.5.1 (from pysal->georasters)\n",
            "  Downloading segregation-2.5.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting spaghetti>=1.7.6 (from pysal->georasters)\n",
            "  Downloading spaghetti-1.7.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mgwr>=2.2.1 (from pysal->georasters)\n",
            "  Downloading mgwr-2.2.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting momepy>=0.9.1 (from pysal->georasters)\n",
            "  Downloading momepy-0.9.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting spglm>=1.1.0 (from pysal->georasters)\n",
            "  Downloading spglm-1.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting spint>=1.0.7 (from pysal->georasters)\n",
            "  Downloading spint-1.0.7.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spreg>=1.8.1 (from pysal->georasters)\n",
            "  Downloading spreg-1.8.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tobler>=0.12.1 (from pysal->georasters)\n",
            "  Downloading tobler-0.12.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting mapclassify>=2.8.1 (from pysal->georasters)\n",
            "  Downloading mapclassify-2.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting splot>=1.1.7 (from pysal->georasters)\n",
            "  Downloading splot-1.1.7-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting spopt>=0.6.1 (from pysal->georasters)\n",
            "  Downloading spopt-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rasterio>=1.0 (from rasterstats->georasters)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from rasterstats->georasters) (3.20.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->georasters) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->georasters) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->georasters) (2025.2.18)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->georasters) (0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.10->pysal->georasters) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.10->pysal->georasters) (4.12.2)\n",
            "Collecting quantecon>=0.7 (from giddy>=2.3.6->pysal->georasters)\n",
            "  Downloading quantecon-0.8.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from momepy>=0.9.1->pysal->georasters) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->georasters) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->pysal->georasters) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->pysal->georasters) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->pysal->georasters) (2.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->pysal->georasters) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->pysal->georasters) (3.6.0)\n",
            "Collecting deprecation (from segregation>=2.5.1->pysal->georasters)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal->georasters) (0.13.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal->georasters) (0.60.0)\n",
            "Collecting rtree>=1.0 (from spaghetti>=1.7.6->pysal->georasters)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pulp>=2.7 (from spopt>=0.6.1->pysal->georasters)\n",
            "  Downloading PuLP-3.0.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from tobler>=0.12.1->pysal->georasters) (0.14.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from quantecon>=0.7->giddy>=2.3.6->pysal->georasters) (1.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->segregation>=2.5.1->pysal->georasters) (0.43.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->tobler>=0.12.1->pysal->georasters) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->quantecon>=0.7->giddy>=2.3.6->pysal->georasters) (1.3.0)\n",
            "Downloading georasters-0.5.29-py2.py3-none-any.whl (30 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading coverage-7.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysal-25.1-py3-none-any.whl (17 kB)\n",
            "Downloading rasterstats-0.20.0-py3-none-any.whl (17 kB)\n",
            "Downloading access-1.1.9-py3-none-any.whl (21 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading esda-2.7.0-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.8/142.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading giddy-2.3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inequality-1.1.1-py3-none-any.whl (29 kB)\n",
            "Downloading libpysal-4.12.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mapclassify-2.8.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mgwr-2.2.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading momepy-0.9.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pointpats-2.5.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segregation-2.5.2-py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spaghetti-1.7.6-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spglm-1.1.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading splot-1.1.7-py3-none-any.whl (39 kB)\n",
            "Downloading spopt-0.6.1-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.1/243.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spreg-1.8.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tobler-0.12.1-py3-none-any.whl (28 kB)\n",
            "Downloading PuLP-3.0.2-py3-none-any.whl (17.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading quantecon-0.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.7/322.7 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: docopt, spint\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=48540fe910215ba040830400fef6e115eed9dc32df778962285861abb0a55ced\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for spint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spint: filename=spint-1.0.7-py3-none-any.whl size=31355 sha256=afa7de0e6c24c87aa34adeee935fde6f6c28ef2e940d7a1841db7fe2a0983a4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/dc/2e/400caaa67e697355772a82b77b8c2ac7cd61633f595c477fd8\n",
            "Successfully built docopt spint\n",
            "Installing collected packages: docopt, rtree, pulp, deprecation, coverage, cligj, click-plugins, affine, rasterio, quantecon, fiona, rasterstats, mapclassify, libpysal, access, tobler, spreg, segregation, pointpats, momepy, inequality, esda, spglm, spaghetti, giddy, spopt, splot, spint, mgwr, pysal, georasters\n",
            "Successfully installed access-1.1.9 affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 coverage-7.7.0 deprecation-2.1.0 docopt-0.6.2 esda-2.7.0 fiona-1.10.1 georasters-0.5.29 giddy-2.3.6 inequality-1.1.1 libpysal-4.12.1 mapclassify-2.8.1 mgwr-2.2.1 momepy-0.9.1 pointpats-2.5.1 pulp-3.0.2 pysal-25.1 quantecon-0.8.0 rasterio-1.4.3 rasterstats-0.20.0 rtree-1.4.0 segregation-2.5.2 spaghetti-1.7.6 spglm-1.1.0 spint-1.0.7 splot-1.1.7 spopt-0.6.1 spreg-1.8.2 tobler-0.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-bio\n",
        "!pip install skbio\n",
        "!pip install georasters\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.patches import Circle\n",
        "import matplotlib as mpl\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn import preprocessing\n",
        "from skbio.diversity import alpha_diversity\n",
        "from skbio.stats.distance import DistanceMatrix\n",
        "from numpy import zeros\n",
        "from skbio.stats.ordination import pcoa\n",
        "\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "from scipy.spatial import cKDTree\n",
        "import georasters as gr\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knpOEILIpgZ6"
      },
      "source": [
        "## My analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DItS4TueUiGm"
      },
      "source": [
        "## Pearson Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yhH0YbJg82aT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "enzyme_df = pd.read_csv(\"enzyme_values.csv\")\n",
        "\n",
        "pollution_df = pd.read_csv('filtered_pollution_values.csv')\n",
        "\n",
        "# Ensure pollution values are numeric\n",
        "pollution_values = pd.to_numeric(pollution_df['conc_box_zscore'], errors='coerce').values\n",
        "\n",
        "sample_names = enzyme_df.columns[1:]\n",
        "\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "for index, row in enzyme_df.iterrows():\n",
        "    enzyme_name = row[0]\n",
        "\n",
        "    # Ensure x_values are numeric\n",
        "    x_values = pd.to_numeric(row[1:], errors='coerce').values\n",
        "\n",
        "    correlation_coefficient = calculate_correlation(x_values, pollution_values)\n",
        "    correlation_coefficients[enzyme_name] = correlation_coefficient\n",
        "\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + list(x_values))\n",
        "\n",
        "# Sort the correlation coefficients in descending order\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "with open(\"all_pearson_correlations.txt\", \"w\") as file:\n",
        "    for enzyme_name, correlation_coefficient in sorted_coefficients:\n",
        "        file.write(f\"EC Number = {enzyme_name}, Correlation = {correlation_coefficient}\\n\")\n",
        "\n",
        "column_names = ['Enzyme'] + list(sample_names)\n",
        "x_values_df = pd.DataFrame(x_values_for_all_enzymes, columns=column_names)\n",
        "x_values_df.to_csv('pearson_y_values.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Az4MZXeRI41f"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    t_value = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - stats.t.cdf(t_value, degrees_of_freedom)\n",
        "    return t_value, probability\n",
        "\n",
        "degrees_of_freedom = 42\n",
        "\n",
        "with open(\"all_pearson_correlations.txt\", \"w\") as file:\n",
        "    for enzyme_name, correlation_coefficient in sorted_coefficients:\n",
        "        t_value, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        file.write(f\"Enzyme = {enzyme_name}, Correlation Coefficient = {correlation_coefficient}, \"\n",
        "                   f\"t-value = {t_value}, Probability = {probability}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "06abxYwyKObc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Function to parse the 'all_pearson_correlations.txt' file and extract enzyme data\n",
        "def parse_pearson_correlations(file_path):\n",
        "    enzyme_data = []\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            match = re.match(r\"Enzyme = ([^,]+), Correlation Coefficient = ([^,]+), t-value = ([^,]+), Probability = ([^\\n]+)\", line)\n",
        "            if match:\n",
        "                enzyme_data.append({\n",
        "                    'Enzyme': match.group(1),\n",
        "                    'Correlation Coefficient': float(match.group(2)),\n",
        "                    't-value': float(match.group(3)),\n",
        "                    'Probability': float(match.group(4))\n",
        "                })\n",
        "    return enzyme_data\n",
        "\n",
        "enzyme_data = parse_pearson_correlations(\"all_pearson_correlations.txt\")\n",
        "\n",
        "# Initialize the total probability\n",
        "total_probability = 0\n",
        "\n",
        "# List to store significant rows\n",
        "significant_rows = []\n",
        "\n",
        "# Iterate through the enzyme data and accumulate probabilities\n",
        "for row in enzyme_data:\n",
        "    probability = row['Probability']\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append(row)  # Add the row to the significant rows\n",
        "        total_probability += probability  # Update the cumulative probability\n",
        "    else:\n",
        "        break  # Stop adding rows once the total probability exceeds 1\n",
        "\n",
        "# Write the significant rows back to a new file, excluding the ones after the total probability exceeds 1\n",
        "with open(\"sig_pearson_enzymes.txt\", \"w\") as file:\n",
        "    for row in significant_rows:\n",
        "        file.write(f\"Enzyme = {row['Enzyme']}, Correlation Coefficient = {row['Correlation Coefficient']}, t-value = {row['t-value']}, Probability = {row['Probability']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SAG4wOkqqvGJ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "\n",
        "def parse_pearson_correlations(file_path):\n",
        "    enzyme_data = []\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            match = re.match(r\"Enzyme = ([^,]+), Correlation Coefficient = ([^,]+), t-value = ([^,]+), Probability = ([^\\n]+)\", line)\n",
        "            if match:\n",
        "                enzyme_data.append({\n",
        "                    'Enzyme': match.group(1),\n",
        "                    'Correlation Coefficient': float(match.group(2)),\n",
        "                    't-value': float(match.group(3)),\n",
        "                    'Probability': float(match.group(4))\n",
        "                })\n",
        "    return enzyme_data\n",
        "\n",
        "def write_to_csv(enzyme_data, output_file):\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=['Enzyme', 'Correlation Coefficient', 't-value', 'Probability'])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(enzyme_data)\n",
        "\n",
        "sig_enzymes_data = parse_pearson_correlations(\"sig_pearson_enzymes.txt\")\n",
        "write_to_csv(sig_enzymes_data, \"sig_pearson_enzymes.csv\")\n",
        "\n",
        "all_enzymes_data = parse_pearson_correlations(\"all_pearson_correlations.txt\")\n",
        "write_to_csv(all_enzymes_data, \"all_pearson_correlations.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = pearsonr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "# Load the enzyme values and pollution data\n",
        "enzyme_df = pd.read_csv(\"enzyme_values.csv\")\n",
        "pollution_df = pd.read_csv('filtered_pollution_values.csv')\n",
        "\n",
        "# Ensure pollution values are numeric\n",
        "pollution_dict = {row['filename']: pd.to_numeric(row['conc_box_zscore'], errors='coerce') for index, row in pollution_df.iterrows()}\n",
        "\n",
        "sample_names = enzyme_df.columns[1:]\n",
        "\n",
        "# Prepare the pollution row\n",
        "pollution_row = ['pollution'] + [pollution_dict.get(sample, np.nan) for sample in sample_names]\n",
        "\n",
        "# Initialize a list to store enzyme values for the new file\n",
        "enzyme_values_for_new_file = []\n",
        "\n",
        "# Add the enzyme values to the new file data (skip the first column of enzyme_df, which is the EC number)\n",
        "for index, row in enzyme_df.iterrows():\n",
        "    enzyme_name = row[0]\n",
        "    enzyme_values = [enzyme_name] + row[1:].values.tolist()\n",
        "    enzyme_values_for_new_file.append(enzyme_values)\n",
        "\n",
        "# Now create a new DataFrame with the header and the pollution row\n",
        "header = ['EC Number'] + list(sample_names)\n",
        "pollution_and_enzymes = [header, pollution_row] + enzyme_values_for_new_file\n",
        "\n",
        "enzymexpollution_df = pd.DataFrame(pollution_and_enzymes)\n",
        "enzymexpollution_df.to_csv('enzymexpollution.tab', sep='\\t', index=False, header=False)\n",
        "\n",
        "# Calculate Pearson correlation coefficients for each enzyme and pollution\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "for index, row in enzyme_df.iterrows():\n",
        "    enzyme_name = row[0]\n",
        "\n",
        "    # Ensure x_values are numeric\n",
        "    x_values = pd.to_numeric(row[1:], errors='coerce').values\n",
        "    correlation_coefficient = calculate_correlation(x_values, list(pollution_dict.values()))\n",
        "    correlation_coefficients[enzyme_name] = correlation_coefficient\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + list(x_values))\n",
        "\n",
        "# Sort the correlation coefficients in descending order\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "with open(\"all_pearson_correlations.txt\", \"w\") as file:\n",
        "    for enzyme_name, correlation_coefficient in sorted_coefficients:\n",
        "        file.write(f\"EC Number = {enzyme_name}, Correlation = {correlation_coefficient}\\n\")\n",
        "\n",
        "column_names = ['Enzyme'] + list(sample_names)\n",
        "x_values_df = pd.DataFrame(x_values_for_all_enzymes, columns=column_names)\n",
        "x_values_df.to_csv('pearson_y_values.csv', index=False)\n"
      ],
      "metadata": {
        "id": "ucWlhXGqWyap"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfXwf-hxUkoI"
      },
      "source": [
        "## Spearman Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UlWDGjlmUl9f"
      },
      "outputs": [],
      "source": [
        "# Calculate spearman correlation between enzyme and pollution abundance\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "def calculate_correlation(x_values, y_values):\n",
        "    correlation_coefficient, _ = spearmanr(x_values, y_values)\n",
        "    return correlation_coefficient\n",
        "\n",
        "enzyme_df = pd.read_csv(\"enzyme_values.csv\")\n",
        "\n",
        "pollution_df = pd.read_csv('filtered_pollution_values.csv')\n",
        "\n",
        "pollution_values = pollution_df['conc_box_zscore'].values\n",
        "\n",
        "sample_names = enzyme_df.columns[1:]\n",
        "\n",
        "correlation_coefficients = {}\n",
        "x_values_for_all_enzymes = []\n",
        "\n",
        "for index, row in enzyme_df.iterrows():\n",
        "    enzyme_name = row[0]\n",
        "    x_values = row[1:].values\n",
        "\n",
        "    correlation_coefficient = calculate_correlation(x_values, pollution_values)\n",
        "    correlation_coefficients[enzyme_name] = correlation_coefficient\n",
        "\n",
        "    x_values_for_all_enzymes.append([enzyme_name] + list(x_values))\n",
        "\n",
        "# Sort the correlation coefficients in descending order\n",
        "sorted_coefficients = sorted(correlation_coefficients.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "with open(\"all_spearman_correlations.txt\", \"w\") as file:\n",
        "    for enzyme_name, correlation_coefficient in sorted_coefficients:\n",
        "        file.write(f\"EC Number = {enzyme_name}, Correlation = {correlation_coefficient}\\n\")\n",
        "\n",
        "column_names = ['Enzyme'] + list(sample_names)\n",
        "x_values_df = pd.DataFrame(x_values_for_all_enzymes, columns=column_names)\n",
        "x_values_df.to_csv('spearman_y_values.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "png-eXjZsAJL"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "def calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom):\n",
        "    t_value = correlation_coefficient * np.sqrt(degrees_of_freedom) / np.sqrt(1 - correlation_coefficient**2)\n",
        "    probability = 1 - stats.t.cdf(t_value, degrees_of_freedom)\n",
        "    return t_value, probability\n",
        "\n",
        "degrees_of_freedom = 42\n",
        "\n",
        "with open(\"all_spearman_correlations.txt\", \"w\") as file:\n",
        "    for enzyme_name, correlation_coefficient in sorted_coefficients:\n",
        "        t_value, probability = calculate_t_value_distribution(correlation_coefficient, degrees_of_freedom)\n",
        "\n",
        "        file.write(f\"Enzyme = {enzyme_name}, Correlation Coefficient = {correlation_coefficient}, \"\n",
        "                   f\"t-value = {t_value}, Probability = {probability}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fNCkan5TsDd0"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def parse_spearman_correlations(file_path):\n",
        "    enzyme_data = []\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            match = re.match(r\"Enzyme = ([^,]+), Correlation Coefficient = ([^,]+), t-value = ([^,]+), Probability = ([^\\n]+)\", line)\n",
        "            if match:\n",
        "                enzyme_data.append({\n",
        "                    'Enzyme': match.group(1),\n",
        "                    'Correlation Coefficient': float(match.group(2)),\n",
        "                    't-value': float(match.group(3)),\n",
        "                    'Probability': float(match.group(4))\n",
        "                })\n",
        "    return enzyme_data\n",
        "\n",
        "enzyme_data = parse_pearson_correlations(\"all_spearman_correlations.txt\")\n",
        "\n",
        "total_probability = 0\n",
        "significant_rows = []\n",
        "\n",
        "for row in enzyme_data:\n",
        "    probability = row['Probability']\n",
        "    if total_probability + probability <= 1:\n",
        "        significant_rows.append(row)\n",
        "        total_probability += probability\n",
        "    else:\n",
        "        break  # Stop adding rows once the total probability exceeds 1\n",
        "\n",
        "with open(\"sig_spearman_enzymes.txt\", \"w\") as file:\n",
        "    for row in significant_rows:\n",
        "        file.write(f\"Enzyme = {row['Enzyme']}, Correlation Coefficient = {row['Correlation Coefficient']}, t-value = {row['t-value']}, Probability = {row['Probability']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AM_ml_att4hr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "\n",
        "def parse_spearman_enzymes(file_path):\n",
        "    enzyme_data = []\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            match = re.match(r\"Enzyme = ([^,]+), Correlation Coefficient = ([^,]+), t-value = ([^,]+), Probability = ([^\\n]+)\", line)\n",
        "            if match:\n",
        "                enzyme_data.append({\n",
        "                    'Enzyme': match.group(1),\n",
        "                    'Correlation Coefficient': float(match.group(2)),\n",
        "                    't-value': float(match.group(3)),\n",
        "                    'Probability': float(match.group(4))\n",
        "                })\n",
        "    return enzyme_data\n",
        "\n",
        "def write_to_csv(enzyme_data, output_file):\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=['Enzyme', 'Correlation Coefficient', 't-value', 'Probability'])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(enzyme_data)\n",
        "\n",
        "spearman_enzymes_data_sig = parse_spearman_enzymes(\"sig_spearman_enzymes.txt\")\n",
        "write_to_csv(spearman_enzymes_data_sig, \"sig_spearman_enzymes.csv\")\n",
        "\n",
        "spearman_enzymes_data_all = parse_spearman_enzymes(\"all_spearman_correlations.txt\")\n",
        "write_to_csv(spearman_enzymes_data_all, \"all_spearman_correlations.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE6H4Tsl_-3z"
      },
      "source": [
        "### Combined version of converting the .txt files to .csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "O86YHp_bAeAC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "\n",
        "def parse_correlation_data(file_path, correlation_type):\n",
        "    enzyme_data = []\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            match = re.match(r\"Enzyme = ([^,]+), Correlation Coefficient = ([^,]+), t-value = ([^,]+), Probability = ([^\\n]+)\", line)\n",
        "            if match:\n",
        "                enzyme_data.append({\n",
        "                    'Enzyme': match.group(1),\n",
        "                    'Correlation Coefficient': float(match.group(2)),\n",
        "                    't-value': float(match.group(3)),\n",
        "                    'Probability': float(match.group(4)),\n",
        "                    'Correlation Type': correlation_type\n",
        "                })\n",
        "    return enzyme_data\n",
        "\n",
        "def write_to_csv(enzyme_data, output_file):\n",
        "    with open(output_file, mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=['Enzyme', 'Correlation Coefficient', 't-value', 'Probability', 'Correlation Type'])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(enzyme_data)\n",
        "\n",
        "pearson_data_sig = parse_correlation_data(\"sig_pearson_enzymes.txt\", \"Pearson\")\n",
        "write_to_csv(pearson_data_sig, \"sig_pearson_enzymes.csv\")\n",
        "\n",
        "pearson_data_all = parse_correlation_data(\"all_pearson_correlations.txt\", \"Pearson\")\n",
        "write_to_csv(pearson_data_all, \"all_pearson_correlations.csv\")\n",
        "\n",
        "spearman_data_sig = parse_correlation_data(\"sig_spearman_enzymes.txt\", \"Spearman\")\n",
        "write_to_csv(spearman_data_sig, \"sig_spearman_enzymes.csv\")\n",
        "\n",
        "spearman_data_all = parse_correlation_data(\"all_spearman_correlations.txt\", \"Spearman\")\n",
        "write_to_csv(spearman_data_all, \"all_spearman_correlations.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUgpLWraw6jf"
      },
      "source": [
        "### Shared enzymes between Spearman correlation and Pearson correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "96PMtYPnt16r"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "pearson_data = {}\n",
        "with open('sig_pearson_enzymes.csv', 'r') as pearson_file:\n",
        "    reader = csv.reader(pearson_file)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        enzyme = row[0]\n",
        "        correlation = float(row[1])\n",
        "        pearson_data[enzyme] = correlation\n",
        "\n",
        "overlap_data = []\n",
        "with open('sig_spearman_enzymes.csv', 'r') as spearman_file:\n",
        "    reader = csv.reader(spearman_file)\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        enzyme = row[0]\n",
        "        spearman_correlation = float(row[1])\n",
        "\n",
        "        if enzyme in pearson_data:\n",
        "            pearson_correlation = pearson_data[enzyme]\n",
        "            overlap_data.append([enzyme, pearson_correlation, spearman_correlation])\n",
        "\n",
        "with open('enzyme_overlap.csv', 'w', newline='') as overlap_file:\n",
        "    writer = csv.writer(overlap_file)\n",
        "    writer.writerow(['Enzyme', 'Pearson_Correlation', 'Spearman_Correlation'])\n",
        "    for row in overlap_data:\n",
        "        writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfy-wtenV0fL"
      },
      "source": [
        "# Combination Analysis using Pearson Correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7iyQocwmsHN"
      },
      "source": [
        "### Mean and Standard Deviation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_cmFrqdszEvJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the significant enzymes file to extract enzyme names\n",
        "enzyme_names = []\n",
        "with open(\"sig_pearson_enzymes.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        enzyme = line.split(' ')[2].replace(\",\", \"\")\n",
        "        enzyme_names.append(enzyme)\n",
        "\n",
        "# Read the enzymes values file\n",
        "enzymes_values_df = pd.read_csv(\"enzyme_values.csv\", sep=\",\")\n",
        "\n",
        "# Create a dictionary to store rows for each enzyme\n",
        "enzyme_rows = {enzyme: [] for enzyme in enzyme_names}\n",
        "\n",
        "# Find rows for each enzyme in the enzymes_values file\n",
        "for enzyme in enzyme_names:\n",
        "    # Matching the enzyme EC Number with the 'EC Number' column in the enzymes_values.csv file\n",
        "    enzyme_rows[enzyme] = enzymes_values_df[enzymes_values_df['EC Number'].str.contains(enzyme)]\n",
        "\n",
        "# Calculate mean and standard deviation for each row and save to a file\n",
        "with open(\"p_mean&sd.txt\", \"w\") as file:\n",
        "    for enzyme, rows in enzyme_rows.items():\n",
        "        means = rows.iloc[:, 1:].mean(axis=1)  # Compute mean of all columns except the 'EC Number'\n",
        "        std_devs = rows.iloc[:, 1:].std(axis=1)  # Compute standard deviation of all columns except the 'EC Number'\n",
        "        for index, (mean, std_dev) in enumerate(zip(means, std_devs)):\n",
        "            file.write(f\"Enzyme: {enzyme} Mean: {mean} Standard Deviation: {std_dev}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mvmX3nT91BUG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "enzymes_df = pd.read_csv(\"sig_pearson_enzymes.csv\")\n",
        "\n",
        "# Create a list of enzyme names (EC Numbers) to look for in the enzyme values file\n",
        "enzyme_names = enzymes_df['Enzyme'].tolist()\n",
        "\n",
        "enzyme_values_df = pd.read_csv(\"enzyme_values.csv\")\n",
        "\n",
        "with open(\"p_mean&sd.txt\", \"w\") as output_file:\n",
        "\n",
        "    for enzyme in enzyme_names:\n",
        "        # Find the row in enzyme_values_df where the EC Number matches the enzyme name\n",
        "        matching_row = enzyme_values_df[enzyme_values_df['EC Number'] == enzyme]\n",
        "\n",
        "        # Check if we found a match\n",
        "        if not matching_row.empty:\n",
        "            # Extract the values (exclude the EC Number column)\n",
        "            values = matching_row.iloc[0, 1:].values\n",
        "            # Calculate the mean and standard deviation for the values\n",
        "            mean_value = values.mean()\n",
        "            std_dev_value = values.std()\n",
        "\n",
        "            output_file.write(f\"{enzyme} Mean: {mean_value} Standard Deviation: {std_dev_value}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cyxZNo2i4fzW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Read sig_pearson_enzymes.csv to extract enzyme names and correlation info\n",
        "enzymes_df = pd.read_csv(\"sig_pearson_enzymes.csv\")\n",
        "\n",
        "# Create a dictionary to store the mean and standard deviation for each enzyme\n",
        "mean_sd_values = {}\n",
        "\n",
        "# Step 2: Read enzyme_values.csv to get the enzyme values for normalization\n",
        "enzyme_values_df = pd.read_csv(\"enzyme_values.csv\")\n",
        "\n",
        "# Extract only the numeric data columns (excluding 'EC Number')\n",
        "enzyme_columns = enzyme_values_df.columns[1:]  # Skip the 'EC Number' column\n",
        "\n",
        "# Step 3: Calculate the mean and standard deviation for each enzyme in enzyme_values.csv\n",
        "for _, row in enzymes_df.iterrows():\n",
        "    enzyme = row['Enzyme']\n",
        "\n",
        "    # Try to find the matching row in enzyme_values_df by EC Number\n",
        "    matching_row = enzyme_values_df[enzyme_values_df['EC Number'] == enzyme]\n",
        "\n",
        "    if not matching_row.empty:\n",
        "        # Get the values for the enzyme (skip the 'EC Number' column)\n",
        "        values = matching_row.iloc[0, 1:].values\n",
        "\n",
        "        # Calculate the mean and standard deviation\n",
        "        mean_value = values.mean()\n",
        "        std_dev_value = values.std()\n",
        "\n",
        "        # Store the mean and standard deviation for this enzyme\n",
        "        mean_sd_values[enzyme] = {'mean': mean_value, 'std_dev': std_dev_value}\n",
        "\n",
        "# Step 4: Normalize the values in enzyme_values.csv using the calculated mean and std dev\n",
        "normalized_values = []\n",
        "\n",
        "for _, row in enzyme_values_df.iterrows():\n",
        "    enzyme = row['EC Number']\n",
        "\n",
        "    if enzyme in mean_sd_values:\n",
        "        mean = mean_sd_values[enzyme]['mean']\n",
        "        std_dev = mean_sd_values[enzyme]['std_dev']\n",
        "\n",
        "        # Normalize the values in the row (excluding the 'EC Number' column)\n",
        "        normalized_row = [(value - mean) / std_dev if std_dev != 0 else 'NaN' for value in row[1:].values]\n",
        "\n",
        "        normalized_values.append([enzyme] + normalized_row)\n",
        "\n",
        "normalized_df = pd.DataFrame(normalized_values, columns=['EC Number'] + list(enzyme_columns))\n",
        "\n",
        "normalized_df.to_csv(\"p_normalized_enzyme_values.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9EpEMxYO7E9O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"p_normalized_enzyme_values.csv\")\n",
        "\n",
        "def count_positive_values(row):\n",
        "    return (row[1:] > 0).sum()  # Count values greater than 0 in each row\n",
        "\n",
        "df['positive_count'] = df.apply(count_positive_values, axis=1)\n",
        "\n",
        "# Step 4: Filter the rows that have at least 10 positive values\n",
        "df_filtered = df[df['positive_count'] >= 10]\n",
        "\n",
        "df_filtered = df_filtered.drop(columns=['positive_count'])\n",
        "\n",
        "df_filtered.to_csv(\"final_sig_p_enzymes.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsJkoO-wibRY"
      },
      "source": [
        "## Binomial Distribution and Mann U Whitney Test for Combo2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Pt98jugHHf_z"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_p_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('p_combo2.txt', 'w') as output_file, \\\n",
        "     open('p_Wilcoxon_y-values2.txt', 'w') as y_file, \\\n",
        "     open('p_Wilcoxon_y-samples2.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Pair', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Pair', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    for i in range(num_enzymes - 1):\n",
        "        for j in range(i + 1, num_enzymes):\n",
        "            enzyme1, enzyme2 = enzyme_list[i], enzyme_list[j]\n",
        "            values1, values2 = enzyme_data[enzyme1], enzyme_data[enzyme2]\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "            sample_list = []\n",
        "\n",
        "            for idx, (v1, v2) in enumerate(zip(values1, values2)):\n",
        "                if v1 > 0 and v2 > 0:\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(str(v1))\n",
        "                    sample_list.append(sample_names[idx])\n",
        "\n",
        "            if count_matches >= n:\n",
        "                fraction = enzyme_percentages[enzyme1] * enzyme_percentages[enzyme2]\n",
        "                distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "                p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "                output_file.write(f'{enzyme1}\\t{enzyme2}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "                y_file.write(f\"{enzyme1}-{enzyme2}\\t{', '.join(positive_values)}\\n\")\n",
        "                samples_file.write(f\"{enzyme1}-{enzyme2}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymkfiG89AajI",
        "outputId": "17fe36ab-081f-445b-f621-a5378ffd17e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available enzymes in the dataset: ['5.4.99.15', '3.4.13.-', '1.2.1.39', '3.5.2.18', '2.1.1.13', '2.7.8.-', '3.1.26.5', '2.1.1.191', '3.4.21.53', '3.1.2.29', '4.1.3.-', '2.5.1.47', '4.3.1.19', '4.1.99.3', '4.6.1.1', '7.5.2.11', '1.4.1.1', '1.5.3.19', '1.1.1.346', '4.2.1.9']...\n",
            "Checking enzymes: 5.4.99.15 and 1.2.1.39\n",
            "Checking enzymes: 5.4.99.15 and 3.4.21.53\n",
            "Checking enzymes: 5.4.99.15 and 2.5.1.47\n",
            "Checking enzymes: 5.4.99.15 and 7.5.2.11\n",
            "Checking enzymes: 5.4.99.15 and 1.4.1.1\n",
            "Checking enzymes: 5.4.99.15 and 6.1.1.18\n",
            "Checking enzymes: 5.4.99.15 and 3.5.4.19\n",
            "Checking enzymes: 5.4.99.15 and 5.3.1.12\n",
            "Checking enzymes: 3.4.13.- and 1.2.1.39\n",
            "Checking enzymes: 3.4.13.- and 2.1.1.13\n",
            "Checking enzymes: 3.4.13.- and 2.5.1.47\n",
            "Checking enzymes: 3.4.13.- and 4.6.1.1\n",
            "Checking enzymes: 3.4.13.- and 4.1.99.22\n",
            "Checking enzymes: 3.4.13.- and 6.1.1.18\n",
            "Checking enzymes: 3.4.13.- and 2.7.7.53\n",
            "Checking enzymes: 1.2.1.39 and 2.1.1.13\n",
            "Checking enzymes: 1.2.1.39 and 2.7.8.-\n",
            "Checking enzymes: 1.2.1.39 and 3.4.21.53\n",
            "Checking enzymes: 1.2.1.39 and 3.1.2.29\n",
            "Checking enzymes: 1.2.1.39 and 4.6.1.1\n",
            "Checking enzymes: 1.2.1.39 and 2.7.4.25\n",
            "Checking enzymes: 1.2.1.39 and 4.1.99.22\n",
            "Checking enzymes: 1.2.1.39 and 6.1.1.18\n",
            "Checking enzymes: 1.2.1.39 and 3.5.1.104\n",
            "Checking enzymes: 1.2.1.39 and 2.7.7.53\n",
            "Checking enzymes: 1.2.1.39 and 2.3.1.168\n",
            "Checking enzymes: 1.2.1.39 and 3.5.4.19\n",
            "Checking enzymes: 1.2.1.39 and 1.13.11.2\n",
            "Checking enzymes: 2.1.1.13 and 3.1.26.5\n",
            "Checking enzymes: 2.1.1.13 and 3.4.21.53\n",
            "Checking enzymes: 2.1.1.13 and 2.5.1.47\n",
            "Checking enzymes: 2.1.1.13 and 4.3.1.19\n",
            "Checking enzymes: 2.1.1.13 and 4.6.1.1\n",
            "Checking enzymes: 2.1.1.13 and 1.4.1.1\n",
            "Checking enzymes: 2.1.1.13 and 2.7.4.25\n",
            "Checking enzymes: 2.1.1.13 and 4.1.99.22\n",
            "Checking enzymes: 2.1.1.13 and 6.1.1.18\n",
            "Checking enzymes: 2.1.1.13 and 2.6.1.113\n",
            "Checking enzymes: 2.1.1.13 and 3.5.1.104\n",
            "Checking enzymes: 2.1.1.13 and 1.1.1.16\n",
            "Checking enzymes: 2.1.1.13 and 4.2.1.36\n",
            "Checking enzymes: 2.1.1.13 and 1.1.1.175\n",
            "Checking enzymes: 2.1.1.13 and 2.7.7.53\n",
            "Checking enzymes: 2.1.1.13 and 2.3.1.168\n",
            "Checking enzymes: 2.1.1.13 and 4.1.1.51\n",
            "Checking enzymes: 2.7.8.- and 3.4.21.53\n",
            "Checking enzymes: 2.7.8.- and 4.2.1.9\n",
            "Checking enzymes: 2.7.8.- and 2.7.4.25\n",
            "Checking enzymes: 2.7.8.- and 6.1.1.18\n",
            "Checking enzymes: 2.7.8.- and 3.5.1.104\n",
            "Checking enzymes: 2.7.8.- and 2.3.1.168\n",
            "Checking enzymes: 2.7.8.- and 3.5.4.19\n",
            "Checking enzymes: 2.7.8.- and 1.13.11.43\n",
            "Checking enzymes: 3.1.26.5 and 3.4.21.53\n",
            "Checking enzymes: 3.1.26.5 and 3.1.2.29\n",
            "Checking enzymes: 3.1.26.5 and 2.5.1.47\n",
            "Checking enzymes: 3.1.26.5 and 4.3.1.19\n",
            "Checking enzymes: 3.1.26.5 and 4.1.99.3\n",
            "Checking enzymes: 3.1.26.5 and 4.6.1.1\n",
            "Checking enzymes: 3.1.26.5 and 7.5.2.11\n",
            "Checking enzymes: 3.1.26.5 and 1.4.1.1\n",
            "Checking enzymes: 3.1.26.5 and 4.2.1.9\n",
            "Checking enzymes: 3.1.26.5 and 2.7.4.25\n",
            "Checking enzymes: 3.1.26.5 and 6.1.1.18\n",
            "Checking enzymes: 3.1.26.5 and 3.5.1.104\n",
            "Checking enzymes: 3.1.26.5 and 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5 and 1.1.1.175\n",
            "Checking enzymes: 3.1.26.5 and 2.7.7.53\n",
            "Checking enzymes: 3.1.26.5 and 2.1.3.12\n",
            "Checking enzymes: 3.1.26.5 and 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5 and 4.1.1.51\n",
            "Checking enzymes: 3.1.26.5 and 1.13.11.2\n",
            "Checking enzymes: 2.1.1.191 and 3.4.21.53\n",
            "Checking enzymes: 2.1.1.191 and 3.1.2.29\n",
            "Checking enzymes: 2.1.1.191 and 4.3.1.19\n",
            "Checking enzymes: 2.1.1.191 and 2.7.4.25\n",
            "Checking enzymes: 2.1.1.191 and 6.1.1.18\n",
            "Checking enzymes: 2.1.1.191 and 2.6.1.113\n",
            "Checking enzymes: 2.1.1.191 and 3.5.1.104\n",
            "Checking enzymes: 2.1.1.191 and 1.2.1.70\n",
            "Checking enzymes: 2.1.1.191 and 2.3.1.168\n",
            "Checking enzymes: 2.1.1.191 and 4.1.1.51\n",
            "Checking enzymes: 2.1.1.191 and 1.13.11.2\n",
            "Checking enzymes: 3.4.21.53 and 3.1.2.29\n",
            "Checking enzymes: 3.4.21.53 and 4.1.3.-\n",
            "Checking enzymes: 3.4.21.53 and 2.5.1.47\n",
            "Checking enzymes: 3.4.21.53 and 4.3.1.19\n",
            "Checking enzymes: 3.4.21.53 and 4.6.1.1\n",
            "Checking enzymes: 3.4.21.53 and 7.5.2.11\n",
            "Checking enzymes: 3.4.21.53 and 1.4.1.1\n",
            "Checking enzymes: 3.4.21.53 and 4.2.1.9\n",
            "Checking enzymes: 3.4.21.53 and 2.7.4.25\n",
            "Checking enzymes: 3.4.21.53 and 6.1.1.18\n",
            "Checking enzymes: 3.4.21.53 and 2.6.1.113\n",
            "Checking enzymes: 3.4.21.53 and 3.5.1.104\n",
            "Checking enzymes: 3.4.21.53 and 1.2.1.70\n",
            "Checking enzymes: 3.4.21.53 and 1.1.1.16\n",
            "Checking enzymes: 3.4.21.53 and 2.7.7.53\n",
            "Checking enzymes: 3.4.21.53 and 2.3.1.168\n",
            "Checking enzymes: 3.4.21.53 and 3.5.4.19\n",
            "Checking enzymes: 3.4.21.53 and 5.3.1.12\n",
            "Checking enzymes: 3.4.21.53 and 4.1.1.51\n",
            "Checking enzymes: 3.4.21.53 and 2.8.3.-\n",
            "Checking enzymes: 3.4.21.53 and 1.13.11.2\n",
            "Checking enzymes: 3.4.21.53 and 1.13.11.43\n",
            "Checking enzymes: 3.1.2.29 and 2.5.1.47\n",
            "Checking enzymes: 3.1.2.29 and 1.4.1.1\n",
            "Checking enzymes: 3.1.2.29 and 6.1.1.18\n",
            "Checking enzymes: 3.1.2.29 and 2.6.1.113\n",
            "Checking enzymes: 3.1.2.29 and 3.5.1.104\n",
            "Checking enzymes: 3.1.2.29 and 1.1.1.175\n",
            "Checking enzymes: 3.1.2.29 and 2.7.7.53\n",
            "Checking enzymes: 3.1.2.29 and 2.3.1.168\n",
            "Checking enzymes: 3.1.2.29 and 4.1.1.51\n",
            "Checking enzymes: 3.1.2.29 and 1.13.11.2\n",
            "Checking enzymes: 4.1.3.- and 2.5.1.47\n",
            "Checking enzymes: 4.1.3.- and 4.3.1.19\n",
            "Checking enzymes: 4.1.3.- and 4.6.1.1\n",
            "Checking enzymes: 4.1.3.- and 1.4.1.1\n",
            "Checking enzymes: 4.1.3.- and 1.1.1.346\n",
            "Checking enzymes: 4.1.3.- and 1.1.3.6\n",
            "Checking enzymes: 4.1.3.- and 6.1.1.18\n",
            "Checking enzymes: 4.1.3.- and 2.3.1.168\n",
            "Checking enzymes: 4.1.3.- and 4.1.1.51\n",
            "Checking enzymes: 4.1.3.- and 2.7.4.27\n",
            "Checking enzymes: 2.5.1.47 and 4.3.1.19\n",
            "Checking enzymes: 2.5.1.47 and 4.6.1.1\n",
            "Checking enzymes: 2.5.1.47 and 1.4.1.1\n",
            "Checking enzymes: 2.5.1.47 and 4.2.1.9\n",
            "Checking enzymes: 2.5.1.47 and 2.7.4.25\n",
            "Checking enzymes: 2.5.1.47 and 6.1.1.18\n",
            "Checking enzymes: 2.5.1.47 and 2.6.1.113\n",
            "Checking enzymes: 2.5.1.47 and 3.5.1.104\n",
            "Checking enzymes: 2.5.1.47 and 1.1.1.16\n",
            "Checking enzymes: 2.5.1.47 and 1.1.1.175\n",
            "Checking enzymes: 2.5.1.47 and 2.7.7.53\n",
            "Checking enzymes: 2.5.1.47 and 2.1.3.12\n",
            "Checking enzymes: 2.5.1.47 and 2.3.1.168\n",
            "Checking enzymes: 2.5.1.47 and 3.5.4.19\n",
            "Checking enzymes: 2.5.1.47 and 5.3.1.12\n",
            "Checking enzymes: 2.5.1.47 and 4.1.1.51\n",
            "Checking enzymes: 2.5.1.47 and 1.13.11.2\n",
            "Checking enzymes: 4.3.1.19 and 4.6.1.1\n",
            "Checking enzymes: 4.3.1.19 and 7.5.2.11\n",
            "Checking enzymes: 4.3.1.19 and 1.4.1.1\n",
            "Checking enzymes: 4.3.1.19 and 1.5.3.19\n",
            "Checking enzymes: 4.3.1.19 and 1.1.3.6\n",
            "Checking enzymes: 4.3.1.19 and 2.7.4.25\n",
            "Checking enzymes: 4.3.1.19 and 6.1.1.18\n",
            "Checking enzymes: 4.3.1.19 and 2.6.1.113\n",
            "Checking enzymes: 4.3.1.19 and 3.5.1.104\n",
            "Checking enzymes: 4.3.1.19 and 1.2.1.70\n",
            "Checking enzymes: 4.3.1.19 and 1.1.1.16\n",
            "Checking enzymes: 4.3.1.19 and 1.1.1.175\n",
            "Checking enzymes: 4.3.1.19 and 2.7.7.53\n",
            "Checking enzymes: 4.3.1.19 and 1.14.14.84\n",
            "Checking enzymes: 4.3.1.19 and 2.3.1.168\n",
            "Checking enzymes: 4.3.1.19 and 3.5.4.19\n",
            "Checking enzymes: 4.3.1.19 and 5.3.1.12\n",
            "Checking enzymes: 4.3.1.19 and 4.1.1.51\n",
            "Checking enzymes: 4.3.1.19 and 2.7.4.27\n",
            "Checking enzymes: 4.3.1.19 and 1.13.11.2\n",
            "Checking enzymes: 4.1.99.3 and 4.6.1.1\n",
            "Checking enzymes: 4.1.99.3 and 7.5.2.11\n",
            "Checking enzymes: 4.1.99.3 and 2.7.4.25\n",
            "Checking enzymes: 4.1.99.3 and 6.1.1.18\n",
            "Checking enzymes: 4.1.99.3 and 1.1.1.16\n",
            "Checking enzymes: 4.1.99.3 and 2.3.1.168\n",
            "Checking enzymes: 4.1.99.3 and 1.13.11.2\n",
            "Checking enzymes: 4.6.1.1 and 1.4.1.1\n",
            "Checking enzymes: 4.6.1.1 and 4.2.1.9\n",
            "Checking enzymes: 4.6.1.1 and 2.7.4.25\n",
            "Checking enzymes: 4.6.1.1 and 6.1.1.18\n",
            "Checking enzymes: 4.6.1.1 and 2.6.1.113\n",
            "Checking enzymes: 4.6.1.1 and 3.5.1.104\n",
            "Checking enzymes: 4.6.1.1 and 1.1.1.16\n",
            "Checking enzymes: 4.6.1.1 and 1.1.1.175\n",
            "Checking enzymes: 4.6.1.1 and 2.7.7.53\n",
            "Checking enzymes: 4.6.1.1 and 1.14.14.84\n",
            "Checking enzymes: 4.6.1.1 and 2.1.3.12\n",
            "Checking enzymes: 4.6.1.1 and 2.3.1.168\n",
            "Checking enzymes: 4.6.1.1 and 4.1.1.51\n",
            "Checking enzymes: 4.6.1.1 and 1.13.11.2\n",
            "Checking enzymes: 7.5.2.11 and 1.4.1.1\n",
            "Checking enzymes: 7.5.2.11 and 1.5.3.19\n",
            "Checking enzymes: 7.5.2.11 and 1.1.3.6\n",
            "Checking enzymes: 7.5.2.11 and 2.7.4.25\n",
            "Checking enzymes: 7.5.2.11 and 6.1.1.18\n",
            "Checking enzymes: 7.5.2.11 and 3.5.1.104\n",
            "Checking enzymes: 7.5.2.11 and 1.1.1.16\n",
            "Checking enzymes: 7.5.2.11 and 1.1.1.175\n",
            "Checking enzymes: 7.5.2.11 and 2.1.3.12\n",
            "Checking enzymes: 7.5.2.11 and 5.3.1.12\n",
            "Checking enzymes: 7.5.2.11 and 4.1.1.51\n",
            "Checking enzymes: 7.5.2.11 and 1.13.11.2\n",
            "Checking enzymes: 1.4.1.1 and 2.7.4.25\n",
            "Checking enzymes: 1.4.1.1 and 6.1.1.18\n",
            "Checking enzymes: 1.4.1.1 and 6.4.-.-\n",
            "Checking enzymes: 1.4.1.1 and 2.6.1.113\n",
            "Checking enzymes: 1.4.1.1 and 3.5.1.104\n",
            "Checking enzymes: 1.4.1.1 and 1.1.1.16\n",
            "Checking enzymes: 1.4.1.1 and 1.1.1.175\n",
            "Checking enzymes: 1.4.1.1 and 2.3.1.168\n",
            "Checking enzymes: 1.4.1.1 and 3.5.4.19\n",
            "Checking enzymes: 1.4.1.1 and 5.3.1.12\n",
            "Checking enzymes: 1.4.1.1 and 4.1.1.51\n",
            "Checking enzymes: 1.4.1.1 and 1.13.11.2\n",
            "Checking enzymes: 1.5.3.19 and 4.2.1.9\n",
            "Checking enzymes: 1.5.3.19 and 6.1.1.18\n",
            "Checking enzymes: 1.1.1.346 and 6.1.1.18\n",
            "Checking enzymes: 4.2.1.9 and 2.7.4.25\n",
            "Checking enzymes: 4.2.1.9 and 6.1.1.18\n",
            "Checking enzymes: 4.2.1.9 and 3.5.1.118\n",
            "Checking enzymes: 4.2.1.9 and 3.5.1.104\n",
            "Checking enzymes: 4.2.1.9 and 1.1.1.16\n",
            "Checking enzymes: 4.2.1.9 and 1.13.11.2\n",
            "Checking enzymes: 1.1.3.6 and 6.1.1.18\n",
            "Checking enzymes: 1.1.3.6 and 4.1.1.51\n",
            "Checking enzymes: 2.7.4.25 and 4.1.99.22\n",
            "Checking enzymes: 2.7.4.25 and 6.1.1.18\n",
            "Checking enzymes: 2.7.4.25 and 3.5.1.104\n",
            "Checking enzymes: 2.7.4.25 and 1.2.1.70\n",
            "Checking enzymes: 2.7.4.25 and 1.1.1.16\n",
            "Checking enzymes: 2.7.4.25 and 1.1.1.175\n",
            "Checking enzymes: 2.7.4.25 and 2.7.7.53\n",
            "Checking enzymes: 2.7.4.25 and 1.14.14.84\n",
            "Checking enzymes: 2.7.4.25 and 2.3.1.168\n",
            "Checking enzymes: 2.7.4.25 and 3.5.4.19\n",
            "Checking enzymes: 2.7.4.25 and 5.3.1.12\n",
            "Checking enzymes: 2.7.4.25 and 4.1.1.51\n",
            "Checking enzymes: 2.7.4.25 and 2.7.4.27\n",
            "Checking enzymes: 2.7.4.25 and 1.13.11.2\n",
            "Checking enzymes: 4.1.99.22 and 6.1.1.18\n",
            "Checking enzymes: 4.1.99.22 and 2.7.7.53\n",
            "Checking enzymes: 4.1.99.22 and 1.13.11.2\n",
            "Checking enzymes: 4.1.99.22 and 2.3.1.245\n",
            "Checking enzymes: 6.1.1.18 and 6.4.-.-\n",
            "Checking enzymes: 6.1.1.18 and 3.5.1.118\n",
            "Checking enzymes: 6.1.1.18 and 2.6.1.113\n",
            "Checking enzymes: 6.1.1.18 and 3.5.1.104\n",
            "Checking enzymes: 6.1.1.18 and 1.4.99.5\n",
            "Checking enzymes: 6.1.1.18 and 1.2.1.70\n",
            "Checking enzymes: 6.1.1.18 and 1.1.1.16\n",
            "Checking enzymes: 6.1.1.18 and 1.1.1.175\n",
            "Checking enzymes: 6.1.1.18 and 2.7.7.53\n",
            "Checking enzymes: 6.1.1.18 and 2.1.3.12\n",
            "Checking enzymes: 6.1.1.18 and 2.3.1.168\n",
            "Checking enzymes: 6.1.1.18 and 3.5.4.19\n",
            "Checking enzymes: 6.1.1.18 and 5.3.1.12\n",
            "Checking enzymes: 6.1.1.18 and 4.1.1.51\n",
            "Checking enzymes: 6.1.1.18 and 2.8.3.-\n",
            "Checking enzymes: 6.1.1.18 and 2.7.4.27\n",
            "Checking enzymes: 6.1.1.18 and 1.13.11.2\n",
            "Checking enzymes: 6.1.1.18 and 1.13.11.43\n",
            "Checking enzymes: 6.4.-.- and 5.3.1.12\n",
            "Checking enzymes: 3.5.1.118 and 1.13.11.2\n",
            "Checking enzymes: 2.6.1.113 and 3.5.1.104\n",
            "Checking enzymes: 2.6.1.113 and 2.7.7.53\n",
            "Checking enzymes: 2.6.1.113 and 1.14.14.84\n",
            "Checking enzymes: 2.6.1.113 and 2.1.3.12\n",
            "Checking enzymes: 2.6.1.113 and 2.3.1.168\n",
            "Checking enzymes: 2.6.1.113 and 5.3.1.12\n",
            "Checking enzymes: 2.6.1.113 and 4.1.1.51\n",
            "Checking enzymes: 3.5.1.104 and 1.2.1.70\n",
            "Checking enzymes: 3.5.1.104 and 1.1.1.16\n",
            "Checking enzymes: 3.5.1.104 and 1.1.1.175\n",
            "Checking enzymes: 3.5.1.104 and 2.7.7.53\n",
            "Checking enzymes: 3.5.1.104 and 1.14.14.84\n",
            "Checking enzymes: 3.5.1.104 and 2.1.3.12\n",
            "Checking enzymes: 3.5.1.104 and 2.3.1.168\n",
            "Checking enzymes: 3.5.1.104 and 3.5.4.19\n",
            "Checking enzymes: 3.5.1.104 and 5.3.1.12\n",
            "Checking enzymes: 3.5.1.104 and 1.18.1.-\n",
            "Checking enzymes: 3.5.1.104 and 4.1.1.51\n",
            "Checking enzymes: 3.5.1.104 and 1.13.11.2\n",
            "Checking enzymes: 1.4.99.5 and 2.7.7.53\n",
            "Checking enzymes: 1.2.1.70 and 2.7.7.53\n",
            "Checking enzymes: 1.2.1.70 and 4.1.1.51\n",
            "Checking enzymes: 1.1.1.16 and 1.1.1.175\n",
            "Checking enzymes: 1.1.1.16 and 2.7.7.53\n",
            "Checking enzymes: 1.1.1.16 and 2.3.1.168\n",
            "Checking enzymes: 1.1.1.16 and 4.1.1.51\n",
            "Checking enzymes: 1.1.1.16 and 1.13.11.2\n",
            "Checking enzymes: 4.2.1.36 and 1.1.1.175\n",
            "Checking enzymes: 4.2.1.36 and 2.7.7.53\n",
            "Checking enzymes: 4.2.1.36 and 2.3.1.168\n",
            "Checking enzymes: 1.1.1.175 and 2.7.7.53\n",
            "Checking enzymes: 1.1.1.175 and 1.14.14.84\n",
            "Checking enzymes: 1.1.1.175 and 2.3.1.168\n",
            "Checking enzymes: 1.1.1.175 and 3.5.4.19\n",
            "Checking enzymes: 1.1.1.175 and 5.3.1.12\n",
            "Checking enzymes: 1.1.1.175 and 4.1.1.51\n",
            "Checking enzymes: 1.1.1.175 and 1.13.11.2\n",
            "Checking enzymes: 2.7.7.53 and 1.14.14.84\n",
            "Checking enzymes: 2.7.7.53 and 2.3.1.168\n",
            "Checking enzymes: 2.7.7.53 and 3.5.4.19\n",
            "Checking enzymes: 2.7.7.53 and 5.3.1.12\n",
            "Checking enzymes: 2.7.7.53 and 2.8.3.-\n",
            "Checking enzymes: 2.1.3.12 and 2.3.1.168\n",
            "Checking enzymes: 2.1.3.12 and 5.3.1.12\n",
            "Checking enzymes: 2.1.3.12 and 4.1.1.51\n",
            "Checking enzymes: 2.1.3.12 and 1.13.11.2\n",
            "Checking enzymes: 2.3.1.168 and 3.5.4.19\n",
            "Checking enzymes: 2.3.1.168 and 5.3.1.12\n",
            "Checking enzymes: 2.3.1.168 and 4.1.1.51\n",
            "Checking enzymes: 2.3.1.168 and 2.7.4.27\n",
            "Checking enzymes: 2.3.1.168 and 1.13.11.2\n",
            "Checking enzymes: 2.3.1.168 and 2.3.1.245\n",
            "Checking enzymes: 3.5.4.19 and 5.3.1.12\n",
            "Checking enzymes: 3.5.4.19 and 1.13.11.2\n",
            "Checking enzymes: 5.3.1.12 and 4.1.1.51\n",
            "Checking enzymes: 5.3.1.12 and 1.13.11.2\n",
            "Checking enzymes: 4.1.1.51 and 2.7.4.27\n",
            "Checking enzymes: 4.1.1.51 and 1.13.11.2\n",
            "Checking enzymes: 2.7.4.27 and 1.13.11.2\n",
            "Checking enzymes: 1.13.11.2 and 2.3.1.245\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "# Read Wilcoxon y-values from file\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values2.txt', 'r') as y_file:\n",
        "    next(y_file)  # Skip header\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[pair_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "# Read data from final_sig_p_enzymes.csv\n",
        "with open('final_sig_p_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "# Diagnostic print: Check available enzyme names in the dataset\n",
        "available_enzymes = [row[0].strip() for row in data]\n",
        "print(f\"Available enzymes in the dataset: {available_enzymes[:20]}...\")  # Print first 20 enzymes for reference\n",
        "\n",
        "# Write the output to the x-values file\n",
        "with open('p_Wilcoxon_x-values2.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Pair', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for pair_name, y_positive_values in y_values.items():\n",
        "        # Handling the different enzyme pair cases\n",
        "        if '--' in pair_name:\n",
        "            # Case 2: x.x.x.-x.x.x.x (one hyphen in first enzyme, no hyphen in second enzyme)\n",
        "            if pair_name.count('--') == 1:\n",
        "                enzyme1 = pair_name[:pair_name.index('--') + 1].strip()  # First enzyme includes one hyphen\n",
        "                enzyme2 = pair_name[pair_name.index('--') + 2:].strip()  # Second enzyme starts after '--'\n",
        "            elif pair_name.count('--') == 2:\n",
        "                # Case 3: x.x.x.x-x.x.-- (second enzyme ends with '--')\n",
        "                enzyme1 = pair_name[:pair_name.rindex('--')].strip()  # First enzyme is before the last '--'\n",
        "                enzyme2 = pair_name[pair_name.rindex('--'):].strip()  # Second enzyme includes '--'\n",
        "        elif '-' in pair_name:\n",
        "            # Case 1: x.x.x.x-x.x.x.x (normal case with single hyphen)\n",
        "            enzyme_names = pair_name.split('-', 1)  # Split only at the first hyphen\n",
        "            enzyme1 = enzyme_names[0].strip()  # First enzyme\n",
        "            enzyme2 = enzyme_names[1].strip()  # Second enzyme\n",
        "            if enzyme2.endswith('-'):\n",
        "                # Case 4: x.x.x.x-x.x.x.- (second enzyme ends with hyphen)\n",
        "                enzyme2 = enzyme2  # Ensure second enzyme includes the trailing hyphen\n",
        "        else:\n",
        "            print(f\"Skipping invalid enzyme pair format: {pair_name}\")\n",
        "            continue  # Skip invalid formats that don't have a '-' or '--'\n",
        "\n",
        "        # Print the enzymes for debugging\n",
        "        print(f\"Checking enzymes: {enzyme1} and {enzyme2}\")\n",
        "\n",
        "        # Check if enzyme1 and enzyme2 are in the dataset\n",
        "        if enzyme1 not in available_enzymes or enzyme2 not in available_enzymes:\n",
        "            print(f\"Skipping pair {pair_name} because one or both enzymes are not in the dataset.\")\n",
        "            continue  # Skip this pair if any enzyme is not found in the dataset\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding row for enzyme1 and enzyme2 in the data\n",
        "            sample_row1 = next(row for row in data if row[0].strip() == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0].strip() == enzyme2)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1 and enzyme2\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the pair's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from both enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2))\n",
        "\n",
        "            # If unique values exist, write them to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Determine which enzyme corresponds to the value\n",
        "                    if value in unique_values_1:\n",
        "                        enzyme_name = enzyme1\n",
        "                    else:\n",
        "                        enzyme_name = enzyme2\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{pair_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kOe9qEsr9zm",
        "outputId": "6e533489-36a6-486a-8fb9-5f6725061ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Sample 'Samples' not found in pollution data.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples2.txt)\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples2.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[pair_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values2.txt)\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values2.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{pair_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU2.txt\n",
        "with open('p_MannU2.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into pair_name and enzyme_name (split only on the first space)\n",
        "        pair_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(pair_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the pair\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{pair_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0lDrOjLW4i0p"
      },
      "outputs": [],
      "source": [
        "# Open MannU2.txt and copy the enzyme pairs with p-values less than 0.1 for both enzymes to sig_combo2.txt\n",
        "with open('p_MannU2.txt', 'r') as mann_u_file, open('p_sig_combo2.txt', 'w') as output_file:\n",
        "\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "\n",
        "        if mann_u_value < 0.1:\n",
        "            next_values = next(mann_u_file, None)\n",
        "            if next_values is not None:\n",
        "                next_values = next_values.strip().split('\\t')\n",
        "                next_enzyme_name = next_values[1]\n",
        "                next_mann_u_value = float(next_values[2])\n",
        "\n",
        "                if next_mann_u_value < 0.1:\n",
        "                    output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                    output_file.write('\\t'.join([enzyme_pair, next_enzyme_name, str(next_mann_u_value)]) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLKnO9goOJ4T"
      },
      "source": [
        "### Combo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sRSxx9kFOJn6"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "from itertools import combinations  # To generate combinations of enzymes\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_p_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('p_combo3.txt', 'w') as output_file, \\\n",
        "     open('p_Wilcoxon_y-values3.txt', 'w') as y_file, \\\n",
        "     open('p_Wilcoxon_y-samples3.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Combo', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Combo', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    # Iterate over combinations of 3 enzymes\n",
        "    for combo in combinations(enzyme_list, 3):\n",
        "        enzyme1, enzyme2, enzyme3 = combo\n",
        "        values1, values2, values3 = enzyme_data[enzyme1], enzyme_data[enzyme2], enzyme_data[enzyme3]\n",
        "        count_matches = 0\n",
        "        positive_values = []\n",
        "        sample_list = []\n",
        "\n",
        "        # Compare the values of the three enzymes\n",
        "        for idx, (v1, v2, v3) in enumerate(zip(values1, values2, values3)):\n",
        "            if v1 > 0 and v2 > 0 and v3 > 0:\n",
        "                count_matches += 1\n",
        "                positive_values.append(f\"{v1}, {v2}, {v3}\")\n",
        "                sample_list.append(sample_names[idx])\n",
        "\n",
        "        if count_matches >= n:\n",
        "            # Calculate fraction of matches\n",
        "            fraction = enzyme_percentages[enzyme1] * enzyme_percentages[enzyme2] * enzyme_percentages[enzyme3]\n",
        "            distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "            p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "            # Write results to files\n",
        "            output_file.write(f'{enzyme1}\\t{enzyme2}\\t{enzyme3}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "            y_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}\\t{', '.join(positive_values)}\\n\")\n",
        "            samples_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOjfiFRPPBjO",
        "outputId": "e92736c4-9b37-4f26-84f3-41243c7490a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available enzymes in the dataset: ['5.4.99.15', '3.4.13.-', '1.2.1.39', '3.5.2.18', '2.1.1.13', '2.7.8.-', '3.1.26.5', '2.1.1.191', '3.4.21.53', '3.1.2.29', '4.1.3.-', '2.5.1.47', '4.3.1.19', '4.1.99.3', '4.6.1.1', '7.5.2.11', '1.4.1.1', '1.5.3.19', '1.1.1.346', '4.2.1.9']...\n",
            "Checking enzymes: 5.4.99.15, 1.2.1.39, 6.1.1.18\n",
            "Checking enzymes: 5.4.99.15, 3.4.21.53, 6.1.1.18\n",
            "Checking enzymes: 5.4.99.15, 2.5.1.47, 6.1.1.18\n",
            "Checking enzymes: 5.4.99.15, 2.5.1.47, 3.5.4.19\n",
            "Checking enzymes: 5.4.99.15, 6.1.1.18, 3.5.4.19\n",
            "Checking enzymes: 5.4.99.15, 6.1.1.18, 5.3.1.12\n",
            "Checking enzymes: 1.2.1.39, 2.1.1.13, 3.4.21.53\n",
            "Checking enzymes: 1.2.1.39, 2.1.1.13, 2.3.1.168\n",
            "Checking enzymes: 1.2.1.39-2.7.8.-, 6.1.1.18, None\n",
            "Skipping combo 1.2.1.39-2.7.8.--6.1.1.18 because one or more enzymes are not in the dataset.\n",
            "Checking enzymes: 1.2.1.39, 3.4.21.53, 6.1.1.18\n",
            "Checking enzymes: 2.1.1.13, 3.1.26.5, 4.6.1.1\n",
            "Checking enzymes: 2.1.1.13, 3.1.26.5, 2.3.1.168\n",
            "Checking enzymes: 2.1.1.13, 3.4.21.53, 2.5.1.47\n",
            "Checking enzymes: 2.1.1.13, 3.4.21.53, 6.1.1.18\n",
            "Checking enzymes: 2.1.1.13, 4.6.1.1, 2.3.1.168\n",
            "Checking enzymes: 2.7.8.-, 3.4.21.53, 6.1.1.18\n",
            "Checking enzymes: 2.7.8.-, 6.1.1.18, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 3.4.21.53, 2.5.1.47\n",
            "Checking enzymes: 3.1.26.5, 3.4.21.53, 4.6.1.1\n",
            "Checking enzymes: 3.1.26.5, 3.4.21.53, 6.1.1.18\n",
            "Checking enzymes: 3.1.26.5, 3.4.21.53, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 3.1.2.29, 3.5.1.104\n",
            "Checking enzymes: 3.1.26.5, 3.1.2.29, 4.1.1.51\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.6.1.1\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 1.4.1.1\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 6.1.1.18\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 3.5.1.104\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.1.1.51\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 1.13.11.2\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 1.4.1.1\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 4.2.1.9\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 2.7.4.25\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 6.1.1.18\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 3.5.1.104\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 2.1.3.12\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 4.1.1.51\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 1.13.11.2\n",
            "Checking enzymes: 3.1.26.5, 1.4.1.1, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 3.1.26.5, 6.1.1.18, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 6.1.1.18, 2.1.3.12\n",
            "Checking enzymes: 3.1.26.5, 6.1.1.18, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 3.1.26.5, 3.5.1.104, 4.1.1.51\n",
            "Checking enzymes: 3.1.26.5, 1.1.1.16, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 1.1.1.16, 1.13.11.2\n",
            "Checking enzymes: 3.1.26.5, 1.1.1.175, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 1.1.1.175, 1.13.11.2\n",
            "Checking enzymes: 3.1.26.5, 2.1.3.12, 4.1.1.51\n",
            "Checking enzymes: 3.1.26.5, 2.3.1.168, 1.13.11.2\n",
            "Checking enzymes: 2.1.1.191, 3.4.21.53, 4.3.1.19\n",
            "Checking enzymes: 2.1.1.191, 3.4.21.53, 6.1.1.18\n",
            "Checking enzymes: 2.1.1.191, 3.4.21.53, 3.5.1.104\n",
            "Checking enzymes: 2.1.1.191, 3.1.2.29, 3.5.1.104\n",
            "Checking enzymes: 2.1.1.191, 4.3.1.19, 3.5.1.104\n",
            "Checking enzymes: 2.1.1.191, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 3.4.21.53, 3.1.2.29, 6.1.1.18\n",
            "Checking enzymes: 3.4.21.53, 3.1.2.29, 3.5.1.104\n",
            "Checking enzymes: 3.4.21.53, 2.5.1.47, 4.6.1.1\n",
            "Checking enzymes: 3.4.21.53, 2.5.1.47, 1.4.1.1\n",
            "Checking enzymes: 3.4.21.53, 2.5.1.47, 6.1.1.18\n",
            "Checking enzymes: 3.4.21.53, 2.5.1.47, 4.1.1.51\n",
            "Checking enzymes: 3.4.21.53, 4.3.1.19, 6.1.1.18\n",
            "Checking enzymes: 3.4.21.53, 4.6.1.1, 6.1.1.18\n",
            "Checking enzymes: 3.4.21.53, 4.6.1.1, 1.1.1.16\n",
            "Checking enzymes: 3.4.21.53, 1.4.1.1, 6.1.1.18\n",
            "Checking enzymes: 3.4.21.53, 2.7.4.25, 6.1.1.18\n",
            "Checking enzymes: 3.4.21.53, 2.7.4.25, 3.5.4.19\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 2.6.1.113\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 1.1.1.16\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 2.7.7.53\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 2.3.1.168\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 5.3.1.12\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 4.1.1.51\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 3.4.21.53, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 3.4.21.53, 2.7.7.53, 2.8.3.-\n",
            "Checking enzymes: 3.1.2.29, 2.5.1.47, 6.1.1.18\n",
            "Checking enzymes: 3.1.2.29, 1.4.1.1, 6.1.1.18\n",
            "Checking enzymes: 3.1.2.29, 6.1.1.18, 2.6.1.113\n",
            "Checking enzymes: 3.1.2.29, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 3.1.2.29, 6.1.1.18, 2.3.1.168\n",
            "Checking enzymes: 3.1.2.29, 6.1.1.18, 4.1.1.51\n",
            "Checking enzymes: 3.1.2.29, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 3.1.2.29, 3.5.1.104, 2.3.1.168\n",
            "Checking enzymes: 3.1.2.29, 3.5.1.104, 4.1.1.51\n",
            "Checking enzymes: 3.1.2.29, 1.1.1.175, 2.3.1.168\n",
            "Checking enzymes: 4.1.3.-, 4.3.1.19, 4.6.1.1\n",
            "Checking enzymes: 4.1.3.-, 4.3.1.19, 1.4.1.1\n",
            "Checking enzymes: 2.5.1.47, 4.3.1.19, 6.1.1.18\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 1.4.1.1\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 6.1.1.18\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 3.5.1.104\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 1.1.1.16\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 2.3.1.168\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 4.1.1.51\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 1.13.11.2\n",
            "Checking enzymes: 2.5.1.47, 1.4.1.1, 6.1.1.18\n",
            "Checking enzymes: 2.5.1.47, 1.4.1.1, 1.1.1.16\n",
            "Checking enzymes: 2.5.1.47, 1.4.1.1, 4.1.1.51\n",
            "Checking enzymes: 2.5.1.47, 1.4.1.1, 1.13.11.2\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 2.6.1.113\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 1.1.1.175\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 2.1.3.12\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 2.3.1.168\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 3.5.4.19\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 5.3.1.12\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 4.1.1.51\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 2.5.1.47, 1.1.1.175, 2.3.1.168\n",
            "Checking enzymes: 2.5.1.47, 1.1.1.175, 1.13.11.2\n",
            "Checking enzymes: 2.5.1.47, 2.1.3.12, 4.1.1.51\n",
            "Checking enzymes: 2.5.1.47, 2.3.1.168, 3.5.4.19\n",
            "Checking enzymes: 2.5.1.47, 2.3.1.168, 4.1.1.51\n",
            "Checking enzymes: 2.5.1.47, 2.3.1.168, 1.13.11.2\n",
            "Checking enzymes: 4.3.1.19, 1.4.1.1, 6.1.1.18\n",
            "Checking enzymes: 4.3.1.19, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 4.3.1.19, 3.5.1.104, 4.1.1.51\n",
            "Checking enzymes: 4.3.1.19, 4.1.1.51, 1.13.11.2\n",
            "Checking enzymes: 4.1.99.3, 4.6.1.1, 2.3.1.168\n",
            "Checking enzymes: 4.6.1.1, 1.4.1.1, 1.1.1.16\n",
            "Checking enzymes: 4.6.1.1, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 4.6.1.1, 6.1.1.18, 1.1.1.16\n",
            "Checking enzymes: 4.6.1.1, 6.1.1.18, 2.1.3.12\n",
            "Checking enzymes: 4.6.1.1, 6.1.1.18, 2.3.1.168\n",
            "Checking enzymes: 4.6.1.1, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 4.6.1.1, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 4.6.1.1, 1.1.1.16, 2.3.1.168\n",
            "Checking enzymes: 4.6.1.1, 1.1.1.16, 1.13.11.2\n",
            "Checking enzymes: 7.5.2.11, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 1.4.1.1, 6.1.1.18, 6.4.-.-\n",
            "Checking enzymes: 1.4.1.1, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 1.4.1.1, 6.1.1.18, 1.1.1.175\n",
            "Checking enzymes: 1.4.1.1, 6.1.1.18, 5.3.1.12\n",
            "Checking enzymes: 1.4.1.1, 6.1.1.18, 4.1.1.51\n",
            "Checking enzymes: 1.4.1.1, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 1.4.1.1, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 1.4.1.1, 1.1.1.175, 2.3.1.168\n",
            "Checking enzymes: 1.4.1.1, 1.1.1.175, 1.13.11.2\n",
            "Checking enzymes: 1.4.1.1, 2.3.1.168, 1.13.11.2\n",
            "Checking enzymes: 1.4.1.1, 4.1.1.51, 1.13.11.2\n",
            "Checking enzymes: 4.2.1.9, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 2.7.4.25, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 2.7.4.25, 3.5.1.104, 2.7.7.53\n",
            "Checking enzymes: 2.7.4.25, 1.1.1.16, 1.13.11.2\n",
            "Checking enzymes: 2.7.4.25, 1.1.1.175, 1.13.11.2\n",
            "Checking enzymes: 6.1.1.18, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 6.1.1.18, 3.5.1.104, 4.1.1.51\n",
            "Checking enzymes: 6.1.1.18, 3.5.1.104, 1.13.11.2\n",
            "Checking enzymes: 6.1.1.18, 1.1.1.16, 1.13.11.2\n",
            "Checking enzymes: 6.1.1.18, 1.1.1.175, 2.3.1.168\n",
            "Checking enzymes: 6.1.1.18, 1.1.1.175, 1.13.11.2\n",
            "Checking enzymes: 6.1.1.18, 2.3.1.168, 3.5.4.19\n",
            "Checking enzymes: 2.6.1.113, 3.5.1.104, 2.7.7.53\n",
            "Checking enzymes: 2.6.1.113, 3.5.1.104, 2.1.3.12\n",
            "Checking enzymes: 2.6.1.113, 3.5.1.104, 2.3.1.168\n",
            "Checking enzymes: 2.6.1.113, 3.5.1.104, 4.1.1.51\n",
            "Checking enzymes: 3.5.1.104, 2.7.7.53, 1.14.14.84\n",
            "Checking enzymes: 3.5.1.104, 2.7.7.53, 2.3.1.168\n",
            "Checking enzymes: 3.5.1.104, 4.1.1.51, 1.13.11.2\n",
            "Checking enzymes: 1.1.1.16, 1.1.1.175, 1.13.11.2\n",
            "Checking enzymes: 1.1.1.175, 2.3.1.168, 3.5.4.19\n",
            "Checking enzymes: 1.1.1.175, 2.3.1.168, 1.13.11.2\n",
            "Checking enzymes: 1.1.1.175, 4.1.1.51, 1.13.11.2\n",
            "Checking enzymes: 2.3.1.168, 4.1.1.51, 1.13.11.2\n",
            "Checking enzymes: 2.3.1.168, 1.13.11.2, 2.3.1.245\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "# Read Wilcoxon y-values from file\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values3.txt', 'r') as y_file:\n",
        "    next(y_file)  # Skip header\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        combo_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[combo_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "# Read data from final_sig_p_enzymes.csv\n",
        "with open('final_sig_p_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "# Diagnostic print: Check available enzyme names in the dataset\n",
        "available_enzymes = [row[0].strip() for row in data]\n",
        "print(f\"Available enzymes in the dataset: {available_enzymes[:20]}...\")  # Print first 20 enzymes for reference\n",
        "\n",
        "# Write the output to the x-values file\n",
        "with open('p_Wilcoxon_x-values3.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Combo', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for combo_name, y_positive_values in y_values.items():\n",
        "        # Handling the different enzyme trio cases\n",
        "        if '--' in combo_name:\n",
        "            # Case 2: x.x.x.-x.x.x.x-x.x.x.x (one hyphen in first enzyme, no hyphen in second or third enzyme)\n",
        "            if combo_name.count('--') == 1:\n",
        "                enzyme1 = combo_name[:combo_name.index('--') + 1].strip()  # First enzyme includes one hyphen\n",
        "                remainder = combo_name[combo_name.index('--') + 2:].strip()\n",
        "                # Check if there's a second hyphen to split\n",
        "                if '-' in remainder:\n",
        "                    enzyme2, enzyme3 = remainder.split('-', 1)\n",
        "                    enzyme2, enzyme3 = enzyme2.strip(), enzyme3.strip()\n",
        "                else:\n",
        "                    # If no second hyphen, assume it's just one enzyme in the remainder\n",
        "                    enzyme2 = remainder.strip()\n",
        "                    enzyme3 = None  # There's no third enzyme\n",
        "            # Case 3: x.x.x.x-x.x.x.x-x.x.x.- (second enzyme ends with '--')\n",
        "            elif combo_name.count('--') == 2:\n",
        "                enzyme1 = combo_name[:combo_name.index('--')].strip()  # First enzyme before '--'\n",
        "                remainder = combo_name[combo_name.index('--') + 2:].strip()\n",
        "                enzyme2, enzyme3 = remainder.split('-', 1)\n",
        "                enzyme2, enzyme3 = enzyme2.strip(), enzyme3.strip()\n",
        "                enzyme3 = enzyme3.strip()\n",
        "            # Case 4: x.x.x.x-x.x.x.--x.x.x.x (second enzyme ends with '--' and has a trailing hyphen)\n",
        "            elif combo_name.count('--') == 3:\n",
        "                enzyme1 = combo_name[:combo_name.index('-')].strip()  # First enzyme before '--'\n",
        "                remainder = combo_name[combo_name.index('-') + 2:].strip()  # The part after the first '--'\n",
        "                enzyme2 = remainder[:remainder.index('--') + 1].strip()  # Second enzyme with one trailing hyphen\n",
        "                enzyme3 = remainder[remainder.index('--') + 2:].strip()  # Third enzyme\n",
        "\n",
        "        elif '-' in combo_name:\n",
        "            # Case 1: x.x.x.x-x.x.x.x-x.x.x.x (standard case with three enzymes connected by hyphens)\n",
        "            enzyme_names = combo_name.split('-', 2)  # Split at the first two hyphens\n",
        "            enzyme1 = enzyme_names[0].strip()  # First enzyme\n",
        "            enzyme2 = enzyme_names[1].strip()  # Second enzyme\n",
        "            enzyme3 = enzyme_names[2].strip()  # Third enzyme\n",
        "        else:\n",
        "            print(f\"Skipping invalid enzyme trio format: {combo_name}\")\n",
        "            continue  # Skip invalid formats that don't match the expected hyphen patterns\n",
        "\n",
        "        # Print the enzymes for debugging\n",
        "        print(f\"Checking enzymes: {enzyme1}, {enzyme2}, {enzyme3}\")\n",
        "\n",
        "        # Check if enzyme1, enzyme2, and enzyme3 are in the dataset\n",
        "        if enzyme1 not in available_enzymes or enzyme2 not in available_enzymes or enzyme3 not in available_enzymes:\n",
        "            print(f\"Skipping combo {combo_name} because one or more enzymes are not in the dataset.\")\n",
        "            continue  # Skip this trio if any enzyme is not found in the dataset\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding rows for enzyme1, enzyme2, and enzyme3 in the data\n",
        "            sample_row1 = next(row for row in data if row[0].strip() == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0].strip() == enzyme2)\n",
        "            sample_row3 = next(row for row in data if row[0].strip() == enzyme3)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1, enzyme2, and enzyme3\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "            sample_positive_values_3 = [float(value) for value in sample_row3[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the trio's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "            unique_values_3 = set(sample_positive_values_3) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from all three enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2).union(unique_values_3))\n",
        "\n",
        "            # If unique values exist, write them to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Determine which enzyme corresponds to the value\n",
        "                    if value in unique_values_1:\n",
        "                        enzyme_name = enzyme1\n",
        "                    elif value in unique_values_2:\n",
        "                        enzyme_name = enzyme2\n",
        "                    else:\n",
        "                        enzyme_name = enzyme3\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{combo_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIyrJeI8PFTu",
        "outputId": "7db86631-fb93-4c26-e45a-5c5d9c67074c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Sample 'Samples' not found in pollution data.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples3.txt) for enzyme triplets\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples3.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        trio_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[trio_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values3.txt) for enzyme triplets\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values3.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        trio_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{trio_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU3.txt\n",
        "with open('p_MannU3.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Trio', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into trio_name and enzyme_name (split only on the first space)\n",
        "        trio_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(trio_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the trio\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{trio_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('p_MannU3.txt', 'r') as mann_u_file, open('p_sig_combo3.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n"
      ],
      "metadata": {
        "id": "jgx72KTc5kGx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I11PWoNhQnk6"
      },
      "source": [
        "### Combo 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "9JObnKOsQooG"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "from itertools import combinations  # To generate combinations of 4 enzymes\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_p_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('p_combo4.txt', 'w') as output_file, \\\n",
        "     open('p_Wilcoxon_y-values4.txt', 'w') as y_file, \\\n",
        "     open('p_Wilcoxon_y-samples4.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Combo', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Combo', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    # Generate all combinations of 4 enzymes\n",
        "    enzyme_combos = combinations(enzyme_list, 4)\n",
        "\n",
        "    for combo in enzyme_combos:\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4 = combo\n",
        "        values1, values2, values3, values4 = enzyme_data[enzyme1], enzyme_data[enzyme2], enzyme_data[enzyme3], enzyme_data[enzyme4]\n",
        "        count_matches = 0\n",
        "        positive_values = []\n",
        "        sample_list = []\n",
        "\n",
        "        # Iterate over samples to check for matching positive values\n",
        "        for idx, (v1, v2, v3, v4) in enumerate(zip(values1, values2, values3, values4)):\n",
        "            if v1 > 0 and v2 > 0 and v3 > 0 and v4 > 0:\n",
        "                count_matches += 1\n",
        "                positive_values.append(str(v1))  # Collect positive values (can be from any enzyme)\n",
        "                sample_list.append(sample_names[idx])  # Collect the samples that have matches\n",
        "\n",
        "        # If there are enough matches, calculate the binomial distribution and p-value\n",
        "        if count_matches >= n:\n",
        "            # Calculate the fraction of matches for the four enzymes combined\n",
        "            fraction = enzyme_percentages[enzyme1] * enzyme_percentages[enzyme2] * enzyme_percentages[enzyme3] * enzyme_percentages[enzyme4]\n",
        "\n",
        "            # Calculate binomial distribution\n",
        "            distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "\n",
        "            # Calculate p-value (sum of binomial probabilities from count_matches to total_samples)\n",
        "            p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "            # Write results to the output files\n",
        "            output_file.write(f'{enzyme1}\\t{enzyme2}\\t{enzyme3}\\t{enzyme4}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "            y_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}\\t{', '.join(positive_values)}\\n\")\n",
        "            samples_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "mHWsAqGwRNbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cf8712-ccbf-4b00-d31d-585bed2e0783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available enzymes in the dataset: ['5.4.99.15', '3.4.13.-', '1.2.1.39', '3.5.2.18', '2.1.1.13', '2.7.8.-', '3.1.26.5', '2.1.1.191', '3.4.21.53', '3.1.2.29', '4.1.3.-', '2.5.1.47', '4.3.1.19', '4.1.99.3', '4.6.1.1', '7.5.2.11', '1.4.1.1', '1.5.3.19', '1.1.1.346', '4.2.1.9']...\n",
            "Checking enzymes: 3.1.26.5, 3.4.21.53, 2.5.1.47, 4.6.1.1\n",
            "Checking enzymes: 3.1.26.5, 3.4.21.53, 2.5.1.47, 6.1.1.18\n",
            "Checking enzymes: 3.1.26.5, 3.4.21.53, 4.6.1.1, 6.1.1.18\n",
            "Checking enzymes: 3.1.26.5, 3.4.21.53, 4.6.1.1, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.6.1.1, 1.4.1.1\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.6.1.1, 6.1.1.18\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.6.1.1, 3.5.1.104\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.6.1.1, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.6.1.1, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.6.1.1, 4.1.1.51\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 4.6.1.1, 1.13.11.2\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 1.4.1.1, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 2.5.1.47, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 1.4.1.1, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 6.1.1.18, 1.1.1.16\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 6.1.1.18, 2.1.3.12\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 6.1.1.18, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 6.1.1.18, 1.13.11.2\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 1.1.1.16, 2.3.1.168\n",
            "Checking enzymes: 3.1.26.5, 4.6.1.1, 1.1.1.16, 1.13.11.2\n",
            "Checking enzymes: 3.1.26.5, 1.1.1.175, 2.3.1.168, 1.13.11.2\n",
            "Checking enzymes: 3.4.21.53, 3.1.2.29, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 3.4.21.53, 2.5.1.47, 4.6.1.1, 6.1.1.18\n",
            "Checking enzymes: 3.4.21.53, 2.5.1.47, 6.1.1.18, 4.1.1.51\n",
            "Checking enzymes: 3.4.21.53, 6.1.1.18, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 3.1.2.29, 6.1.1.18, 2.6.1.113, 3.5.1.104\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 1.4.1.1, 1.1.1.16\n",
            "Checking enzymes: 2.5.1.47, 4.6.1.1, 6.1.1.18, 3.5.1.104\n",
            "Checking enzymes: 2.5.1.47, 6.1.1.18, 2.3.1.168, 3.5.4.19\n",
            "Checking enzymes: 2.5.1.47, 1.1.1.175, 2.3.1.168, 1.13.11.2\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "# Read Wilcoxon y-values from file\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values4.txt', 'r') as y_file:  # Updated to read 4-enzyme values file\n",
        "    next(y_file)  # Skip header\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        combo_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[combo_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "# Read data from final_sig_p_enzymes.csv\n",
        "with open('final_sig_p_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "# Diagnostic print: Check available enzyme names in the dataset\n",
        "available_enzymes = [row[0].strip() for row in data]\n",
        "print(f\"Available enzymes in the dataset: {available_enzymes[:20]}...\")  # Print first 20 enzymes for reference\n",
        "\n",
        "# Write the output to the x-values file\n",
        "with open('p_Wilcoxon_x-values4.txt', 'w') as x_output_file:  # Updated to output 4-enzyme file\n",
        "    x_output_file.write('\\t'.join(['Enzyme Combo', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for combo_name, y_positive_values in y_values.items():\n",
        "        # Handling the different enzyme combo cases for 4 enzymes\n",
        "        if '-' in combo_name:\n",
        "            # Case: Four enzymes connected by hyphens\n",
        "            enzyme_names = combo_name.split('-', 3)  # Split at the first three hyphens\n",
        "            if len(enzyme_names) == 4:\n",
        "                enzyme1 = enzyme_names[0].strip()  # First enzyme\n",
        "                enzyme2 = enzyme_names[1].strip()  # Second enzyme\n",
        "                enzyme3 = enzyme_names[2].strip()  # Third enzyme\n",
        "                enzyme4 = enzyme_names[3].strip()  # Fourth enzyme\n",
        "            else:\n",
        "                print(f\"Skipping invalid enzyme combo format (not exactly four enzymes): {combo_name}\")\n",
        "                continue  # Skip invalid formats that don't have four enzymes\n",
        "\n",
        "        else:\n",
        "            print(f\"Skipping invalid enzyme combo format (no hyphens detected): {combo_name}\")\n",
        "            continue  # Skip invalid formats that don't have hyphens\n",
        "\n",
        "        # Print the enzymes for debugging\n",
        "        print(f\"Checking enzymes: {enzyme1}, {enzyme2}, {enzyme3}, {enzyme4}\")\n",
        "\n",
        "        # Check if enzyme1, enzyme2, enzyme3, and enzyme4 are in the dataset\n",
        "        if enzyme1 not in available_enzymes or enzyme2 not in available_enzymes or enzyme3 not in available_enzymes or enzyme4 not in available_enzymes:\n",
        "            print(f\"Skipping combo {combo_name} because one or more enzymes are not in the dataset.\")\n",
        "            continue  # Skip this combo if any enzyme is not found in the dataset\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding rows for enzyme1, enzyme2, enzyme3, and enzyme4 in the data\n",
        "            sample_row1 = next(row for row in data if row[0].strip() == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0].strip() == enzyme2)\n",
        "            sample_row3 = next(row for row in data if row[0].strip() == enzyme3)\n",
        "            sample_row4 = next(row for row in data if row[0].strip() == enzyme4)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1, enzyme2, enzyme3, and enzyme4\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "            sample_positive_values_3 = [float(value) for value in sample_row3[1:] if float(value) > 0]\n",
        "            sample_positive_values_4 = [float(value) for value in sample_row4[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the combo's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "            unique_values_3 = set(sample_positive_values_3) - set(y_positive_values)\n",
        "            unique_values_4 = set(sample_positive_values_4) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from all four enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2).union(unique_values_3).union(unique_values_4))\n",
        "\n",
        "            # If unique values exist, write them to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Determine which enzyme corresponds to the value\n",
        "                    if value in unique_values_1:\n",
        "                        enzyme_name = enzyme1\n",
        "                    elif value in unique_values_2:\n",
        "                        enzyme_name = enzyme2\n",
        "                    elif value in unique_values_3:\n",
        "                        enzyme_name = enzyme3\n",
        "                    else:\n",
        "                        enzyme_name = enzyme4\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{combo_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXBqNSS5Rddp",
        "outputId": "867be31d-5c02-4a28-b0dc-b91f621fa957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Sample 'Samples' not found in pollution data.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples4.txt) for enzyme quadruples\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples4.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quadruple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[quadruple_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values4.txt) for enzyme quadruples\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values4.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quadruple_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{quadruple_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU4.txt\n",
        "with open('p_MannU4.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Quadruple', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into quadruple_name and enzyme_name (split only on the first space)\n",
        "        quadruple_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(quadruple_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the quadruple\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{quadruple_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('p_MannU4.txt', 'r') as mann_u_file, open('p_sig_combo4.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "        next_values_4 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None and next_values_4 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "            next_values_4 = next_values_4.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            next_enzyme_name_4 = next_values_4[1]\n",
        "            next_mann_u_value_4 = float(next_values_4[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1 and next_mann_u_value_4 < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_4, str(next_mann_u_value_4)]) + '\\n')\n"
      ],
      "metadata": {
        "id": "Paj1hww25dBK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGoG6MVeRkMO"
      },
      "source": [
        "### Combo 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "fL3Zfq0kRlbe"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "from itertools import combinations  # To generate combinations of 5 enzymes\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_p_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('p_combo5.txt', 'w') as output_file, \\\n",
        "     open('p_Wilcoxon_y-values5.txt', 'w') as y_file, \\\n",
        "     open('p_Wilcoxon_y-samples5.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Enzyme5', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Combo', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Combo', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    # Generate all combinations of 5 enzymes\n",
        "    enzyme_combos = combinations(enzyme_list, 5)\n",
        "\n",
        "    for combo in enzyme_combos:\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4, enzyme5 = combo\n",
        "        values1, values2, values3, values4, values5 = enzyme_data[enzyme1], enzyme_data[enzyme2], enzyme_data[enzyme3], enzyme_data[enzyme4], enzyme_data[enzyme5]\n",
        "        count_matches = 0\n",
        "        positive_values = []\n",
        "        sample_list = []\n",
        "\n",
        "        # Iterate over samples to check for matching positive values\n",
        "        for idx, (v1, v2, v3, v4, v5) in enumerate(zip(values1, values2, values3, values4, values5)):\n",
        "            if v1 > 0 and v2 > 0 and v3 > 0 and v4 > 0 and v5 > 0:\n",
        "                count_matches += 1\n",
        "                positive_values.append(str(v1))  # Collect positive values (can be from any enzyme)\n",
        "                sample_list.append(sample_names[idx])  # Collect the samples that have matches\n",
        "\n",
        "        # If there are enough matches, calculate the binomial distribution and p-value\n",
        "        if count_matches >= n:\n",
        "            # Calculate the fraction of matches for the five enzymes combined\n",
        "            fraction = (enzyme_percentages[enzyme1] *\n",
        "                        enzyme_percentages[enzyme2] *\n",
        "                        enzyme_percentages[enzyme3] *\n",
        "                        enzyme_percentages[enzyme4] *\n",
        "                        enzyme_percentages[enzyme5])\n",
        "\n",
        "            # Calculate binomial distribution\n",
        "            distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "\n",
        "            # Calculate p-value (sum of binomial probabilities from count_matches to total_samples)\n",
        "            p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "            # Write results to the output files\n",
        "            output_file.write(f'{enzyme1}\\t{enzyme2}\\t{enzyme3}\\t{enzyme4}\\t{enzyme5}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "            y_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}-{enzyme5}\\t{', '.join(positive_values)}\\n\")\n",
        "            samples_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}-{enzyme5}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rit0NF7XR37p"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Read Wilcoxon y-values from file\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values5.txt', 'r') as y_file:\n",
        "    next(y_file)  # Skip header\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quintuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[quintuple_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "# Read data from final_sig_p_enzymes.csv\n",
        "with open('final_sig_p_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "# Write the output to the x-values file\n",
        "with open('p_Wilcoxon_x-values5.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Quintuple', 'Sample Name', 'Enzyme Name', 'Value']) + '\\n')\n",
        "\n",
        "    for quintuple_name, y_positive_values in y_values.items():\n",
        "        # Clean enzyme names by stripping leading/trailing dashes\n",
        "        quintuple_name_parts = quintuple_name.split('-')\n",
        "\n",
        "        # Ensure that we have exactly 5 enzymes in the quintuple name\n",
        "        if len(quintuple_name_parts) != 5:\n",
        "            print(f\"Skipping invalid quintuple: {quintuple_name}\")\n",
        "            continue\n",
        "\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4, enzyme5 = quintuple_name_parts  # Assign enzymes\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding rows for enzyme1, enzyme2, enzyme3, enzyme4, and enzyme5 in the data\n",
        "            sample_row1 = next(row for row in data if row[0] == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0] == enzyme2)\n",
        "            sample_row3 = next(row for row in data if row[0] == enzyme3)\n",
        "            sample_row4 = next(row for row in data if row[0] == enzyme4)\n",
        "            sample_row5 = next(row for row in data if row[0] == enzyme5)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1, enzyme2, enzyme3, enzyme4, and enzyme5\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "            sample_positive_values_3 = [float(value) for value in sample_row3[1:] if float(value) > 0]\n",
        "            sample_positive_values_4 = [float(value) for value in sample_row4[1:] if float(value) > 0]\n",
        "            sample_positive_values_5 = [float(value) for value in sample_row5[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the quintuple's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "            unique_values_3 = set(sample_positive_values_3) - set(y_positive_values)\n",
        "            unique_values_4 = set(sample_positive_values_4) - set(y_positive_values)\n",
        "            unique_values_5 = set(sample_positive_values_5) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from all five enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2).union(unique_values_3).union(unique_values_4).union(unique_values_5))\n",
        "\n",
        "            # If unique values exist, find the enzyme names and write to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Try to find the enzyme name corresponding to the positive value by comparing the values as floats\n",
        "                    try:\n",
        "                        enzyme_name = header[sample_row1[1:].index(str(value)) + 1]  # Shift by 1 to match the enzyme name\n",
        "                    except ValueError:\n",
        "                        # In case the value is not found due to small precision differences, skip\n",
        "                        continue\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{quintuple_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9tTFJh7SUVP",
        "outputId": "e077f27b-9eb6-4500-e678-f88899007f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Sample 'Samples' not found in pollution data.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples5.txt) for enzyme quintuples (5 enzymes)\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples5.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quintuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[quintuple_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values5.txt) for enzyme quintuples (5 enzymes)\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values5.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quintuple_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{quintuple_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU5.txt\n",
        "with open('p_MannU5.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Quintuple', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into quintuple_name and enzyme_name (split only on the first space)\n",
        "        quintuple_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(quintuple_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the quintuple\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{quintuple_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e-2HLdzTtTZ"
      },
      "source": [
        "### Combo 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTTRJFaTTufA"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "from itertools import combinations  # To generate combinations of 6 enzymes\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_p_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('p_combo6.txt', 'w') as output_file, \\\n",
        "     open('p_Wilcoxon_y-values6.txt', 'w') as y_file, \\\n",
        "     open('p_Wilcoxon_y-samples6.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Enzyme5', 'Enzyme6', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Combo', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Combo', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    # Generate all combinations of 6 enzymes\n",
        "    enzyme_combos = combinations(enzyme_list, 6)\n",
        "\n",
        "    for combo in enzyme_combos:\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4, enzyme5, enzyme6 = combo\n",
        "        values1, values2, values3, values4, values5, values6 = enzyme_data[enzyme1], enzyme_data[enzyme2], enzyme_data[enzyme3], enzyme_data[enzyme4], enzyme_data[enzyme5], enzyme_data[enzyme6]\n",
        "        count_matches = 0\n",
        "        positive_values = []\n",
        "        sample_list = []\n",
        "\n",
        "        # Iterate over samples to check for matching positive values\n",
        "        for idx, (v1, v2, v3, v4, v5, v6) in enumerate(zip(values1, values2, values3, values4, values5, values6)):\n",
        "            if v1 > 0 and v2 > 0 and v3 > 0 and v4 > 0 and v5 > 0 and v6 > 0:\n",
        "                count_matches += 1\n",
        "                positive_values.append(str(v1))  # Collect positive values (can be from any enzyme)\n",
        "                sample_list.append(sample_names[idx])  # Collect the samples that have matches\n",
        "\n",
        "        # If there are enough matches, calculate the binomial distribution and p-value\n",
        "        if count_matches >= n:\n",
        "            # Calculate the fraction of matches for the six enzymes combined\n",
        "            fraction = (enzyme_percentages[enzyme1] *\n",
        "                        enzyme_percentages[enzyme2] *\n",
        "                        enzyme_percentages[enzyme3] *\n",
        "                        enzyme_percentages[enzyme4] *\n",
        "                        enzyme_percentages[enzyme5] *\n",
        "                        enzyme_percentages[enzyme6])\n",
        "\n",
        "            # Calculate binomial distribution\n",
        "            distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "\n",
        "            # Calculate p-value (sum of binomial probabilities from count_matches to total_samples)\n",
        "            p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "            # Write results to the output files\n",
        "            output_file.write(f'{enzyme1}\\t{enzyme2}\\t{enzyme3}\\t{enzyme4}\\t{enzyme5}\\t{enzyme6}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "            y_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}-{enzyme5}-{enzyme6}\\t{', '.join(positive_values)}\\n\")\n",
        "            samples_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}-{enzyme5}-{enzyme6}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNtnBq7NUJQl"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Read Wilcoxon y-values from file\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-values6.txt', 'r') as y_file:\n",
        "    next(y_file)  # Skip header\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[sextuple_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "# Read data from final_sig_p_enzymes.csv\n",
        "with open('final_sig_p_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "# Write the output to the x-values file\n",
        "with open('p_Wilcoxon_x-values6.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Sextuple', 'Sample Name', 'Enzyme Name', 'Value']) + '\\n')\n",
        "\n",
        "    for sextuple_name, y_positive_values in y_values.items():\n",
        "        # Clean enzyme names by stripping leading/trailing dashes\n",
        "        sextuple_name_parts = sextuple_name.split('-')\n",
        "\n",
        "        # Ensure that we have exactly 6 enzymes in the sextuple name\n",
        "        if len(sextuple_name_parts) != 6:\n",
        "            print(f\"Skipping invalid sextuple: {sextuple_name}\")\n",
        "            continue\n",
        "\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4, enzyme5, enzyme6 = sextuple_name_parts  # Assign enzymes\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding rows for enzyme1, enzyme2, enzyme3, enzyme4, enzyme5, and enzyme6 in the data\n",
        "            sample_row1 = next(row for row in data if row[0] == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0] == enzyme2)\n",
        "            sample_row3 = next(row for row in data if row[0] == enzyme3)\n",
        "            sample_row4 = next(row for row in data if row[0] == enzyme4)\n",
        "            sample_row5 = next(row for row in data if row[0] == enzyme5)\n",
        "            sample_row6 = next(row for row in data if row[0] == enzyme6)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1, enzyme2, enzyme3, enzyme4, enzyme5, and enzyme6\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "            sample_positive_values_3 = [float(value) for value in sample_row3[1:] if float(value) > 0]\n",
        "            sample_positive_values_4 = [float(value) for value in sample_row4[1:] if float(value) > 0]\n",
        "            sample_positive_values_5 = [float(value) for value in sample_row5[1:] if float(value) > 0]\n",
        "            sample_positive_values_6 = [float(value) for value in sample_row6[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the sextuple's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "            unique_values_3 = set(sample_positive_values_3) - set(y_positive_values)\n",
        "            unique_values_4 = set(sample_positive_values_4) - set(y_positive_values)\n",
        "            unique_values_5 = set(sample_positive_values_5) - set(y_positive_values)\n",
        "            unique_values_6 = set(sample_positive_values_6) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from all six enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2).union(unique_values_3).union(unique_values_4).union(unique_values_5).union(unique_values_6))\n",
        "\n",
        "            # If unique values exist, find the enzyme names and write to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Try to find the enzyme name corresponding to the positive value by comparing the values as floats\n",
        "                    try:\n",
        "                        enzyme_name = header[sample_row1[1:].index(str(value)) + 1]  # Shift by 1 to match the enzyme name\n",
        "                    except ValueError:\n",
        "                        # In case the value is not found due to small precision differences, skip\n",
        "                        continue\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{sextuple_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU4mVcnYU8wf"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples6.txt) for enzyme sextuples (6 enzymes)\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples6.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[sextuple_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values6.txt) for enzyme sextuples (6 enzymes)\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values6.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{sextuple_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU6.txt\n",
        "with open('p_MannU6.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Sextuple', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into sextuple_name and enzyme_name (split only on the first space)\n",
        "        sextuple_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(sextuple_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the sextuple\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{sextuple_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeD7TphUVWkz"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples6.txt) for enzyme sextuples (6 enzymes)\n",
        "y_values = {}\n",
        "with open('p_Wilcoxon_y-samples6.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[sextuple_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values6.txt) for enzyme sextuples (6 enzymes)\n",
        "x_values = {}\n",
        "with open('p_Wilcoxon_x-values6.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{sextuple_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU6.txt\n",
        "with open('p_MannU6.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Sextuple', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into sextuple_name and enzyme_name (split only on the first space)\n",
        "        sextuple_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(sextuple_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the sextuple\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{sextuple_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NIlwKgcSkuW"
      },
      "source": [
        "## Pearson Combinations Results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If previous doesn't work, uncomment this\n",
        "\n",
        "y_samples = []  # Initialize y_samples as an empty list\n",
        "y_samples_file = f'p_Wilcoxon_y-samples{len(enzyme_set.split(\"-\"))}.txt'\n",
        "with open(y_samples_file, 'r') as y_samples_data:\n",
        "    for y_samples_line in y_samples_data:\n",
        "        y_samples_values = y_samples_line.strip().split('\\t')\n",
        "        if y_samples_values[0] == enzyme_set:\n",
        "            y_samples = y_samples_values[1:]\n",
        "            break\n",
        "\n",
        "# Check if y_samples were found\n",
        "if y_samples:\n",
        "    # Count the number of samples in the set of y-samples\n",
        "    num_samples = count_samples(', '.join(y_samples))\n",
        "\n",
        "    # Add the new row to the results dataframe\n",
        "    new_row = pd.DataFrame([{\n",
        "        'Enzyme Pair': enzyme_set,\n",
        "        'Enzyme Name': enzyme_name,\n",
        "        'Mann U': mann_u_value,\n",
        "        'Binomial Distribution': binomial_distribution,\n",
        "        'y-samples': ', '.join(y_samples),\n",
        "        '# of samples': num_samples\n",
        "    }])\n",
        "\n",
        "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "else:\n",
        "    print(f\"Warning: No y-samples found for enzyme set {enzyme_set}\")\n"
      ],
      "metadata": {
        "id": "pbog-WrUgK1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG3mY9I4Smbz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Function to count the number of samples in a set of y-samples\n",
        "def count_samples(y_samples):\n",
        "    return len(set(y_samples.split(', ')))\n",
        "\n",
        "# Reading the 'sig_pearson_enzymes.txt' file properly\n",
        "def parse_sig_pearson_enzymes(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # Extract data using regular expressions\n",
        "            match = re.match(r\"Enzyme = ([\\d.]+), Correlation Coefficient = ([\\d.-]+), t-value = ([\\d.-]+), Probability = ([\\d.e+-]+)\", line)\n",
        "            if match:\n",
        "                enzyme = match.group(1)\n",
        "                correlation = float(match.group(2))\n",
        "                t_value = float(match.group(3))\n",
        "                probability = float(match.group(4))\n",
        "                data.append([enzyme, correlation, t_value, probability])\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data, columns=['Enzyme', 'Correlation', 't-value', 'Probability'])\n",
        "    return df\n",
        "\n",
        "# Read the content of sig_pearson_enzymes.txt into a DataFrame\n",
        "significant_enzymes_df = parse_sig_pearson_enzymes('sig_pearson_enzymes.txt')\n",
        "\n",
        "# Read the content of sig_combo2.txt, sig_combo3.txt, sig_combo4.txt, sig_combo5.txt, and sig_combo6.txt\n",
        "files = ['p_sig_combo2.txt', 'p_sig_combo3.txt', 'p_sig_combo4.txt']\n",
        "\n",
        "results_df = pd.DataFrame(columns=['Enzyme Pair', 'Enzyme Name', 'Mann U', 'Binomial Distribution', 'y-samples', '# of samples'])\n",
        "\n",
        "# Adding the significant enzymes data to results_df\n",
        "results_df = pd.concat([significant_enzymes_df, results_df], ignore_index=True)\n",
        "\n",
        "for file in files:\n",
        "    with open(file, 'r') as sig_file:\n",
        "        next(sig_file)  # Skip the header\n",
        "\n",
        "        for line in sig_file:\n",
        "            values = line.strip().split('\\t')\n",
        "            enzyme_set = values[0]\n",
        "            enzyme_name = values[1]\n",
        "            mann_u_value = float(values[2])\n",
        "\n",
        "            # Retrieve binomial distribution from the corresponding combo file\n",
        "            combo_file = f'p_combo{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            binomial_distribution = None\n",
        "\n",
        "            with open(combo_file, 'r') as combo_data:\n",
        "                next(combo_data)  # Skip the header\n",
        "                for combo_line in combo_data:\n",
        "                    combo_values = combo_line.strip().split('\\t')\n",
        "\n",
        "                    # Check if enzyme_set matches any combination in the combo file\n",
        "                    combo_enzymes = set(combo_values[:len(enzyme_set.split(\"-\"))])\n",
        "                    if set(enzyme_set.split(\"-\")) == combo_enzymes:\n",
        "                        binomial_distribution = float(combo_values[-2])\n",
        "                        break\n",
        "\n",
        "            # Retrieve y-samples from the corresponding Wilcoxon_y-samples file\n",
        "            y_samples_file = f'p_Wilcoxon_y-samples{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            with open(y_samples_file, 'r') as y_samples_data:\n",
        "                for y_samples_line in y_samples_data:\n",
        "                    y_samples_values = y_samples_line.strip().split('\\t')\n",
        "                    if y_samples_values[0] == enzyme_set:\n",
        "                        y_samples = y_samples_values[1:]\n",
        "                        break\n",
        "\n",
        "            # Count the number of samples in the set of y-samples\n",
        "            num_samples = count_samples(', '.join(y_samples))\n",
        "\n",
        "            # Append the new row to the DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                'Enzyme Pair': enzyme_set,\n",
        "                'Enzyme Name': enzyme_name,\n",
        "                'Mann U': mann_u_value,\n",
        "                'Binomial Distribution': binomial_distribution,\n",
        "                'y-samples': ', '.join(y_samples),\n",
        "                '# of samples': num_samples\n",
        "            }])\n",
        "\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "\n",
        "# Save the results to an Excel file\n",
        "results_df.to_excel('pearson_combos.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modification"
      ],
      "metadata": {
        "id": "pwzMFwVFfixv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Function to calculate the binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "# Function to count the number of samples in a set of y-samples\n",
        "def count_samples(y_samples):\n",
        "    return len(set(y_samples.split(', ')))\n",
        "\n",
        "significant_enzymes_df = pd.read_csv('sig_pearson_enzymes.txt', sep=', ', header=None, engine='python')\n",
        "significant_enzymes_df.columns = ['Enzyme', 'Correlation', 't-value', 'p-value']\n",
        "\n",
        "files = ['p_sig_combo2.txt', 'p_sig_combo3.txt', 'p_sig_combo4.txt']\n",
        "\n",
        "results_df = pd.DataFrame(columns=['Enzyme Pair', 'Enzyme Name', 'Mann U', 'Binomial Distribution', 'y-samples', '# of samples'])\n",
        "\n",
        "results_df = pd.concat([significant_enzymes_df, results_df], ignore_index=True)\n",
        "\n",
        "for file in files:\n",
        "    with open(file, 'r') as sig_file:\n",
        "        next(sig_file)\n",
        "\n",
        "        for line in sig_file:\n",
        "            values = line.strip().split('\\t')\n",
        "            enzyme_set = values[0]\n",
        "            enzyme_name = values[1]\n",
        "            mann_u_value = float(values[2])\n",
        "\n",
        "            # Retrieve binomial distribution from the corresponding combo file\n",
        "            combo_file = f'p_combo{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            binomial_distribution = None\n",
        "\n",
        "            with open(combo_file, 'r') as combo_data:\n",
        "                next(combo_data)\n",
        "                for combo_line in combo_data:\n",
        "                    combo_values = combo_line.strip().split('\\t')\n",
        "\n",
        "                    # Check if enzyme_set matches any combination in the combo file\n",
        "                    combo_enzymes = set(combo_values[:len(enzyme_set.split(\"-\"))])\n",
        "                    if set(enzyme_set.split(\"-\")) == combo_enzymes:\n",
        "                        binomial_distribution = float(combo_values[-2])\n",
        "                        break\n",
        "\n",
        "            # Retrieve y-samples from the corresponding Wilcoxon_y-samples file\n",
        "            y_samples_file = f'p_Wilcoxon_y-samples{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            with open(y_samples_file, 'r') as y_samples_data:\n",
        "                for y_samples_line in y_samples_data:\n",
        "                    y_samples_values = y_samples_line.strip().split('\\t')\n",
        "                    if y_samples_values[0] == enzyme_set:\n",
        "                        y_samples = y_samples_values[1:]\n",
        "                        break\n",
        "\n",
        "            # Count the number of samples in the set of y-samples\n",
        "            num_samples = count_samples(', '.join(y_samples))\n",
        "\n",
        "            new_row = pd.DataFrame([{\n",
        "                'Enzyme Pair': enzyme_set,\n",
        "                'Enzyme Name': enzyme_name,\n",
        "                'Mann U': mann_u_value,\n",
        "                'Binomial Distribution': binomial_distribution,\n",
        "                'y-samples': ', '.join(y_samples),\n",
        "                '# of samples': num_samples\n",
        "            }])\n",
        "\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "\n",
        "results_df.to_excel('soil_pearson_combinations.xlsx', index=False)"
      ],
      "metadata": {
        "id": "uBQ_qCpifike"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgdmG9cASiBF"
      },
      "source": [
        "## Combinations with Spearman Correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eWgZZ1gwylC"
      },
      "source": [
        "### Mean and Standard Deviation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_4LGNb2wylE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the significant enzymes file to extract enzyme names\n",
        "enzyme_names = []\n",
        "with open(\"sig_spearman_enzymes.txt\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        enzyme = line.split(' ')[2].replace(\",\", \"\")\n",
        "        enzyme_names.append(enzyme)\n",
        "\n",
        "# Read the enzymes values file\n",
        "enzymes_values_df = pd.read_csv(\"enzyme_values.csv\", sep=\",\")\n",
        "\n",
        "# Create a dictionary to store rows for each enzyme\n",
        "enzyme_rows = {enzyme: [] for enzyme in enzyme_names}\n",
        "\n",
        "# Find rows for each enzyme in the enzymes_values file\n",
        "for enzyme in enzyme_names:\n",
        "    # Matching the enzyme EC Number with the 'EC Number' column in the enzymes_values.csv file\n",
        "    enzyme_rows[enzyme] = enzymes_values_df[enzymes_values_df['EC Number'].str.contains(enzyme)]\n",
        "\n",
        "# Calculate mean and standard deviation for each row and save to a file\n",
        "with open(\"p_mean&sd.txt\", \"w\") as file:\n",
        "    for enzyme, rows in enzyme_rows.items():\n",
        "        means = rows.iloc[:, 1:].mean(axis=1)  # Compute mean of all columns except the 'EC Number'\n",
        "        std_devs = rows.iloc[:, 1:].std(axis=1)  # Compute standard deviation of all columns except the 'EC Number'\n",
        "        for index, (mean, std_dev) in enumerate(zip(means, std_devs)):\n",
        "            file.write(f\"Enzyme: {enzyme} Mean: {mean} Standard Deviation: {std_dev}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkPrWKxrwylE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "enzymes_df = pd.read_csv(\"sig_spearman_enzymes.csv\")\n",
        "\n",
        "# Create a list of enzyme names (EC Numbers) to look for in the enzyme values file\n",
        "enzyme_names = enzymes_df['Enzyme'].tolist()\n",
        "\n",
        "enzyme_values_df = pd.read_csv(\"enzyme_values.csv\")\n",
        "\n",
        "with open(\"p_mean&sd.txt\", \"w\") as output_file:\n",
        "\n",
        "    for enzyme in enzyme_names:\n",
        "        # Find the row in enzyme_values_df where the EC Number matches the enzyme name\n",
        "        matching_row = enzyme_values_df[enzyme_values_df['EC Number'] == enzyme]\n",
        "\n",
        "        # Check if we found a match\n",
        "        if not matching_row.empty:\n",
        "            # Extract the values (exclude the EC Number column)\n",
        "            values = matching_row.iloc[0, 1:].values\n",
        "            # Calculate the mean and standard deviation for the values\n",
        "            mean_value = values.mean()\n",
        "            std_dev_value = values.std()\n",
        "\n",
        "            output_file.write(f\"{enzyme} Mean: {mean_value} Standard Deviation: {std_dev_value}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzDo0PCwwylF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "enzymes_df = pd.read_csv(\"sig_spearman_enzymes.csv\")\n",
        "\n",
        "mean_sd_values = {}\n",
        "\n",
        "enzyme_values_df = pd.read_csv(\"enzyme_values.csv\")\n",
        "\n",
        "enzyme_columns = enzyme_values_df.columns[1:]\n",
        "\n",
        "for _, row in enzymes_df.iterrows():\n",
        "    enzyme = row['Enzyme']\n",
        "    matching_row = enzyme_values_df[enzyme_values_df['EC Number'] == enzyme]\n",
        "\n",
        "    if not matching_row.empty:\n",
        "        values = matching_row.iloc[0, 1:].values\n",
        "        mean_value = values.mean()\n",
        "        std_dev_value = values.std()\n",
        "        mean_sd_values[enzyme] = {'mean': mean_value, 'std_dev': std_dev_value}\n",
        "\n",
        "normalized_values = []\n",
        "\n",
        "for _, row in enzyme_values_df.iterrows():\n",
        "    enzyme = row['EC Number']\n",
        "\n",
        "    if enzyme in mean_sd_values:\n",
        "        mean = mean_sd_values[enzyme]['mean']\n",
        "        std_dev = mean_sd_values[enzyme]['std_dev']\n",
        "\n",
        "        normalized_row = [(value - mean) / std_dev if std_dev != 0 else 'NaN' for value in row[1:].values]\n",
        "\n",
        "        normalized_values.append([enzyme] + normalized_row)\n",
        "\n",
        "normalized_df = pd.DataFrame(normalized_values, columns=['EC Number'] + list(enzyme_columns))\n",
        "\n",
        "normalized_df.to_csv(\"s_normalized_enzyme_values.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AwQ1sHywylF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"s_normalized_enzyme_values.csv\")\n",
        "\n",
        "def count_positive_values(row):\n",
        "    return (row[1:] > 0).sum()  # Count values greater than 0 in each row\n",
        "\n",
        "df['positive_count'] = df.apply(count_positive_values, axis=1)\n",
        "\n",
        "# Step 4: Filter the rows that have at least 10 positive values\n",
        "df_filtered = df[df['positive_count'] >= 10]\n",
        "\n",
        "df_filtered = df_filtered.drop(columns=['positive_count'])\n",
        "\n",
        "df_filtered.to_csv(\"final_sig_s_enzymes.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDEm518hwylG"
      },
      "source": [
        "## Binomial Distribution and Mann U Whitney Test for Combo2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKhhI_aAwylG"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('s_combo2.txt', 'w') as output_file, \\\n",
        "     open('s_Wilcoxon_y-values2.txt', 'w') as y_file, \\\n",
        "     open('s_Wilcoxon_y-samples2.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Pair', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Pair', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    for i in range(num_enzymes - 1):\n",
        "        for j in range(i + 1, num_enzymes):\n",
        "            enzyme1, enzyme2 = enzyme_list[i], enzyme_list[j]\n",
        "            values1, values2 = enzyme_data[enzyme1], enzyme_data[enzyme2]\n",
        "            count_matches = 0\n",
        "            positive_values = []\n",
        "            sample_list = []\n",
        "\n",
        "            for idx, (v1, v2) in enumerate(zip(values1, values2)):\n",
        "                if v1 > 0 and v2 > 0:\n",
        "                    count_matches += 1\n",
        "                    positive_values.append(str(v1))\n",
        "                    sample_list.append(sample_names[idx])\n",
        "\n",
        "            if count_matches >= n:\n",
        "                fraction = enzyme_percentages[enzyme1] * enzyme_percentages[enzyme2]\n",
        "                distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "                p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "                output_file.write(f'{enzyme1}\\t{enzyme2}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "                y_file.write(f\"{enzyme1}-{enzyme2}\\t{', '.join(positive_values)}\\n\")\n",
        "                samples_file.write(f\"{enzyme1}-{enzyme2}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuzDy6RAwylH"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values2.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[pair_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "available_enzymes = [row[0].strip() for row in data]\n",
        "print(f\"Available enzymes in the dataset: {available_enzymes[:20]}...\")  # Print first 20 enzymes for reference\n",
        "\n",
        "with open('s_Wilcoxon_x-values2.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Pair', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for pair_name, y_positive_values in y_values.items():\n",
        "        # Handling the different enzyme pair cases\n",
        "        if '--' in pair_name:\n",
        "            # Case 2: x.x.x.-x.x.x.x (one hyphen in first enzyme, no hyphen in second enzyme)\n",
        "            if pair_name.count('--') == 1:\n",
        "                enzyme1 = pair_name[:pair_name.index('--') + 1].strip()  # First enzyme includes one hyphen\n",
        "                enzyme2 = pair_name[pair_name.index('--') + 2:].strip()  # Second enzyme starts after '--'\n",
        "            elif pair_name.count('--') == 2:\n",
        "                # Case 3: x.x.x.x-x.x.-- (second enzyme ends with '--')\n",
        "                enzyme1 = pair_name[:pair_name.rindex('--')].strip()  # First enzyme is before the last '--'\n",
        "                enzyme2 = pair_name[pair_name.rindex('--'):].strip()  # Second enzyme includes '--'\n",
        "        elif '-' in pair_name:\n",
        "            # Case 1: x.x.x.x-x.x.x.x (normal case with single hyphen)\n",
        "            enzyme_names = pair_name.split('-', 1)  # Split only at the first hyphen\n",
        "            enzyme1 = enzyme_names[0].strip()  # First enzyme\n",
        "            enzyme2 = enzyme_names[1].strip()  # Second enzyme\n",
        "            if enzyme2.endswith('-'):\n",
        "                # Case 4: x.x.x.x-x.x.x.- (second enzyme ends with hyphen)\n",
        "                enzyme2 = enzyme2  # Ensure second enzyme includes the trailing hyphen\n",
        "        else:\n",
        "            print(f\"Skipping invalid enzyme pair format: {pair_name}\")\n",
        "            continue  # Skip invalid formats that don't have a '-' or '--'\n",
        "\n",
        "        # Print the enzymes for debugging\n",
        "        print(f\"Checking enzymes: {enzyme1} and {enzyme2}\")\n",
        "\n",
        "        # Check if enzyme1 and enzyme2 are in the dataset\n",
        "        if enzyme1 not in available_enzymes or enzyme2 not in available_enzymes:\n",
        "            print(f\"Skipping pair {pair_name} because one or both enzymes are not in the dataset.\")\n",
        "            continue  # Skip this pair if any enzyme is not found in the dataset\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding row for enzyme1 and enzyme2 in the data\n",
        "            sample_row1 = next(row for row in data if row[0].strip() == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0].strip() == enzyme2)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1 and enzyme2\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the pair's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from both enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2))\n",
        "\n",
        "            # If unique values exist, write them to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Determine which enzyme corresponds to the value\n",
        "                    if value in unique_values_1:\n",
        "                        enzyme_name = enzyme1\n",
        "                    else:\n",
        "                        enzyme_name = enzyme2\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{pair_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHEluzNQwylI"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples2.txt)\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples2.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[pair_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values2.txt)\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values2.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        pair_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{pair_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU2.txt\n",
        "with open('s_MannU2.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into pair_name and enzyme_name (split only on the first space)\n",
        "        pair_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(pair_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the pair\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{pair_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8yEfYk6wylJ"
      },
      "outputs": [],
      "source": [
        "with open('s_MannU2.txt', 'r') as mann_u_file, open('s_sig_combo2.txt', 'w') as output_file:\n",
        "\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "\n",
        "        if mann_u_value < 0.1:\n",
        "            next_values = next(mann_u_file, None)\n",
        "            if next_values is not None:\n",
        "                next_values = next_values.strip().split('\\t')\n",
        "                next_enzyme_name = next_values[1]\n",
        "                next_mann_u_value = float(next_values[2])\n",
        "\n",
        "                if next_mann_u_value < 0.1:\n",
        "                    output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                    output_file.write('\\t'.join([enzyme_pair, next_enzyme_name, str(next_mann_u_value)]) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O89NXDcYwylK"
      },
      "source": [
        "### Combo 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsfDwvNkwylK"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "from itertools import combinations  # To generate combinations of enzymes\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('s_combo3.txt', 'w') as output_file, \\\n",
        "     open('s_Wilcoxon_y-values3.txt', 'w') as y_file, \\\n",
        "     open('s_Wilcoxon_y-samples3.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Combo', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Combo', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    # Iterate over combinations of 3 enzymes\n",
        "    for combo in combinations(enzyme_list, 3):\n",
        "        enzyme1, enzyme2, enzyme3 = combo\n",
        "        values1, values2, values3 = enzyme_data[enzyme1], enzyme_data[enzyme2], enzyme_data[enzyme3]\n",
        "        count_matches = 0\n",
        "        positive_values = []\n",
        "        sample_list = []\n",
        "\n",
        "        # Compare the values of the three enzymes\n",
        "        for idx, (v1, v2, v3) in enumerate(zip(values1, values2, values3)):\n",
        "            if v1 > 0 and v2 > 0 and v3 > 0:\n",
        "                count_matches += 1\n",
        "                positive_values.append(f\"{v1}, {v2}, {v3}\")\n",
        "                sample_list.append(sample_names[idx])\n",
        "\n",
        "        if count_matches >= n:\n",
        "            # Calculate fraction of matches\n",
        "            fraction = enzyme_percentages[enzyme1] * enzyme_percentages[enzyme2] * enzyme_percentages[enzyme3]\n",
        "            distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "            p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "            # Write results to files\n",
        "            output_file.write(f'{enzyme1}\\t{enzyme2}\\t{enzyme3}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "            y_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}\\t{', '.join(positive_values)}\\n\")\n",
        "            samples_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaESaLjbwylL"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values3.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        combo_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[combo_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "# Diagnostic print: Check available enzyme names in the dataset\n",
        "available_enzymes = [row[0].strip() for row in data]\n",
        "print(f\"Available enzymes in the dataset: {available_enzymes[:20]}...\")  # Print first 20 enzymes for reference\n",
        "\n",
        "# Write the output to the x-values file\n",
        "with open('s_Wilcoxon_x-values3.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Combo', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for combo_name, y_positive_values in y_values.items():\n",
        "        # Handling the different enzyme trio cases\n",
        "        if '--' in combo_name:\n",
        "            # Case 2: x.x.x.-x.x.x.x-x.x.x.x (one hyphen in first enzyme, no hyphen in second or third enzyme)\n",
        "            if combo_name.count('--') == 1:\n",
        "                enzyme1 = combo_name[:combo_name.index('--') + 1].strip()  # First enzyme includes one hyphen\n",
        "                remainder = combo_name[combo_name.index('--') + 2:].strip()\n",
        "                # Check if there's a second hyphen to split\n",
        "                if '-' in remainder:\n",
        "                    enzyme2, enzyme3 = remainder.split('-', 1)\n",
        "                    enzyme2, enzyme3 = enzyme2.strip(), enzyme3.strip()\n",
        "                else:\n",
        "                    # If no second hyphen, assume it's just one enzyme in the remainder\n",
        "                    enzyme2 = remainder.strip()\n",
        "                    enzyme3 = None  # There's no third enzyme\n",
        "            # Case 3: x.x.x.x-x.x.x.x-x.x.x.- (second enzyme ends with '--')\n",
        "            elif combo_name.count('--') == 2:\n",
        "                enzyme1 = combo_name[:combo_name.index('--')].strip()  # First enzyme before '--'\n",
        "                remainder = combo_name[combo_name.index('--') + 2:].strip()\n",
        "                enzyme2, enzyme3 = remainder.split('-', 1)\n",
        "                enzyme2, enzyme3 = enzyme2.strip(), enzyme3.strip()\n",
        "                enzyme3 = enzyme3.strip()\n",
        "            # Case 4: x.x.x.x-x.x.x.--x.x.x.x (second enzyme ends with '--' and has a trailing hyphen)\n",
        "            elif combo_name.count('--') == 3:\n",
        "                enzyme1 = combo_name[:combo_name.index('-')].strip()  # First enzyme before '--'\n",
        "                remainder = combo_name[combo_name.index('-') + 2:].strip()  # The part after the first '--'\n",
        "                enzyme2 = remainder[:remainder.index('--') + 1].strip()  # Second enzyme with one trailing hyphen\n",
        "                enzyme3 = remainder[remainder.index('--') + 2:].strip()  # Third enzyme\n",
        "\n",
        "        elif '-' in combo_name:\n",
        "            # Case 1: x.x.x.x-x.x.x.x-x.x.x.x (standard case with three enzymes connected by hyphens)\n",
        "            enzyme_names = combo_name.split('-', 2)  # Split at the first two hyphens\n",
        "            enzyme1 = enzyme_names[0].strip()  # First enzyme\n",
        "            enzyme2 = enzyme_names[1].strip()  # Second enzyme\n",
        "            enzyme3 = enzyme_names[2].strip()  # Third enzyme\n",
        "        else:\n",
        "            print(f\"Skipping invalid enzyme trio format: {combo_name}\")\n",
        "            continue  # Skip invalid formats that don't match the expected hyphen patterns\n",
        "\n",
        "        # Print the enzymes for debugging\n",
        "        print(f\"Checking enzymes: {enzyme1}, {enzyme2}, {enzyme3}\")\n",
        "\n",
        "        # Check if enzyme1, enzyme2, and enzyme3 are in the dataset\n",
        "        if enzyme1 not in available_enzymes or enzyme2 not in available_enzymes or enzyme3 not in available_enzymes:\n",
        "            print(f\"Skipping combo {combo_name} because one or more enzymes are not in the dataset.\")\n",
        "            continue  # Skip this trio if any enzyme is not found in the dataset\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding rows for enzyme1, enzyme2, and enzyme3 in the data\n",
        "            sample_row1 = next(row for row in data if row[0].strip() == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0].strip() == enzyme2)\n",
        "            sample_row3 = next(row for row in data if row[0].strip() == enzyme3)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1, enzyme2, and enzyme3\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "            sample_positive_values_3 = [float(value) for value in sample_row3[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the trio's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "            unique_values_3 = set(sample_positive_values_3) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from all three enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2).union(unique_values_3))\n",
        "\n",
        "            # If unique values exist, write them to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Determine which enzyme corresponds to the value\n",
        "                    if value in unique_values_1:\n",
        "                        enzyme_name = enzyme1\n",
        "                    elif value in unique_values_2:\n",
        "                        enzyme_name = enzyme2\n",
        "                    else:\n",
        "                        enzyme_name = enzyme3\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{combo_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbWKWqtLwylL"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples3.txt) for enzyme triplets\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples3.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        trio_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[trio_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values3.txt) for enzyme triplets\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values3.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        trio_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{trio_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU3.txt\n",
        "with open('s_MannU3.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Trio', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into trio_name and enzyme_name (split only on the first space)\n",
        "        trio_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(trio_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the trio\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{trio_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('s_MannU3.txt', 'r') as mann_u_file, open('s_sig_combo3.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n"
      ],
      "metadata": {
        "id": "s-jvmBsN5qc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfoWm9Q5wylL"
      },
      "source": [
        "### Combo 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or_ait8jwylM"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "from itertools import combinations  # To generate combinations of 4 enzymes\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('s_combo4.txt', 'w') as output_file, \\\n",
        "     open('s_Wilcoxon_y-values4.txt', 'w') as y_file, \\\n",
        "     open('s_Wilcoxon_y-samples4.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Combo', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Combo', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    # Generate all combinations of 4 enzymes\n",
        "    enzyme_combos = combinations(enzyme_list, 4)\n",
        "\n",
        "    for combo in enzyme_combos:\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4 = combo\n",
        "        values1, values2, values3, values4 = enzyme_data[enzyme1], enzyme_data[enzyme2], enzyme_data[enzyme3], enzyme_data[enzyme4]\n",
        "        count_matches = 0\n",
        "        positive_values = []\n",
        "        sample_list = []\n",
        "\n",
        "        # Iterate over samples to check for matching positive values\n",
        "        for idx, (v1, v2, v3, v4) in enumerate(zip(values1, values2, values3, values4)):\n",
        "            if v1 > 0 and v2 > 0 and v3 > 0 and v4 > 0:\n",
        "                count_matches += 1\n",
        "                positive_values.append(str(v1))  # Collect positive values (can be from any enzyme)\n",
        "                sample_list.append(sample_names[idx])  # Collect the samples that have matches\n",
        "\n",
        "        # If there are enough matches, calculate the binomial distribution and p-value\n",
        "        if count_matches >= n:\n",
        "            # Calculate the fraction of matches for the four enzymes combined\n",
        "            fraction = enzyme_percentages[enzyme1] * enzyme_percentages[enzyme2] * enzyme_percentages[enzyme3] * enzyme_percentages[enzyme4]\n",
        "\n",
        "            # Calculate binomial distribution\n",
        "            distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "\n",
        "            # Calculate p-value (sum of binomial probabilities from count_matches to total_samples)\n",
        "            p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "            # Write results to the output files\n",
        "            output_file.write(f'{enzyme1}\\t{enzyme2}\\t{enzyme3}\\t{enzyme4}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "            y_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}\\t{', '.join(positive_values)}\\n\")\n",
        "            samples_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q78dgofzwylM"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values4.txt', 'r') as y_file:  # Updated to read 4-enzyme values file\n",
        "    next(y_file)  # Skip header\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        combo_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[combo_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "available_enzymes = [row[0].strip() for row in data]\n",
        "print(f\"Available enzymes in the dataset: {available_enzymes[:20]}...\")  # Print first 20 enzymes for reference\n",
        "\n",
        "with open('s_Wilcoxon_x-values4.txt', 'w') as x_output_file:  # Updated to output 4-enzyme file\n",
        "    x_output_file.write('\\t'.join(['Enzyme Combo', 'Sample Name', 'Enzyme Name', 'Values']) + '\\n')\n",
        "\n",
        "    for combo_name, y_positive_values in y_values.items():\n",
        "        # Handling the different enzyme combo cases for 4 enzymes\n",
        "        if '-' in combo_name:\n",
        "            # Case: Four enzymes connected by hyphens\n",
        "            enzyme_names = combo_name.split('-', 3)  # Split at the first three hyphens\n",
        "            if len(enzyme_names) == 4:\n",
        "                enzyme1 = enzyme_names[0].strip()  # First enzyme\n",
        "                enzyme2 = enzyme_names[1].strip()  # Second enzyme\n",
        "                enzyme3 = enzyme_names[2].strip()  # Third enzyme\n",
        "                enzyme4 = enzyme_names[3].strip()  # Fourth enzyme\n",
        "            else:\n",
        "                print(f\"Skipping invalid enzyme combo format (not exactly four enzymes): {combo_name}\")\n",
        "                continue  # Skip invalid formats that don't have four enzymes\n",
        "\n",
        "        else:\n",
        "            print(f\"Skipping invalid enzyme combo format (no hyphens detected): {combo_name}\")\n",
        "            continue  # Skip invalid formats that don't have hyphens\n",
        "\n",
        "        # Print the enzymes for debugging\n",
        "        print(f\"Checking enzymes: {enzyme1}, {enzyme2}, {enzyme3}, {enzyme4}\")\n",
        "\n",
        "        # Check if enzyme1, enzyme2, enzyme3, and enzyme4 are in the dataset\n",
        "        if enzyme1 not in available_enzymes or enzyme2 not in available_enzymes or enzyme3 not in available_enzymes or enzyme4 not in available_enzymes:\n",
        "            print(f\"Skipping combo {combo_name} because one or more enzymes are not in the dataset.\")\n",
        "            continue  # Skip this combo if any enzyme is not found in the dataset\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding rows for enzyme1, enzyme2, enzyme3, and enzyme4 in the data\n",
        "            sample_row1 = next(row for row in data if row[0].strip() == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0].strip() == enzyme2)\n",
        "            sample_row3 = next(row for row in data if row[0].strip() == enzyme3)\n",
        "            sample_row4 = next(row for row in data if row[0].strip() == enzyme4)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1, enzyme2, enzyme3, and enzyme4\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "            sample_positive_values_3 = [float(value) for value in sample_row3[1:] if float(value) > 0]\n",
        "            sample_positive_values_4 = [float(value) for value in sample_row4[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the combo's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "            unique_values_3 = set(sample_positive_values_3) - set(y_positive_values)\n",
        "            unique_values_4 = set(sample_positive_values_4) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from all four enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2).union(unique_values_3).union(unique_values_4))\n",
        "\n",
        "            # If unique values exist, write them to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Determine which enzyme corresponds to the value\n",
        "                    if value in unique_values_1:\n",
        "                        enzyme_name = enzyme1\n",
        "                    elif value in unique_values_2:\n",
        "                        enzyme_name = enzyme2\n",
        "                    elif value in unique_values_3:\n",
        "                        enzyme_name = enzyme3\n",
        "                    else:\n",
        "                        enzyme_name = enzyme4\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{combo_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvVh68GkwylM"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples4.txt) for enzyme quadruples\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples4.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quadruple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[quadruple_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values4.txt) for enzyme quadruples\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values4.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quadruple_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{quadruple_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU4.txt\n",
        "with open('s_MannU4.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Quadruple', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into quadruple_name and enzyme_name (split only on the first space)\n",
        "        quadruple_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(quadruple_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the quadruple\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{quadruple_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('s_MannU4.txt', 'r') as mann_u_file, open('s_sig_combo4.txt', 'w') as output_file:\n",
        "    output_file.write('\\t'.join(['Enzyme Pair', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    next(mann_u_file)\n",
        "    for line in mann_u_file:\n",
        "        values = line.strip().split('\\t')\n",
        "        enzyme_pair = values[0]\n",
        "        enzyme_name = values[1]\n",
        "        mann_u_value = float(values[2])\n",
        "        next_values_2 = next(mann_u_file, None)\n",
        "        next_values_3 = next(mann_u_file, None)\n",
        "        next_values_4 = next(mann_u_file, None)\n",
        "\n",
        "        if next_values_2 is not None and next_values_3 is not None and next_values_4 is not None:\n",
        "            next_values_2 = next_values_2.strip().split('\\t')\n",
        "            next_values_3 = next_values_3.strip().split('\\t')\n",
        "            next_values_4 = next_values_4.strip().split('\\t')\n",
        "\n",
        "            next_enzyme_name_2 = next_values_2[1]\n",
        "            next_mann_u_value_2 = float(next_values_2[2])\n",
        "\n",
        "            next_enzyme_name_3 = next_values_3[1]\n",
        "            next_mann_u_value_3 = float(next_values_3[2])\n",
        "\n",
        "            next_enzyme_name_4 = next_values_4[1]\n",
        "            next_mann_u_value_4 = float(next_values_4[2])\n",
        "\n",
        "            if next_mann_u_value_2 < 0.1 and next_mann_u_value_3 < 0.1 and mann_u_value < 0.1 and next_mann_u_value_4 < 0.1:\n",
        "                output_file.write('\\t'.join([enzyme_pair, enzyme_name, str(mann_u_value)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_2, str(next_mann_u_value_2)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_3, str(next_mann_u_value_3)]) + '\\n')\n",
        "                output_file.write('\\t'.join([enzyme_pair, next_enzyme_name_4, str(next_mann_u_value_4)]) + '\\n')\n"
      ],
      "metadata": {
        "id": "o11SEyPP54Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJFggCAWwylN"
      },
      "source": [
        "### Combo 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcG3c5diwylN"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "from itertools import combinations  # To generate combinations of 5 enzymes\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('s_combo5.txt', 'w') as output_file, \\\n",
        "     open('s_Wilcoxon_y-values5.txt', 'w') as y_file, \\\n",
        "     open('s_Wilcoxon_y-samples5.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Enzyme5', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Combo', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Combo', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    # Generate all combinations of 5 enzymes\n",
        "    enzyme_combos = combinations(enzyme_list, 5)\n",
        "\n",
        "    for combo in enzyme_combos:\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4, enzyme5 = combo\n",
        "        values1, values2, values3, values4, values5 = enzyme_data[enzyme1], enzyme_data[enzyme2], enzyme_data[enzyme3], enzyme_data[enzyme4], enzyme_data[enzyme5]\n",
        "        count_matches = 0\n",
        "        positive_values = []\n",
        "        sample_list = []\n",
        "\n",
        "        # Iterate over samples to check for matching positive values\n",
        "        for idx, (v1, v2, v3, v4, v5) in enumerate(zip(values1, values2, values3, values4, values5)):\n",
        "            if v1 > 0 and v2 > 0 and v3 > 0 and v4 > 0 and v5 > 0:\n",
        "                count_matches += 1\n",
        "                positive_values.append(str(v1))  # Collect positive values (can be from any enzyme)\n",
        "                sample_list.append(sample_names[idx])  # Collect the samples that have matches\n",
        "\n",
        "        # If there are enough matches, calculate the binomial distribution and p-value\n",
        "        if count_matches >= n:\n",
        "            # Calculate the fraction of matches for the five enzymes combined\n",
        "            fraction = (enzyme_percentages[enzyme1] *\n",
        "                        enzyme_percentages[enzyme2] *\n",
        "                        enzyme_percentages[enzyme3] *\n",
        "                        enzyme_percentages[enzyme4] *\n",
        "                        enzyme_percentages[enzyme5])\n",
        "\n",
        "            # Calculate binomial distribution\n",
        "            distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "\n",
        "            # Calculate p-value (sum of binomial probabilities from count_matches to total_samples)\n",
        "            p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "            # Write results to the output files\n",
        "            output_file.write(f'{enzyme1}\\t{enzyme2}\\t{enzyme3}\\t{enzyme4}\\t{enzyme5}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "            y_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}-{enzyme5}\\t{', '.join(positive_values)}\\n\")\n",
        "            samples_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}-{enzyme5}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdAJI5XgwylO"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values5.txt', 'r') as y_file:\n",
        "    next(y_file)\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quintuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[quintuple_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "with open('s_Wilcoxon_x-values5.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Quintuple', 'Sample Name', 'Enzyme Name', 'Value']) + '\\n')\n",
        "\n",
        "    for quintuple_name, y_positive_values in y_values.items():\n",
        "        # Clean enzyme names by stripping leading/trailing dashes\n",
        "        quintuple_name_parts = quintuple_name.split('-')\n",
        "\n",
        "        # Ensure that we have exactly 5 enzymes in the quintuple name\n",
        "        if len(quintuple_name_parts) != 5:\n",
        "            print(f\"Skipping invalid quintuple: {quintuple_name}\")\n",
        "            continue\n",
        "\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4, enzyme5 = quintuple_name_parts  # Assign enzymes\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding rows for enzyme1, enzyme2, enzyme3, enzyme4, and enzyme5 in the data\n",
        "            sample_row1 = next(row for row in data if row[0] == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0] == enzyme2)\n",
        "            sample_row3 = next(row for row in data if row[0] == enzyme3)\n",
        "            sample_row4 = next(row for row in data if row[0] == enzyme4)\n",
        "            sample_row5 = next(row for row in data if row[0] == enzyme5)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1, enzyme2, enzyme3, enzyme4, and enzyme5\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "            sample_positive_values_3 = [float(value) for value in sample_row3[1:] if float(value) > 0]\n",
        "            sample_positive_values_4 = [float(value) for value in sample_row4[1:] if float(value) > 0]\n",
        "            sample_positive_values_5 = [float(value) for value in sample_row5[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the quintuple's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "            unique_values_3 = set(sample_positive_values_3) - set(y_positive_values)\n",
        "            unique_values_4 = set(sample_positive_values_4) - set(y_positive_values)\n",
        "            unique_values_5 = set(sample_positive_values_5) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from all five enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2).union(unique_values_3).union(unique_values_4).union(unique_values_5))\n",
        "\n",
        "            # If unique values exist, find the enzyme names and write to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Try to find the enzyme name corresponding to the positive value by comparing the values as floats\n",
        "                    try:\n",
        "                        enzyme_name = header[sample_row1[1:].index(str(value)) + 1]  # Shift by 1 to match the enzyme name\n",
        "                    except ValueError:\n",
        "                        # In case the value is not found due to small precision differences, skip\n",
        "                        continue\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{quintuple_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PumU15G6wylO"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples5.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quintuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[quintuple_name] = sample_values\n",
        "\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values5.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        quintuple_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{quintuple_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU5.txt\n",
        "with open('s_MannU5.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Quintuple', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into quintuple_name and enzyme_name (split only on the first space)\n",
        "        quintuple_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(quintuple_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the quintuple\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{quintuple_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmCif4UmwylP"
      },
      "source": [
        "### Combo 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-D07M-PwylP"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import binom\n",
        "import csv\n",
        "from itertools import combinations  # To generate combinations of 6 enzymes\n",
        "\n",
        "# Function to calculate binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    return binom.pmf(count_matches, total_samples, count_percentage)\n",
        "\n",
        "n = 10  # Minimum matches required\n",
        "total_samples = 44  # Total number of samples\n",
        "\n",
        "# Read enzyme data and calculate percentages\n",
        "enzyme_percentages = {}\n",
        "enzyme_data = {}\n",
        "sample_names = []\n",
        "\n",
        "with open('final_sig_s_enzymes.csv', 'r') as enzyme_file:\n",
        "    reader = csv.reader(enzyme_file, delimiter=',')\n",
        "    header = next(reader)\n",
        "    sample_names = header[1:]  # Store sample names\n",
        "\n",
        "    for line in reader:\n",
        "        enzyme_name = line[0]\n",
        "        values = [float(v) for v in line[1:]]\n",
        "        positive_values = sum(1 for v in values if v > 0)\n",
        "        enzyme_percentages[enzyme_name] = positive_values / total_samples\n",
        "        enzyme_data[enzyme_name] = values\n",
        "\n",
        "# Open output files\n",
        "with open('s_combo6.txt', 'w') as output_file, \\\n",
        "     open('s_Wilcoxon_y-values6.txt', 'w') as y_file, \\\n",
        "     open('s_Wilcoxon_y-samples6.txt', 'w') as samples_file:\n",
        "\n",
        "    # Write headers\n",
        "    output_file.write('\\t'.join(['Enzyme1', 'Enzyme2', 'Enzyme3', 'Enzyme4', 'Enzyme5', 'Enzyme6', 'Count Percentage', 'Matches', 'Binomial Distribution', 'p_value']) + '\\n')\n",
        "    y_file.write('\\t'.join(['Enzyme Combo', 'Values']) + '\\n')\n",
        "    samples_file.write('\\t'.join(['Enzyme Combo', 'Samples']) + '\\n')\n",
        "\n",
        "    enzyme_list = list(enzyme_data.keys())\n",
        "    num_enzymes = len(enzyme_list)\n",
        "\n",
        "    # Generate all combinations of 6 enzymes\n",
        "    enzyme_combos = combinations(enzyme_list, 6)\n",
        "\n",
        "    for combo in enzyme_combos:\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4, enzyme5, enzyme6 = combo\n",
        "        values1, values2, values3, values4, values5, values6 = enzyme_data[enzyme1], enzyme_data[enzyme2], enzyme_data[enzyme3], enzyme_data[enzyme4], enzyme_data[enzyme5], enzyme_data[enzyme6]\n",
        "        count_matches = 0\n",
        "        positive_values = []\n",
        "        sample_list = []\n",
        "\n",
        "        # Iterate over samples to check for matching positive values\n",
        "        for idx, (v1, v2, v3, v4, v5, v6) in enumerate(zip(values1, values2, values3, values4, values5, values6)):\n",
        "            if v1 > 0 and v2 > 0 and v3 > 0 and v4 > 0 and v5 > 0 and v6 > 0:\n",
        "                count_matches += 1\n",
        "                positive_values.append(str(v1))  # Collect positive values (can be from any enzyme)\n",
        "                sample_list.append(sample_names[idx])  # Collect the samples that have matches\n",
        "\n",
        "        # If there are enough matches, calculate the binomial distribution and p-value\n",
        "        if count_matches >= n:\n",
        "            # Calculate the fraction of matches for the six enzymes combined\n",
        "            fraction = (enzyme_percentages[enzyme1] *\n",
        "                        enzyme_percentages[enzyme2] *\n",
        "                        enzyme_percentages[enzyme3] *\n",
        "                        enzyme_percentages[enzyme4] *\n",
        "                        enzyme_percentages[enzyme5] *\n",
        "                        enzyme_percentages[enzyme6])\n",
        "\n",
        "            # Calculate binomial distribution\n",
        "            distribution = calculate_binomial_distribution(count_matches, total_samples, fraction)\n",
        "\n",
        "            # Calculate p-value (sum of binomial probabilities from count_matches to total_samples)\n",
        "            p_value = sum(calculate_binomial_distribution(k, total_samples, fraction) for k in range(count_matches, total_samples + 1))\n",
        "\n",
        "            # Write results to the output files\n",
        "            output_file.write(f'{enzyme1}\\t{enzyme2}\\t{enzyme3}\\t{enzyme4}\\t{enzyme5}\\t{enzyme6}\\t{fraction:.16f}\\t{count_matches}\\t{distribution:.16e}\\t{p_value:.16e}\\n')\n",
        "            y_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}-{enzyme5}-{enzyme6}\\t{', '.join(positive_values)}\\n\")\n",
        "            samples_file.write(f\"{enzyme1}-{enzyme2}-{enzyme3}-{enzyme4}-{enzyme5}-{enzyme6}\\t{', '.join(sample_list)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unDJKoaZwylP"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Read Wilcoxon y-values from file\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-values6.txt', 'r') as y_file:\n",
        "    next(y_file)  # Skip header\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        y_values[sextuple_name] = [float(value) for value in values_str.split(', ')]\n",
        "\n",
        "# Read data from final_sig_p_enzymes.csv\n",
        "with open('final_sig_s_enzymes.csv', 'r') as sample_file:\n",
        "    input_reader = csv.reader(sample_file, delimiter=',')\n",
        "    header = next(input_reader)  # Read header row (sample names are in columns after the first)\n",
        "    data = list(input_reader)  # All data rows\n",
        "\n",
        "# Write the output to the x-values file\n",
        "with open('s_Wilcoxon_x-values6.txt', 'w') as x_output_file:\n",
        "    x_output_file.write('\\t'.join(['Enzyme Sextuple', 'Sample Name', 'Enzyme Name', 'Value']) + '\\n')\n",
        "\n",
        "    for sextuple_name, y_positive_values in y_values.items():\n",
        "        # Clean enzyme names by stripping leading/trailing dashes\n",
        "        sextuple_name_parts = sextuple_name.split('-')\n",
        "\n",
        "        # Ensure that we have exactly 6 enzymes in the sextuple name\n",
        "        if len(sextuple_name_parts) != 6:\n",
        "            print(f\"Skipping invalid sextuple: {sextuple_name}\")\n",
        "            continue\n",
        "\n",
        "        enzyme1, enzyme2, enzyme3, enzyme4, enzyme5, enzyme6 = sextuple_name_parts  # Assign enzymes\n",
        "\n",
        "        # Loop through each sample (these are columns after the first one in final_sig_p_enzymes.csv)\n",
        "        for sample_name in header[1:]:  # Skip the first column with enzyme names\n",
        "            # Find the corresponding rows for enzyme1, enzyme2, enzyme3, enzyme4, enzyme5, and enzyme6 in the data\n",
        "            sample_row1 = next(row for row in data if row[0] == enzyme1)\n",
        "            sample_row2 = next(row for row in data if row[0] == enzyme2)\n",
        "            sample_row3 = next(row for row in data if row[0] == enzyme3)\n",
        "            sample_row4 = next(row for row in data if row[0] == enzyme4)\n",
        "            sample_row5 = next(row for row in data if row[0] == enzyme5)\n",
        "            sample_row6 = next(row for row in data if row[0] == enzyme6)\n",
        "\n",
        "            # Extract positive values for the current sample from enzyme1, enzyme2, enzyme3, enzyme4, enzyme5, and enzyme6\n",
        "            sample_positive_values_1 = [float(value) for value in sample_row1[1:] if float(value) > 0]\n",
        "            sample_positive_values_2 = [float(value) for value in sample_row2[1:] if float(value) > 0]\n",
        "            sample_positive_values_3 = [float(value) for value in sample_row3[1:] if float(value) > 0]\n",
        "            sample_positive_values_4 = [float(value) for value in sample_row4[1:] if float(value) > 0]\n",
        "            sample_positive_values_5 = [float(value) for value in sample_row5[1:] if float(value) > 0]\n",
        "            sample_positive_values_6 = [float(value) for value in sample_row6[1:] if float(value) > 0]\n",
        "\n",
        "            # Find unique positive values not shared between the sextuple's row in Wilcoxon_y-values.txt\n",
        "            unique_values_1 = set(sample_positive_values_1) - set(y_positive_values)\n",
        "            unique_values_2 = set(sample_positive_values_2) - set(y_positive_values)\n",
        "            unique_values_3 = set(sample_positive_values_3) - set(y_positive_values)\n",
        "            unique_values_4 = set(sample_positive_values_4) - set(y_positive_values)\n",
        "            unique_values_5 = set(sample_positive_values_5) - set(y_positive_values)\n",
        "            unique_values_6 = set(sample_positive_values_6) - set(y_positive_values)\n",
        "\n",
        "            # Combine the unique values from all six enzymes for the current sample\n",
        "            combined_unique_values = list(unique_values_1.union(unique_values_2).union(unique_values_3).union(unique_values_4).union(unique_values_5).union(unique_values_6))\n",
        "\n",
        "            # If unique values exist, find the enzyme names and write to the output file\n",
        "            if combined_unique_values:\n",
        "                for value in combined_unique_values:\n",
        "                    # Try to find the enzyme name corresponding to the positive value by comparing the values as floats\n",
        "                    try:\n",
        "                        enzyme_name = header[sample_row1[1:].index(str(value)) + 1]  # Shift by 1 to match the enzyme name\n",
        "                    except ValueError:\n",
        "                        # In case the value is not found due to small precision differences, skip\n",
        "                        continue\n",
        "\n",
        "                    # Write the details into the output file\n",
        "                    x_output_file.write(f'{sextuple_name}\\t{sample_name}\\t{enzyme_name}\\t{value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I1X5JMUwylQ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples6.txt) for enzyme sextuples (6 enzymes)\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples6.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[sextuple_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values6.txt) for enzyme sextuples (6 enzymes)\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values6.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{sextuple_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU6.txt\n",
        "with open('s_MannU6.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Sextuple', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into sextuple_name and enzyme_name (split only on the first space)\n",
        "        sextuple_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(sextuple_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the sextuple\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{sextuple_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaC9RrlewylQ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Function to extract and format pollution values (z-scores) from filtered_pollution_values.csv\n",
        "def extract_pollution_values(sample_name, pollution_data):\n",
        "    # Try to find the corresponding pollution value using filename (from filtered_pollution_values.csv)\n",
        "    try:\n",
        "        # Match by filename to extract the pollution value (filename is in the 5th column of pollution_data)\n",
        "        row = next(row for row in pollution_data if row[4] == sample_name)  # Match by filename (column 4)\n",
        "        return float(row[1])  # Return the pollution z-score value (column 1)\n",
        "    except StopIteration:\n",
        "        # Handle the case where the sample name is not found in the pollution data\n",
        "        print(f\"Warning: Sample '{sample_name}' not found in pollution data.\")\n",
        "        return None  # Return None if sample is not found\n",
        "\n",
        "# Read data from filtered_pollution_values.csv (comma-separated)\n",
        "pollution_data = []\n",
        "with open('filtered_pollution_values.csv', 'r') as pollution_file:\n",
        "    input_reader = csv.reader(pollution_file)\n",
        "    next(input_reader)  # Skip header row\n",
        "    pollution_data = list(input_reader)  # Store all rows in pollution_data\n",
        "\n",
        "# Read Wilcoxon y-values (from p_Wilcoxon_y-samples6.txt) for enzyme sextuples (6 enzymes)\n",
        "y_values = {}\n",
        "with open('s_Wilcoxon_y-samples6.txt', 'r') as y_file:\n",
        "    for line in y_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        values_str = parts[1]\n",
        "        sample_values = []\n",
        "\n",
        "        # Extract corresponding pollution values for the samples in y-values\n",
        "        for sample_name in values_str.split(', '):\n",
        "            value = extract_pollution_values(sample_name, pollution_data)\n",
        "            if value is not None:  # Only append if a valid value is found\n",
        "                sample_values.append(value)\n",
        "\n",
        "        y_values[sextuple_name] = sample_values\n",
        "\n",
        "# Read x-values (from p_Wilcoxon_x-values6.txt) for enzyme sextuples (6 enzymes)\n",
        "x_values = {}\n",
        "with open('s_Wilcoxon_x-values6.txt', 'r') as x_file:\n",
        "    next(x_file)  # Skip the header row\n",
        "    for line in x_file:\n",
        "        parts = line.strip().split('\\t')\n",
        "        sextuple_name = parts[0]\n",
        "        sample_name = parts[1]\n",
        "        enzyme_name = parts[2]\n",
        "\n",
        "        # Extract corresponding pollution data (values) for the sample name\n",
        "        value = extract_pollution_values(sample_name, pollution_data)\n",
        "        if value is not None:  # Only add to x_values if value is valid\n",
        "            key = f'{sextuple_name} {enzyme_name}'\n",
        "            if key in x_values:\n",
        "                x_values[key].append(value)\n",
        "            else:\n",
        "                x_values[key] = [value]\n",
        "\n",
        "# Perform Mann-Whitney U test and save results to p_MannU6.txt\n",
        "with open('s_MannU6.txt', 'w') as mann_u_file:\n",
        "    mann_u_file.write('\\t'.join(['Enzyme Sextuple', 'Enzyme Name', 'Mann U']) + '\\n')\n",
        "\n",
        "    for key, x_sample_values in x_values.items():\n",
        "        # Split the key into sextuple_name and enzyme_name (split only on the first space)\n",
        "        sextuple_name, enzyme_name_x = key.split(' ', 1)\n",
        "        y_sample_values = y_values.get(sextuple_name, [])\n",
        "\n",
        "        # Perform Mann-Whitney U test on the samples\n",
        "        if y_sample_values:  # Ensure there are y values for the sextuple\n",
        "            stat, p_value = mannwhitneyu(x_sample_values, y_sample_values, alternative='two-sided')\n",
        "            mann_u_file.write(f'{sextuple_name}\\t{enzyme_name_x}\\t{p_value}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBZZjZpywylR"
      },
      "source": [
        "## Spearman Combinations Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2C1KnEPwylR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from scipy.stats import binom\n",
        "\n",
        "def count_samples(y_samples):\n",
        "    return len(set(y_samples.split(', ')))\n",
        "\n",
        "def parse_sig_spearman_enzymes(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            # Extract data using regular expressions\n",
        "            match = re.match(r\"Enzyme = ([\\d.]+), Correlation Coefficient = ([\\d.-]+), t-value = ([\\d.-]+), Probability = ([\\d.e+-]+)\", line)\n",
        "            if match:\n",
        "                enzyme = match.group(1)\n",
        "                correlation = float(match.group(2))\n",
        "                t_value = float(match.group(3))\n",
        "                probability = float(match.group(4))\n",
        "                data.append([enzyme, correlation, t_value, probability])\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data, columns=['Enzyme', 'Correlation', 't-value', 'Probability'])\n",
        "    return df\n",
        "\n",
        "significant_enzymes_df = parse_sig_spearman_enzymes('sig_spearman_enzymes.txt')\n",
        "\n",
        "files = ['s_sig_combo2.txt', 's_sig_combo3.txt', 's_sig_combo4.txt']\n",
        "\n",
        "results_df = pd.DataFrame(columns=['Enzyme Pair', 'Enzyme Name', 'Mann U', 'Binomial Distribution', 'y-samples', '# of samples'])\n",
        "\n",
        "# Adding the significant enzymes data to results_df\n",
        "results_df = pd.concat([significant_enzymes_df, results_df], ignore_index=True)\n",
        "\n",
        "for file in files:\n",
        "    with open(file, 'r') as sig_file:\n",
        "        next(sig_file)  # Skip the header\n",
        "\n",
        "        for line in sig_file:\n",
        "            values = line.strip().split('\\t')\n",
        "            enzyme_set = values[0]\n",
        "            enzyme_name = values[1]\n",
        "            mann_u_value = float(values[2])\n",
        "\n",
        "            # Retrieve binomial distribution from the corresponding combo file\n",
        "            combo_file = f's_combo{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            binomial_distribution = None\n",
        "\n",
        "            with open(combo_file, 'r') as combo_data:\n",
        "                next(combo_data)  # Skip the header\n",
        "                for combo_line in combo_data:\n",
        "                    combo_values = combo_line.strip().split('\\t')\n",
        "\n",
        "                    # Check if enzyme_set matches any combination in the combo file\n",
        "                    combo_enzymes = set(combo_values[:len(enzyme_set.split(\"-\"))])\n",
        "                    if set(enzyme_set.split(\"-\")) == combo_enzymes:\n",
        "                        binomial_distribution = float(combo_values[-2])\n",
        "                        break\n",
        "\n",
        "            # Retrieve y-samples from the corresponding Wilcoxon_y-samples file\n",
        "            y_samples_file = f's_Wilcoxon_y-samples{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            with open(y_samples_file, 'r') as y_samples_data:\n",
        "                for y_samples_line in y_samples_data:\n",
        "                    y_samples_values = y_samples_line.strip().split('\\t')\n",
        "                    if y_samples_values[0] == enzyme_set:\n",
        "                        y_samples = y_samples_values[1:]\n",
        "                        break\n",
        "\n",
        "            # Count the number of samples in the set of y-samples\n",
        "            num_samples = count_samples(', '.join(y_samples))\n",
        "\n",
        "            # Append the new row to the DataFrame\n",
        "            new_row = pd.DataFrame([{\n",
        "                'Enzyme Pair': enzyme_set,\n",
        "                'Enzyme Name': enzyme_name,\n",
        "                'Mann U': mann_u_value,\n",
        "                'Binomial Distribution': binomial_distribution,\n",
        "                'y-samples': ', '.join(y_samples),\n",
        "                '# of samples': num_samples\n",
        "            }])\n",
        "\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "\n",
        "# Save the results to an Excel file\n",
        "results_df.to_excel('soil_spearman_combos.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modification (use this)"
      ],
      "metadata": {
        "id": "-96-h_ItXv0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Function to calculate the binomial distribution\n",
        "def calculate_binomial_distribution(count_matches, total_samples, count_percentage):\n",
        "    k = count_matches\n",
        "    distribution = binom.pmf(k, total_samples, count_percentage)\n",
        "    return distribution\n",
        "\n",
        "# Function to count the number of samples in a set of y-samples\n",
        "def count_samples(y_samples):\n",
        "    return len(set(y_samples.split(', ')))\n",
        "\n",
        "significant_enzymes_df = pd.read_csv('sig_spearman_enzymes.txt', sep=', ', header=None, engine='python')\n",
        "significant_enzymes_df.columns = ['Enzyme', 'Correlation', 't-value', 'p-value']\n",
        "\n",
        "files = ['s_sig_combo2.txt', 's_sig_combo3.txt', 's_sig_combo4.txt']\n",
        "\n",
        "results_df = pd.DataFrame(columns=['Enzyme Pair', 'Enzyme Name', 'Mann U', 'Binomial Distribution', 'y-samples', '# of samples'])\n",
        "\n",
        "results_df = pd.concat([significant_enzymes_df, results_df], ignore_index=True)\n",
        "\n",
        "for file in files:\n",
        "    with open(file, 'r') as sig_file:\n",
        "        next(sig_file)\n",
        "\n",
        "        for line in sig_file:\n",
        "            values = line.strip().split('\\t')\n",
        "            enzyme_set = values[0]\n",
        "            enzyme_name = values[1]\n",
        "            mann_u_value = float(values[2])\n",
        "\n",
        "            # Retrieve binomial distribution from the corresponding combo file\n",
        "            combo_file = f's_combo{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            binomial_distribution = None\n",
        "\n",
        "            with open(combo_file, 'r') as combo_data:\n",
        "                next(combo_data)\n",
        "                for combo_line in combo_data:\n",
        "                    combo_values = combo_line.strip().split('\\t')\n",
        "\n",
        "                    # Check if enzyme_set matches any combination in the combo file\n",
        "                    combo_enzymes = set(combo_values[:len(enzyme_set.split(\"-\"))])\n",
        "                    if set(enzyme_set.split(\"-\")) == combo_enzymes:\n",
        "                        binomial_distribution = float(combo_values[-2])\n",
        "                        break\n",
        "\n",
        "            # Retrieve y-samples from the corresponding Wilcoxon_y-samples file\n",
        "            y_samples_file = f's_Wilcoxon_y-samples{len(enzyme_set.split(\"-\"))}.txt'\n",
        "            with open(y_samples_file, 'r') as y_samples_data:\n",
        "                for y_samples_line in y_samples_data:\n",
        "                    y_samples_values = y_samples_line.strip().split('\\t')\n",
        "                    if y_samples_values[0] == enzyme_set:\n",
        "                        y_samples = y_samples_values[1:]\n",
        "                        break\n",
        "\n",
        "            # Count the number of samples in the set of y-samples\n",
        "            num_samples = count_samples(', '.join(y_samples))\n",
        "\n",
        "            new_row = pd.DataFrame([{\n",
        "                'Enzyme Pair': enzyme_set,\n",
        "                'Enzyme Name': enzyme_name,\n",
        "                'Mann U': mann_u_value,\n",
        "                'Binomial Distribution': binomial_distribution,\n",
        "                'y-samples': ', '.join(y_samples),\n",
        "                '# of samples': num_samples\n",
        "            }])\n",
        "\n",
        "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
        "\n",
        "results_df.to_excel('soil_spearman_combinations.xlsx', index=False)"
      ],
      "metadata": {
        "id": "TwLNndxZXvSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confidence Interval"
      ],
      "metadata": {
        "id": "Pd9MTLFYffBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to perform Fisher's transformation\n",
        "def fisher_z_transformation(correlation_coefficient):\n",
        "    return 0.5 * np.log((1 + correlation_coefficient) / (1 - correlation_coefficient))\n",
        "\n",
        "# Function to calculate confidence interval for correlation\n",
        "def calculate_confidence_interval(correlation_coefficient, degrees_of_freedom, confidence_level=0.95):\n",
        "    # Step 1: Apply Fisher's transformation\n",
        "    z = fisher_z_transformation(correlation_coefficient)\n",
        "\n",
        "    # Step 2: Calculate the standard error (SE)\n",
        "    n = degrees_of_freedom + 2  # Sample size (degrees of freedom + 2)\n",
        "    se = 1 / np.sqrt(n - 3)\n",
        "\n",
        "    # Step 3: Calculate the Z-value for the confidence level\n",
        "    alpha = 1 - confidence_level\n",
        "    z_alpha = stats.norm.ppf(1 - alpha / 2)  # Z value for confidence level (e.g., 1.96 for 95% CI)\n",
        "\n",
        "    # Step 4: Compute the confidence interval in the Fisher transformed space\n",
        "    z_lower = z - z_alpha * se\n",
        "    z_upper = z + z_alpha * se\n",
        "\n",
        "    # Step 5: Back-transform the Z interval to get the correlation coefficient interval\n",
        "    r_lower = (np.exp(2 * z_lower) - 1) / (np.exp(2 * z_lower) + 1)\n",
        "    r_upper = (np.exp(2 * z_upper) - 1) / (np.exp(2 * z_upper) + 1)\n",
        "\n",
        "    return r_lower, r_upper\n",
        "\n",
        "significant_rows = []\n",
        "with open(\"sig_pearson_enzymes.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        # Parse the enzyme name, correlation coefficient, and t-dist values\n",
        "        parts = line.strip().split(\", \")\n",
        "        enzyme_name = parts[0].split(\" = \")[1]\n",
        "        correlation = float(parts[1].split(\" = \")[1])\n",
        "        t_value = float(parts[2].split(\" = \")[1].split()[0])\n",
        "        p_value = float(parts[3].split(\" = \")[1])\n",
        "\n",
        "        significant_rows.append((enzyme_name, correlation, t_value, p_value))\n",
        "\n",
        "# Calculate the confidence intervals and store the results\n",
        "confidence_intervals = []\n",
        "for enzyme_name, correlation, t_value, p_value in significant_rows:\n",
        "    df = 39\n",
        "\n",
        "    # Calculate the confidence interval for this enzyme's correlation coefficient\n",
        "    r_lower, r_upper = calculate_confidence_interval(correlation, df)\n",
        "\n",
        "    confidence_intervals.append((enzyme_name, correlation, r_lower, r_upper, t_value, p_value))\n",
        "\n",
        "# Write to a .tab file with header\n",
        "with open(\"confidence_intervals_pearson.tab\", \"w\") as file:\n",
        "    # Write header row\n",
        "    file.write(\"Enzyme\\tCorrelation\\t95% CI Lower\\t95% CI Upper\\tt-dist (x value)\\tp-value\\n\")\n",
        "\n",
        "    # Write data rows without \"Enzyme = \" etc.\n",
        "    for enzyme_name, correlation, r_lower, r_upper, t_value, p_value in confidence_intervals:\n",
        "        # Using tabs as separators instead of the \" = \" syntax\n",
        "        file.write(f\"{enzyme_name}\\t{correlation}\\t{r_lower}\\t{r_upper}\\t{t_value}\\t{p_value}\\n\")"
      ],
      "metadata": {
        "id": "F-DPLeR6sTV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confidence Interval (Spearman)"
      ],
      "metadata": {
        "id": "2G1JiyFyPKSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Function to perform Fisher's transformation\n",
        "def fisher_z_transformation(correlation_coefficient):\n",
        "    return 0.5 * np.log((1 + correlation_coefficient) / (1 - correlation_coefficient))\n",
        "\n",
        "# Function to calculate confidence interval for correlation\n",
        "def calculate_confidence_interval(correlation_coefficient, degrees_of_freedom, confidence_level=0.95):\n",
        "    # Step 1: Apply Fisher's transformation\n",
        "    z = fisher_z_transformation(correlation_coefficient)\n",
        "\n",
        "    # Step 2: Calculate the standard error (SE)\n",
        "    n = degrees_of_freedom + 2  # Sample size (degrees of freedom + 2)\n",
        "    se = 1 / np.sqrt(n - 3)\n",
        "\n",
        "    # Step 3: Calculate the Z-value for the confidence level\n",
        "    alpha = 1 - confidence_level\n",
        "    z_alpha = stats.norm.ppf(1 - alpha / 2)  # Z value for confidence level (e.g., 1.96 for 95% CI)\n",
        "\n",
        "    # Step 4: Compute the confidence interval in the Fisher transformed space\n",
        "    z_lower = z - z_alpha * se\n",
        "    z_upper = z + z_alpha * se\n",
        "\n",
        "    # Step 5: Back-transform the Z interval to get the correlation coefficient interval\n",
        "    r_lower = (np.exp(2 * z_lower) - 1) / (np.exp(2 * z_lower) + 1)\n",
        "    r_upper = (np.exp(2 * z_upper) - 1) / (np.exp(2 * z_upper) + 1)\n",
        "\n",
        "    return r_lower, r_upper\n",
        "\n",
        "significant_rows = []\n",
        "with open(\"sig_spearman_enzymes.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        # Parse the enzyme name, correlation coefficient, and t-dist values\n",
        "        parts = line.strip().split(\", \")\n",
        "        enzyme_name = parts[0].split(\" = \")[1]\n",
        "        correlation = float(parts[1].split(\" = \")[1])\n",
        "        t_value = float(parts[2].split(\" = \")[1].split()[0])\n",
        "        p_value = float(parts[3].split(\" = \")[1])\n",
        "\n",
        "        significant_rows.append((enzyme_name, correlation, t_value, p_value))\n",
        "\n",
        "# Calculate the confidence intervals and store the results\n",
        "confidence_intervals = []\n",
        "for enzyme_name, correlation, t_value, p_value in significant_rows:\n",
        "    df = 39\n",
        "\n",
        "    # Calculate the confidence interval for this enzyme's correlation coefficient\n",
        "    r_lower, r_upper = calculate_confidence_interval(correlation, df)\n",
        "\n",
        "    confidence_intervals.append((enzyme_name, correlation, r_lower, r_upper, t_value, p_value))\n",
        "\n",
        "# Change the output file extension to .tab\n",
        "with open(\"confidence_intervals_spearman.tab\", \"w\") as file:\n",
        "    # Write header row\n",
        "    file.write(\"Enzyme\\tCorrelation\\t95% CI Lower\\t95% CI Upper\\tt-dist (x value)\\tp-value\\n\")\n",
        "\n",
        "    # Write data rows without the \"Enzyme = \" etc.\n",
        "    for enzyme_name, correlation, r_lower, r_upper, t_value, p_value in confidence_intervals:\n",
        "        # Using tabs as separators instead of the \" = \" syntax\n",
        "        file.write(f\"{enzyme_name}\\t{correlation}\\t{r_lower}\\t{r_upper}\\t{t_value}\\t{p_value}\\n\")\n"
      ],
      "metadata": {
        "id": "EQkK4VBcPVT4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "plastics",
      "language": "python",
      "name": "plastics"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}